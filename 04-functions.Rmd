---
output_yaml:
  - _output.yml
---

# Functions


<!-- 0. Add all of the Primer to the tutorial. Add lots more list-column and map functions, both at the start and at end.  Add 30 list-column and mapping questions, generally with with each set of questions grouped into a mini two or three question series. E-mail me. -->

<!-- 1. Make clear the mapping from chapter sections to tutorial panels. With numbering. Also fix the easily fixable from style.Rmd. -->

<!-- 3. Read the probability chapter in bok. Maybe the running examples here should all be stuff from dice, coins and so on, setting the stage for chapter 5. Or maybe those are the questions we should ask in the tutorial? -->

<!-- 4. Create 04-functions-questions.Rmd. This where we will put questions (and their answers) which we will use in problem sets and exams. Write one. -->

<!-- 5. Create 04-functions-script.Rmd. This will be the script that we use in class that week. Put down some thoughts. about what we should be doing. -->


The goal of this chapter is to reveal the __process__ a long-time useR employs for writing functions. We also want to illustrate why the process is the way it is. Merely looking at the finished product, e.g. source code for R packages, can be extremely deceiving. Reality is generally much uglier ... but more interesting! Powerful machines like dplyr and purrr are ready and waiting to apply your purpose-built functions to various bits of your data. If you can express your analytical wishes in a function, these tools will give you great power.

To introduce the concept of functions, this chapter will first involve a discussion of list columns and map function. 

## List columns and `map_*` functions

We are now going to learn about [**list columns**](https://r4ds.had.co.nz/many-models.html#list-columns-1) and [**`map_*` functions**](https://jennybc.github.io/purrr-tutorial/ls01_map-name-position-shortcuts.html), powerful tools that we will be using throughout the book.^[If I were going to give a lecture on these topics, it would look like [this one](https://resources.rstudio.com/webinars/how-to-work-with-list-columns-garrett-grolemund).]


### What are list columns?

<!-- DK: maybe start with "What are lists?" The chapter from R4DS with the pepper shaker pictures is excellent. -->

A list column is a column of your data which is a [list](https://adv-r.hadley.nz/vectors-chap.html#lists) rather than an atomic vector. Atomic vectors are familiar to us: each element of the vector has one value, and thus if an atomic vector is a column in your dataset, each observation gets a single value.  Lists, however, can contain vectors as elements. The best way to understand this is by creating a list column yourself and inspecting the results.  `str()` is a helpful function for looking at the contents of a tibble with list columns:

```{r simple_list_col, message = FALSE}
library(tidyverse)
library(gapminder)

tibble(new_col = list(1:2, 3:5)) %>%
  str()
```

Here we see that our tibble has one column (`new_col`) and one observation, which is a list with two elements.  The first element in the list is a vector of the integers 1 and 2 and the second element is a vector of the integers 3, 4, and 5. The tibble only has one row because there is only one value for `new_col`. 

Note that this is a case where it is crucial to use `tibble()`, not `data.frame()`!  If we had used `data.frame()` in the last example, it wouldn't have worked:

```{r data_frame, error = TRUE}
data.frame(new_col = list(1:2, 3:5)) %>%
  str()
```

Lists are very flexible.  For example, each element of a list can have its own data type:

```{r mulitple_types}
tibble(new_col = list(1:2,
                      c("Alice", "Bob"))) %>%
  str()
```

Now the first element consists of the integers 1 and 2 while the second is a character vector containing "Alice" and "Bob".

We wrapped "Alice" and "Bob" in `c()` in order to make it clear that this is a vector.  If we hadn't done that, we would have three elements in our list: the vector with 1 and 2, "Alice", and "Bob":

```{r no_c}
tibble(new_col = list(1:2,
                      "Alice",
                      "Bob")) %>%
  str()
```

### Creating list columns with `mutate()`

Any function that returns multiple values can be used to create a list column.  For example, consider the following tibble:

```{r alice_and_bob, eval = FALSE}
tibble(col_1 = c("Alice and Bob", "Carol and Dan"))
```

`col_1` is a character vector with two observations: "Alice and Bob" and "Carol and Dan". The tibble has two rows. It may be more useful to present these as vectors of names, without the annoying "and" in between.  That's exactly what we can do with `str_split()`:

```{r function_list_col}
tibble(col_1 = c("Alice and Bob", "Carol and Dan")) %>%
  mutate(col_2 = str_split(col_1, " and ")) %>%
  str()
```

After using `str_split()` within `mutate()`, we have created a new column, and that new column is a list column. 

This is often how we will go about creating list columns.  Let's practice with the `gapminder` dataset.  How could we add a column to the dataset that included the quantiles of the `lifeExp` variable?

```{r gapminder_list_column}
gapminder %>%
  group_by(year) %>%
  mutate(lifeExpQuantile = list(quantile(lifeExp)))
```

*Note*: `str_split()` was a particularly easy function for using with `mutate()` and `summarize()` because it returns a list.  You can check this by running `typeof()` on the output of `str_split()`: e.g., `str_split("Alice and Bob", " and ") %>% typeof()`.  If a function returns multiple values as a vector, like `quantile()` does, you can't use it directly in `mutate()` or `summarize()`, but you can wrap `list()` around it in order to get the same behavior.

<!-- DK: The above bit should be explained at the beginning when we review lists. -->

Or let's say that we wanted 1) to subset the dataset to the most recent year, 2) group by continent, and 3) get a `summary()` of the `gdpPercap` variable by continent:

```{r continent_summary}
gapminder %>%
  filter(year == max(year)) %>%
  group_by(continent) %>%
  summarize(gdpSummary = list(summary(gdpPercap)))
```

### `map_*` functions

What can we do with a list column? That is tricky! Lists are hard to work with. But the most natural thing to do with a list is to feed it to a `map_*` function.  What are these functions?

Let's say that you want to add 1 to row of a variable in a tibble, storing the result in `x`.  You could accomplish this with `mutate`:

```{r for_loop_example}
tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = start + 1)

```

We could instead create a function that adds 1 to a number.  Then, we can use `map_dbl()` to apply this to our input variable.  `map_dbl()` --- pronounced "map double" --- comes from the **purrr** package, which you will have loaded if you have loaded **tidyverse**.  `map_dbl()` is just one member of a family of `map_*` functions which applies the same function to every row in a tibble. The "dbl" suffix indicates that the function returns a "double," meaning a numeric value.


```{r map_simple}
increment <- function(x) return(x + 1)

tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = map_dbl(start, increment))
```

`map_dbl()` took the function `increment` and applied it to each element of `start`. Note that, when we passed the function `increment` to `map_dbl()`, we passed in just its name, without the closing parentheses. This code fails:

```{r, error=TRUE}
tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = map_dbl(start, increment()))
```

`increment()` with the parantheses is a call to the function. So, the first thing R tries to do is to run the function. Doing so fails because `increment()` requires an argument `x`, which is not present. Lesson: When passing a function in to `map_*` functions, pass just the name.

The syntax can get even simpler than this if we use [anonymous functions.](https://coolbutuseless.github.io/2019/03/13/anonymous-functions-in-r-part-1/)  An anonymous function in R is one without a name. The function `increment()` has a name, obviously. But we can create a function which does the same thing "on the fly" without bothering to give it a name. 

There are two ways to create anonymous functions.  The first one, using base R, uses `function()` to create a function within `map_dbl()`.  

```{r}
tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = map_dbl(start, function(x) x + 1))
```

The second, using the **purrr** package (from where we get `map_dbl()`), starts with the `~` operator and then uses `.` to represent the current element.

```{r}
tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = map_dbl(start, ~ (. + 1)))
```

Note that the parantheses are not necessary. As long as everything after the `~` works as R code, the anonymous function should work, each time replace the `.` with the value of the `.x` variable --- which is `start` in this case --- with its value in that row.

```{r}
tibble(start = c(3, 2.5, 6)) %>% 
  mutate(new = map_dbl(start, ~ . + 1))
```

The `~ ` shorthand is very convenient once you get used to it.  

We called these `map_*` *functions* (plural) before.  If you know the expected output of your function, you can specify that kind of vector:

- `map()`: list  
- `map_lgl()`: logical
- `map_int()`: integer
- `map_dbl()`: double (numeric)
- `map_chr()`: character
- `map_df()`: data frame

So, since our example produces numeric output, we use `map_dbl()` instead of `map()`.

### Using `map_*` functions to create list columns

We can use `map_*` functions to create list columns.  We'll use the `weather` dataset in the `nycflights13` package.

First, let's wrangle the data so each observation is a day rather than an hour.  We'll create a list column `temps_F` that consists of all the temperatures recorded that day at a particular origin.

```{r weather_temps, eval = FALSE}
weather %>%
  group_by(origin, year, month, day) %>%
  summarize(temps_F = list(c(temp)))
```

Now that we have a list column, we can use it as the input to `map()`, outputting another list column.  Let's say we wanted a new list column, `temps_C`, which records the temperature in Celsius:

```{r temps_C, eval = FALSE}
weather %>%
  group_by(origin, year, month, day) %>%
  summarize(temps_F = list(c(temp))) %>%
  mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9))
```

Note that we took the list column `temps_F` and, by applying an anonymous function to it with `map()`, created another list column `temps_C`.  This is a very common process.  It is similar to taking a tibble and piping it into a `dplyr` function (such as `mutate()`) which gives you a new tibble that you can work with.

You can also use `map_*` functions to take a list column as an input and return an atomic vector -- a column with a single value per observation -- as an output.  For instance, let's say we now wanted the mean of the recorded temperatures per day in Celsius:

```{r temps_C_mean, eval = FALSE}
weather %>%
  group_by(origin, year, month, day) %>%
  summarize(temps_F = list(c(temp))) %>%
  mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9),
         mean_C = map_dbl(temps_C, mean, na.rm = TRUE))
```

Here, we also see that the `map_*` functions have the `...` argument, which allows `na.rm = TRUE` to be passed along to `mean()`.

What if we wanted to know the proportion of temperatures recorded per day per airport that were below freezing?

```{r prop_freezing, eval = FALSE}
weather %>%
  group_by(origin, year, month, day) %>%
  summarize(temps_F = list(c(temp))) %>%
  mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9),
         is_freezing = map(temps_C, ~ . < 0),
         prop_freezing = map_dbl(is_freezing, mean, na.rm = TRUE))
```

See how we chained the `map_*` functions:

1) `temps_F` was used as the input to `map()` to create `temps_C`
2) `temps_C` was used as the input to `map()` to create `is_freezing`
3) `is_freezing` was used as the input to `map_dbl()` to create `prop_freezing`

Or let's say we wanted to know the top 5 temperatures recorded at each airport each day:

```{r top_5, eval = FALSE}
weather %>%
  group_by(origin, year, month, day) %>%
  summarize(temps_F = list(c(temp))) %>%
  mutate(temps_C = map(temps_F, ~ (. - 32) * 5/9),
         sorted_C = map(temps_C, ~ sort(., decreasing = TRUE)),
         top5_C = map(temps_C, ~ .[1:5]))
```

<!-- This is where we need to fill in the gap between map functions and functions in general -->

## Part 1

Load gapminder.

```{r start_func1}
library(gapminder)
str(gapminder)
```

Say you've got a numeric vector, and you want to compute the difference between its max and min. `lifeExp` or `pop` or `gdpPercap` are great examples of a typical input. You can imagine wanting to get this statistic after we slice up the Gapminder data by year, country, continent, or combinations thereof.

### Get something that works

First, develop some working code for interactive use, using a representative input. Use Gapminder's life expectancy variable. R functions that will be useful: `min()`, `max()`, `range()`. 

```{r}
# Get to know the functions mentioned above

min(gapminder$lifeExp)
max(gapminder$lifeExp)
range(gapminder$lifeExp)

# Some natural solutions

max(gapminder$lifeExp) - min(gapminder$lifeExp)
with(gapminder, max(lifeExp) - min(lifeExp))
range(gapminder$lifeExp)[2] - range(gapminder$lifeExp)[1]
with(gapminder, range(lifeExp)[2] - range(lifeExp)[1])
diff(range(gapminder$lifeExp))
```

Internalize this "answer" because our informal testing relies on you noticing departures from this.

### Skateboard >> perfectly formed rear-view mirror

This image --- widely attributed to the Spotify development team --- conveys an important point.

```{r spotify-howtobuildmvp, echo = FALSE, out.width = "60%", fig.cap = "From [Your ultimate guide to Minimum Viable Product (+great examples)](https://blog.fastmonkeys.com/2014/06/18/minimum-viable-product-your-ultimate-guide-to-mvp-great-examples/)"}
knitr::include_graphics("04-functions/images/mvp.jpg")
```

Build that skateboard before you build the car or some fancy car part. A limited-but-functioning thing is very useful. It also keeps the spirits high.

This is related to the valuable [Telescope Rule][telescope-rule]:

> It is faster to make a four-inch mirror and then a six-inch mirror than it is to make a six-inch mirror.

### Turn the working interactive code into a function

Add NO new functionality! Just write your very first R function.

```{r}
max_minus_min <- function(x) max(x) - min(x)
max_minus_min(gapminder$lifeExp)
```

Check that you're getting the same answer as you did with your interactive code. Test it eyeball-o-metrically at this point.

### Test your function

#### Test on new inputs

Pick some new artificial inputs where you know (at least approximately) what your function should return.

```{r}
max_minus_min(1:10)
max_minus_min(runif(1000))
```

I know that 10 minus 1 is 9. I know that random uniform [0, 1] variates will be between 0 and 1. Therefore max - min should be less than 1. If I take LOTS of them, max - min should be pretty close to 1.

It is intentional that I tested on integer input as well as floating point. Likewise, I like to use valid-but-random data for this sort of check.

#### Test on real data but *different* real data

Back to the real world now. Two other quantitative variables are lying around: `gdpPercap` and `pop`. Let's have a go.

```{r}
max_minus_min(gapminder$gdpPercap)
max_minus_min(gapminder$pop)
```

Either check these results "by hand" or apply the "does that even make sense?" test.

#### Test on weird stuff

Now we try to break our function. Don't get truly diabolical (yet). Just make the kind of mistakes you can imagine making at 2am when, 3 years from now, you rediscover this useful function you wrote. Give your function inputs it's not expecting.

```{r error = TRUE}
max_minus_min(gapminder)

# Hey, sometimes things "just work" on data.frames!

max_minus_min(gapminder$country)

# Factors are kind of like integer vectors, no?

max_minus_min("eggplants are purple")

# I have no excuse for this one
```

How happy are you with those error messages? You must imagine that some entire __script__ has failed and that you were hoping to just `source()` it without re-reading it. If a colleague or future you encountered these errors, do you run screaming from the room? How hard is it to pinpoint the usage problem?

#### I will scare you now

Here are some great examples where the function __should break but it does not.__

```{r}
max_minus_min(gapminder[c('lifeExp', 'gdpPercap', 'pop')])
max_minus_min(c(TRUE, TRUE, FALSE, TRUE, TRUE))
```

In both cases, R's eagerness to make sense of our requests is unfortunately successful. In the first case, a tibble containing just the quantitative variables is eventually coerced into numeric vector. We can compute max minus min, even though it makes absolutely no sense at all. In the second case, a logical vector is converted to zeroes and ones, which might merit an error or at least a warning.

### Check the validity of arguments

For functions that will be used again -- which is not all of them! -- it is good to check the validity of arguments. This implements a rule from [the Unix philosophy][unix-philosophy]:

> Rule of Repair: When you must fail, fail noisily and as soon as possible.

#### stop if not

`stopifnot()` is the entry level solution. We use it here to make sure the input `x` is a numeric vector.

```{r error = TRUE}
mmm <- function(x) {
  stopifnot(is.numeric(x))
  max(x) - min(x)
}
mmm(gapminder)
mmm(gapminder$country)
mmm("eggplants are purple")
mmm(gapminder[c('lifeExp', 'gdpPercap', 'pop')])
mmm(c(TRUE, TRUE, FALSE, TRUE, TRUE))
```

And we see that it catches all of the self-inflicted damage we would like to avoid.

#### if then stop

`stopifnot()` doesn't provide a very good error message. The next approach is very widely used. Put your validity check inside an `if()` statement and call `stop()` yourself, with a custom error message, in the body.

```{r error = TRUE}
mmm2 <- function(x) {
  if(!is.numeric(x)) {
    stop('I am so sorry, but this function only works for numeric input!\n',
         'You have provided an object of class: ', class(x)[1])
  }
  max(x) - min(x)
}
mmm2(gapminder)
```

In addition to a gratuitous apology, the error also contains two more pieces of helpful info:
  
* *Which* function threw the error.
* Hints on how to fix things: expected class of input vs actual class.

If it is easy to do so, we highly recommend this template: "you gave me THIS, but I need THAT".

The tidyverse style guide has a very useful [chapter on how to construct error messages](https://style.tidyverse.org/error-messages.html).

#### Sidebar: non-programming uses for assertions

Another good use of this pattern is to leave checks behind in data analytical scripts. Consider our repetitive use of Gapminder in this book. Every time we load it, we inspect it, hoping to see the usual stuff. If we were loading from file (vs. a stable data package), we might want to formalize our expectations about the number of rows and columns, the names and flavors of the variables, etc. This would alert us if the data suddenly changed, which can be a useful wake-up call in scripts that you re-run *ad nauseam* on auto-pilot or non-interactively.

### Wrap-up and what's next?

Here's the function we've written so far:

```{r end_func1}
mmm2
```

What we've accomplished:

* We've written our first function.
* We are checking the validity of its input, argument `x`.
* We've done a good amount of informal testing.
  
## Part 2

In part 1, we wrote our first R function to compute the difference between the max and min of a numeric vector. We checked the validity of the function's only argument and, informally, we verified that it worked pretty well.

In this part, we generalize this function, learn more technical details about R functions, and set default values for some arguments.

### Load the Gapminder data

Load gapminder.

```{r start_func2}
library(gapminder)
```

### Restore our max minus min function

Let's keep our previous function around as a baseline.

```{r}
mmm <- function(x) {
  stopifnot(is.numeric(x))
  max(x) - min(x)
}
```

### Generalize our function to other quantiles

The max and the min are special cases of a __quantile__. Here are other special cases you may have heard of:

* median = 0.5 quantile
* 1st quartile = 0.25 quantile
* 3rd quartile = 0.75 quantile
  
If you're familiar with [box plots][wiki-boxplot], the rectangle typically runs from the 1st quartile to the 3rd quartile, with a line at the median.

If $q$ is the $p$-th quantile of a set of $n$ observations, what does that mean? Approximately $pn$ of the observations are less than $q$ and $(1 - p)n$ are greater than $q$. Yeah, you need to worry about rounding to an integer and less/greater than or equal to, but these details aren't critical here.

Let's generalize our function to take the difference between any two quantiles. We can still consider the max and min, if we like, but we're not limited to that.

### Get something that works, again

The eventual inputs to our new function will be the data `x` and two probabilities.

First, play around with the `quantile()` function. Convince yourself you know how to use it, for example, by cross-checking your results with other built-in functions.

```{r}
quantile(gapminder$lifeExp)
quantile(gapminder$lifeExp, probs = 0.5)
median(gapminder$lifeExp)
quantile(gapminder$lifeExp, probs = c(0.25, 0.75))
boxplot(gapminder$lifeExp, plot = FALSE)$stats
```

Now write a code snippet that takes the difference between two quantiles.

```{r}
the_probs <- c(0.25, 0.75)
the_quantiles <- quantile(gapminder$lifeExp, probs = the_probs)
max(the_quantiles) - min(the_quantiles)
```

### Turn the working interactive code into a function, again

Use `qdiff` as the base of our function's name. We copy the overall structure from our previous "max minus min" work but replace the guts of the function with the more general code we just developed.

```{r}
qdiff1 <- function(x, probs) {
  stopifnot(is.numeric(x))
  the_quantiles <- quantile(x = x, probs = probs)
  max(the_quantiles) - min(the_quantiles)
}
qdiff1(gapminder$lifeExp, probs = c(0.25, 0.75))
IQR(gapminder$lifeExp)

# Hey, we've reinvented IQR

qdiff1(gapminder$lifeExp, probs = c(0, 1))
mmm(gapminder$lifeExp)
```

Again we do some informal tests against familiar results and external implementations.

### Argument names: freedom and conventions

Understand the importance of argument names. We can name my arguments almost anything we like. Proof:

```{r}
qdiff2 <- function(zeus, hera) {
  stopifnot(is.numeric(zeus))
  the_quantiles <- quantile(x = zeus, probs = hera)
  max(the_quantiles) - min(the_quantiles)
}
qdiff2(zeus = gapminder$lifeExp, hera = 0:1)
```

While we can name my arguments after Greek gods, it's usually a bad idea. Take all opportunities to make things more self-explanatory via meaningful names.

If you are going to pass the arguments of your function as arguments of a built-in function, consider copying the argument names. Unless you have a good reason to do your own thing (some argument names are bad!), be consistent with the existing function. Again, the reason is to reduce your cognitive load. 

```{r}
qdiff1
```

We took this detour so you could see there is no *structural* relationship between our arguments (`x` and `probs`) and those of `quantile()` (also `x` and `probs`). The similarity or equivalence of the names __accomplishes nothing__ as far as R is concerned; it is solely for the benefit of humans reading, writing, and using the code. Which is very important!

### What a function returns

By default, a function returns the result of the last line of the body. We are just letting that happen with the line `max(the_quantiles) - min(the_quantiles)`. However, there is an explicit function for this: `return()`. We could just as easily make this the last line of my function's body:

```{r eval = FALSE}
return(max(the_quantiles) - min(the_quantiles))
```

You absolutely must use `return()` if you want to return early based on some condition, i.e. before execution gets to the last line of the body. Otherwise, you can decide your own conventions about when you use `return()` and when you don't.

### Default values: freedom to NOT specify the arguments

What happens if we call our function but neglect to specify the probabilities?

```{r error = TRUE}
qdiff1(gapminder$lifeExp)
```

Oops! At the moment, this causes a fatal error. It can be nice to provide some reasonable default values for certain arguments. In our case, it would be crazy to specify a default value for the primary input `x`, but very kind to specify a default for `probs`.

We started by focusing on the max and the min, so I think those make reasonable defaults. Here's how to specify that in a function definition.

```{r}
qdiff3 <- function(x, probs = c(0, 1)) {
  stopifnot(is.numeric(x))
  the_quantiles <- quantile(x, probs)
  max(the_quantiles) - min(the_quantiles)
}
```

Again we check how the function works, in old examples and new, specifying the `probs` argument and not.

```{r}
qdiff3(gapminder$lifeExp)
mmm(gapminder$lifeExp)
qdiff3(gapminder$lifeExp, c(0.1, 0.9))
```

### Wrap-up and what's next?

Here's the function we've written so far:

```{r end_func2}
qdiff3
```

What we've accomplished:

* We've generalized our first function to take a difference between arbitrary quantiles.
* We've specified default values for the probabilities that set the quantiles.
  
## Part 3

In part 2 we generalized our first R function so it could take the difference between any two quantiles of a numeric vector. We also set default values for the underlying probabilities, so that, by default, we compute the max minus the min.

In this part, we tackle `NA`s, the special argument `...` and formal testing.

### Load the Gapminder data

Load gapminder.

```{r start_func3}
library(gapminder)
```

### Restore our max minus min function

Let's keep our previous function around as a baseline.

```{r}
qdiff3 <- function(x, probs = c(0, 1)) {
  stopifnot(is.numeric(x))
  the_quantiles <- quantile(x, probs)
  max(the_quantiles) - min(the_quantiles)
}
```

### Be proactive about `NA`s

We are being gentle by letting you practice with the Gapminder data. In real life, missing data will make your life a living hell. If you are lucky, it will be properly indicated by the special value `NA`, but don't hold your breath. Many built-in R functions have an `na.rm =` argument through which you can specify how you want to handle `NA`s. Typically the default value is `na.rm = FALSE` and typical default behavior is to either let `NA`s propagate or to raise an error. Let's see how `quantile()` handles `NA`s:

```{r error = TRUE}
z <- gapminder$lifeExp
z[3] <- NA
quantile(gapminder$lifeExp)
quantile(z)
quantile(z, na.rm = TRUE)
```

So `quantile()` simply will not operate in the presence of `NA`s unless `na.rm = TRUE`. How shall we modify our function?

If we wanted to hardwire `na.rm = TRUE`, we could. Focus on our call to `quantile()` inside our function definition.

```{r}
qdiff4 <- function(x, probs = c(0, 1)) {
  stopifnot(is.numeric(x))
  the_quantiles <- quantile(x, probs, na.rm = TRUE)
  max(the_quantiles) - min(the_quantiles)
}
qdiff4(gapminder$lifeExp)
qdiff4(z)
```

This works but it is dangerous to invert the default behavior of a well-known built-in function and to provide the user with no way to override this.

We could add an `na.rm =` argument to our own function. We might even enforce our preferred default -- but at least we're giving the user a way to control the behavior around `NA`s.

```{r error = TRUE}
qdiff5 <- function(x, probs = c(0, 1), na.rm = TRUE) {
  stopifnot(is.numeric(x))
  the_quantiles <- quantile(x, probs, na.rm = na.rm)
  max(the_quantiles) - min(the_quantiles)
}
qdiff5(gapminder$lifeExp)
qdiff5(z)
qdiff5(z, na.rm = FALSE)
```

### The useful but mysterious `...` argument

You probably could have lived a long and happy life without knowing there are at least 9 different algorithms for computing quantiles. [Go read about the `type` argument][rdocs-quantile] of `quantile()`. TLDR: If a quantile is not unambiguously equal to an observed data point, you must somehow average two data points. You can weight this average different ways, depending on the rest of the data, and `type =` controls this.

Let's say we want to give the user of our function the ability to specify how the quantiles are computed, but we want to accomplish with as little fuss as possible. In fact, we don't even want to clutter our function's interface with this! This calls for the very special `...` argument. In English, this set of three dots is frequently called an "ellipsis".

```{r}
qdiff6 <- function(x, probs = c(0, 1), na.rm = TRUE, ...) {
  the_quantiles <- quantile(x = x, probs = probs, na.rm = na.rm, ...)
  max(the_quantiles) - min(the_quantiles)
}
```

The practical significance of the `type =` argument is virtually nonexistent, so we can't demo with the Gapminder data. Thanks to [\@wrathematics][twitter-wrathematics], here's a small example where we can (barely) detect a difference due to `type`.

```{r}
set.seed(1234)
z <- rnorm(10)
quantile(z, type = 1)
quantile(z, type = 4)
all.equal(quantile(z, type = 1), quantile(z, type = 4))
```

Now we can call our function, requesting that quantiles be computed in different ways.

```{r}
qdiff6(z, probs = c(0.25, 0.75), type = 1)
qdiff6(z, probs = c(0.25, 0.75), type = 4)
```

While the difference may be subtle, __it's there__. Marvel at the fact that we have passed `type = 1` through to `quantile()` *even though it was not a formal argument of our own function*.

The special argument `...` is very useful when you want the ability to pass arbitrary arguments down to another function, but without constantly expanding the formal arguments to your function. This leaves you with a less cluttered function definition and gives you future flexibility to specify these arguments only when you need to.

You will also encounter the `...` argument in many built-in functions -- read up on [`c()`][rdocs-c] or [`list()`][rdocs-list] -- and now you have a better sense of what it means. It is not a breezy "and so on and so forth."

There are also downsides to `...`, so use it with intention. In a package, you will have to work harder to create truly informative documentation for your user. Also, the quiet, absorbent properties of `...` mean it can sometimes silently swallow other named arguments, when the user has a typo in the name. Depending on whether or how this fails, it can be a little tricky to find out what went wrong.

The [ellipsis package](https://ellipsis.r-lib.org) provides tools that help package developers use `...` more safely. The in-progress tidyverse principles guide provides further guidance on the design of functions that take `...` in [Data, dots, details](https://principles.tidyverse.org/dots-position.html).

### Use testthat for formal unit tests

Until now, we've relied on informal tests of our evolving function. If you are going to use a function a lot, especially if it is part of a package, it is wise to use formal unit tests.

The [testthat][testthat-web] package ([CRAN][testthat-cran]; [GitHub][testthat-github]) provides excellent facilities for this, with a distinct emphasis on automated unit testing of entire packages. However, we can take it out for a test drive even with our one measly function.

We will construct a test with `test_that()` and, within it, we put one or more *expectations* that check actual against expected results. You simply harden your informal, interactive tests into formal unit tests. Here are some examples of tests and indicative expectations.

```{r eval = FALSE}
library(testthat)

test_that('invalid args are detected', {
  expect_error(qdiff6("eggplants are purple"))
  expect_error(qdiff6(iris))
})

test_that('NA handling works', {
  expect_error(qdiff6(c(1:5, NA), na.rm = FALSE))
  expect_equal(qdiff6(c(1:5, NA)), 4)
})
```

No news is good news! Let's see what test failure would look like. Let's revert to a version of our function that does no `NA` handling, then test for proper `NA` handling. We can watch it fail.

```{r end_func3, eval = FALSE}
qdiff_no_NA <- function(x, probs = c(0, 1)) {
  the_quantiles <- quantile(x = x, probs = probs)
  max(the_quantiles) - min(the_quantiles)
}

test_that('NA handling works', {
  expect_that(qdiff_no_NA(c(1:5, NA)), equals(4))
})
```

Similar to the advice to use assertions in data analytical scripts, I recommend you use unit tests to monitor the behavior of functions you (or others) will use often. If your tests cover the function's important behavior, then you can edit the internals freely. You'll rest easy in the knowledge that, if you broke anything important, the tests will fail and alert you to the problem. A function that is important enough for unit tests probably also belongs in a package, where there are obvious mechanisms for running the tests as part of overall package checks.

### Practice with `map_*` functions and list columns

Let’s practice `map_*` functions and list columns! We will give step by step instructions; we recommend that you follow along so that you understand how each part works.  We'll also be introducing some important conditional functions (`ifelse()`, `any()`, `all()`, and `case_when()`).

a. Write a function called `roll_dice()`, which will throw a pair of dice as many times as the user specifies.

For clarity, we will begin by creating an intermediate function `add_dice()` which throws n dice and adds the results:

```{r add_dice}
add_dice <- function(n = 1) {
  stopifnot(is.numeric(n))
  sum(sample(1:6, n, replace = TRUE))
}
```

Next, we will create `roll_dice()`, which calls `add_dice(n = 2)` as many times as the user specifies:

```{r roll_dice}
roll_dice <- function(n = 1) {
  stopifnot(is.numeric(n))
  map_int(rep(2, n), add_dice)
}
```

`rep()` is a useful input to `map_*` when you want to call a function with the same input multiple times. `rep(2, n)` creates a vector of length n where every element is 2. We use that as the input to `map_int()` because we want the input to `add_dice()` to be 2 every time (we are always throwing a pair of dice) and we want to perform the operation n times, chosen by the user.

b. Create a tibble named `x` with one variable: `throws`. `throws` is a list column, each element of which is three throws of the dice pair, i.e., the result of calling `roll_dice(n = 3)`.  Thus, our tibble will have ten rows and two columns.

```{r throw_dice}
x <- tibble(throws = map(rep(3, 10), roll_dice))
```

c. Add a variable to `x` called `first_seven` which is TRUE if the first roll in `throws` is a 7.

```{r first_seven, message = FALSE}
library(magrittr)

# The magrittr package allows us to use %<>%, the compound assignment pipe
# operator, which (as its name suggests) both assigns and pipes

x %<>% 
  mutate(first_seven = map_lgl(throws, ~ ifelse(.[[1]] == 7, TRUE, FALSE)))
```

We see here that `[[1]]` is how we extract the first element of a list, just like `[1]` extracts the first element of an atomic vector.  `ifelse()` takes as its first argument a condition; if it is TRUE it returns the second argument (here TRUE) and if not the third (here FALSE).

d. Add a variable to `x` called `a_winner` which is TRUE if at least one of the three throws is a 7 or an 11 and is FALSE otherwise.

```{r a_winner}
x %<>% 
  mutate(a_winner = map_lgl(throws, ~ ifelse(any(c(7, 11) %in% .), TRUE, FALSE)))
```

Here we use `any()`: `any()` checks if any element in its input is TRUE. So, let's say a particular throw was 4, 6, and 7: `c(7, 11) %in% c(4, 6, 7)` returns the vector `TRUE FALSE` (since 7 is in the vector but 11 isn't); then, `any(c(7, 11) %in% c(4, 6, 7))` returns TRUE because one of the conditions is TRUE.

e. Run `str()` on `x` and show the results.

```{r str_x}
str(x)
```

f. Calculate how “surpised” you should be if someone rolls three winners in a row. First, create a tibble with 10,000 rows. Include a `throws` list column with three throws of our dice, just as in part a). Second, create a column called `perfection` which is TRUE if all three of the throws are either 7 or 11.

```{r surprised}
surprised <- tibble(throws = map(rep(3, 10000), roll_dice)) %>% 
  mutate(perfection = map_lgl(throws, ~ ifelse(all(. %in% c(7, 11)), TRUE, FALSE)))

surprised %>%
  pull(perfection) %>%
  mean()
```

Here, we use `all()`, which has the same structure as `any()`, but checks whether *all* the elements in the input are TRUE.

Approximately 1.1% of three rolls of a pair of fair dice are all equal to either 7 or 11.

g. Your friend proposes the following bet. You will roll a pair of fair dice 10 times. Side A gets the second highest of the first 4 rolls. Side B gets 1 plus the the median of the remaining 6 rolls. Which side is more likely to win?  What's the chance of a tie?

```{r a_vs_b}
bet <- tibble(throws = map(rep(10, 10000), roll_dice)) %>% 
  mutate(A = map_dbl(throws, ~ sort(.[1:4])[3]),
         B = map_dbl(throws, ~ 1 + median(.[5:10])),
         winner = case_when(A > B ~ "A",
                            B > A ~ "B",
                            TRUE ~ "tie"))

case_when(sum(bet$winner == "A") > sum(bet$winner == "B") ~ "A",
          sum(bet$winner == "B") > sum(bet$winner == "A") ~ "B",
          TRUE ~ "Same # Victories")

sum(bet$winner == "tie")/length(bet$winner)
```

You can think of `case_when()` as a generalized `ifelse()`.  The syntax is a little more complicated.  Each expression is followed by `~` and what should be returned if that expression is TRUE.  The final expression, TRUE, is always true, and thus is the residual category if none of the above expression are TRUE.  Thus, the second `case_when()` in our above code will print "A" if A is the winner in more replications than B, "B" if B is the winner more than A, and "Same # Victories" otherwise.

Side B is more likely to win.

The chance of a tie is approximately 11%.
