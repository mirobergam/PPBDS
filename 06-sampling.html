<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="" />
<meta property="og:type" content="book" />







<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="">

<title></title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



</head>

<body>




<!--bookdown:toc:start-->
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title"><p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="#sampling"><span class="toc-section-number">1</span> Sampling</a>
</div>
</li>
</ul>
</div>
<!--bookdown:toc:end-->

<!--bookdown:body:start-->
<div id="sampling" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Sampling</h1>
<!-- Priorities: -->
<!-- 1) Remove library(moderndive) and anything which depends in it. This may require creating our own copy of some of its built in datasets, or replacing them. Example: the code uses `tactile_prop_red` a dataset in **moderndive**. So, create, on the fly, a similar looking data set and just use that. (Hint: IN your own code chunk, use the include=FALSE code chunk option.) -->
<!-- 2) Remove library(infer). This means that we need to replace `rep_sample_n()`. Chapters 7 and later use `rsample::bootstraps()` in its place. Here is a [nice example](https://juliasilge.com/blog/beer-production/) of how to use it and [this excellent introduction](https://afit-r.github.io/bootstrapping). Should we do that here? Or perhaps we just have three (?) lines of R code which do what `rep_sample_n()` use to do? Take a look at the current version of chapter 7 for one approach. -->
<!-- 3) Read the current versions of 05-probability.Rmd. This is tricky and important stuff. The below comments only make sense with that background knowledge. The biggest changes involving connecting the current chapter to that chapter and, to a lesser extent, to the Rubin Causal Model chapter. Not really RCM, but still a Rubin Table. *missing data*. -->
<!-- Add in Bayesian! -->
<!-- m&m example? Is it useful to imagine an urn where, instead of two colors, an income is written on the bead? -->
<!-- 4) *Bias* is important, connect to chapter 3 discussion. Sampling goes wrong all the time. People underestimate the true uncertainty in the world.  -->
<!--5) *Censoring*: Problem with your tape measure. -->
<!-- Key issues for summer 2020. -->
<!-- 1) We need to provide a Bayes scatterplot which is the next step in complexity from the ones we finished with in chapter 5. The x-axis is the number of red beads pulled in the sample, a number which varies from 0 to 25. (And we can discuss how different paddles would lead to different displays.) The y-axis is the model.  -->
<!-- 2) One new complexity with the notion of the "model" is that we can "parameterize" the same thing in different ways. We want to show that. First, we parameterize it in the same way as chapter 5. There is a p, which can have certain values, but we restrict the set of possible values. Although perhaps making it different from previously. Maybe 0 to 1 by 0.05, so 21 values. Then we do the same thing as before, look at one sample from the urn, look at the marginal distribution, posterior predict the outcomes of the next draw, and so on. Just like before. -->
<!-- 3) We might make the transition from this case to the next by noting two things:  First, even though we often assume that p is continuous, it never really is. In this case, since we are told that there are 2400 beads, p can only take on 2401 possible values. Second, we can (sort of!) use some prior knowledge by noting that values near p = 0 and p = 1 are impossible. Just look at the urn! It is wasteful to even consider those possibilities in doing our analysis. Better to consider more values of p in a more plausible range. -->
<!-- 4) Our second parameterization might, instead of looking at p, look at specific values of the number of red beans (out of 2400), chosen from near where we thing the truth might be. These are now the numbers of the y-axis. Note how this elides the distinction between a "model" and the "data". (Keep in mind that the data in the x-axis the data we gathered in our experiment.) The data of the number of red beads in the urn is an empirical reality of the world, something independent of us and our experiment. "Model" just means "Assumption about the world." Same steps afterward as above, although maybe more precise, since we have narrowed our search. -->
<!-- 5) At this stage, we could get into a variety of issues like: How do things look with different shovel sizes? How do we handle the case of taking two or more samples? And so on. Do those belong in the book, or in a class exercise or in a problem set? Not sure! -->
<!-- 6) Not too early to get into the topic of looking at the effectiveness (?) of different procedures in terms how well they work. How good a job does this approach do in terms of predicting the future? If you were betting, how well would you do? Would you win the prediction game?  -->
<!-- 7) No need, yet, to look for R functions for doing things. For now, we continue to do things by hand, interpreting our posterior estimate like a good Bayesian. -->
<!-- 8) We also need to do something with Rubin Causal Model, specifically the sampling discussion and everything is a missing data problem.  -->
<!-- Need to incorporate some notion of betting. The over/under line for percentage of red balls in the bowl. Can you show (maybe a problem set?) that the mean is the best place to put the over/under line? Play the prediction game.  -->
<!-- Can we incorporate some notion of uncertainty, even before we see the bootstrap in the next chapter? And, along with that notion of uncertainty, discuss a Bayesian interpretation. -->
<!-- Without what range would you offer 50/50 odds that the true percentage lies? -->
<!-- Revisit Albert's functions. Is it OK that urn is just treated as a global variable? Or should it be passed in as an argument. Also, are two functions really necessary? -->
<!-- A big point of confusion is the difference between random sampling and random assignment. So, explain in a paragraph.  -->
<!-- Would be great to have a concrete example of how biased sampling can be, like all the red beads at the bottom. Maybe just a picture and discussion? -->
<!-- Discuss hypothesis tests and why we hate them. See style.Rmd for details. -->
<!-- Every problem has a Rubin Table highlighting what God would know, what we know, and then how we form a pdf about what we don't know. (Read chapter 3 for background.) This is even so with sampling! Until we sample a bead, it is a "?". Then, it resolves to red/white. After drawing our sample, we make inferences about the other beads. In one sense, we are inferring the value of p. In another, we are guessing what each of the "?" is, at least in expectation. But we can then also capture uncertainty! Each bead might be red or white, regardless of p. And there is uncertainty about p as well. This is the first time we are seeing both model uncertainty --- what is p? --- and predictive uncertainty --- what color is the next bead? -->
<!-- Also interesting to think about tables which we know are finite but we don't ever know how many rows, like number of living people in US right now (i.e., includes planes landing? someone whose heart has stopped beating but has not been "pronounced" dead?)  -->
<!-- Might also use Topic 16 from the Workshop here, or save it for the next chapter. -->
<p>Sampling is the beginning of our journey toward inference.</p>
<div id="needed-packages" class="section level3 unnumbered">
<h3>Needed packages</h3>
<p>Let's load all the packages needed for this chapter (this assumes you've already installed them). Recall from our discussion in Section <a href="#tidyverse-package"><strong>??</strong></a> that loading the <strong>tidyverse</strong> package by running <code>library(tidyverse)</code> loads the following commonly used data science packages all at once:</p>
<ul>
<li><strong>ggplot2</strong> for data visualization</li>
<li><strong>dplyr</strong> for data wrangling</li>
<li><strong>tidyr</strong> for converting data to &quot;tidy&quot; format</li>
<li><strong>readr</strong> for importing spreadsheet data into R</li>
<li>As well as the more advanced <strong>purrr</strong>, <strong>tibble</strong>, <strong>stringr</strong>, and <strong>forcats</strong> packages</li>
</ul>
<p>If needed, read Section <a href="#packages"><strong>??</strong></a> for information on how to install and load R packages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)</code></pre></div>
</div>
</div>
<div id="sampling-activity" class="section level2">
<h2><span class="header-section-number">1.1</span> Sampling urn activity</h2>
<p>Let's start with a hands-on activity.</p>
<div id="what-proportion-of-this-urns-balls-are-red" class="section level3">
<h3><span class="header-section-number">1.1.1</span> What proportion of this urn's balls are red?</h3>
<p>Take a look at the urn in Figure <a href="#fig:sampling-exercise-1">1.1</a>. It has a certain number of red and a certain number of white balls all of equal size. Furthermore, it appears the urn has been mixed beforehand, as there does not seem to be any coherent pattern to the spatial distribution of the red and white balls.</p>
<p>Let's now ask ourselves, what proportion of this urn's balls are red?</p>
<!-- What is the best approach to R code chunks for images in the book? What is "purl" doing? Why out.width set to 95%? Need to understand this better and standardize it. -->
<div class="figure"><span id="fig:sampling-exercise-1"></span>
<p class="caption marginnote shownote">
FIGURE 1.1: An urn with red and white balls.
</p>
<img src="06-sampling/images/sampling_bowl_1.jpg" alt="An urn with red and white balls." width="95%"  />
</div>
<p>One way to answer this question would be to perform an exhaustive count: remove each ball individually, count the number of red balls and the number of white balls, and divide the number of red balls by the total number of balls. However, this would be a long and tedious process.</p>
</div>
<div id="using-the-shovel-once" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Using the shovel once</h3>
<p>Instead of performing an exhaustive count, let's insert a shovel into the urn as seen in Figure <a href="#fig:sampling-exercise-2">1.2</a>. Using the shovel, let's remove <span class="math inline">\(5 \cdot 10 = 50\)</span> balls, as seen in Figure <a href="#fig:sampling-exercise-3">1.3</a>.</p>
<div class="figure"><span id="fig:sampling-exercise-2"></span>
<p class="caption marginnote shownote">
FIGURE 1.2: Inserting a shovel into the urn.
</p>
<img src="06-sampling/images/sampling_bowl_2.jpg" alt="Inserting a shovel into the urn." width="100%"  />
</div>
<div class="figure"><span id="fig:sampling-exercise-3"></span>
<p class="caption marginnote shownote">
FIGURE 1.3: Removing 50 balls from the urn.
</p>
<img src="06-sampling/images/sampling_bowl_3_cropped.jpg" alt="Removing 50 balls from the urn." width="100%"  />
</div>
<p>Observe that 17 of the balls are red and thus 17/50 = 0.34 = 34% of the shovel's balls are red. We can view the proportion of balls that are red in this shovel as a guess of the proportion of balls that are red in the entire urn. While not as exact as doing an exhaustive count of all the balls in the urn, our guess of 34% took much less time and energy to make.</p>
<p>However, say, we started this activity over from the beginning. In other words, we replace the 50 balls back into the urn and start over. Would we remove exactly 17 red balls again? In other words, would our guess at the proportion of the urn's balls that are red be exactly 34% again? Maybe?</p>
<p>What if we repeated this activity several times following the process shown in Figure <a href="#fig:sampling-exercise-3b">1.4</a>? Would we obtain exactly 17 red balls each time? In other words, would our guess at the proportion of the urn's balls that are red be exactly 34% every time? Surely not. Let's repeat this exercise several times with the help of 33 groups of friends to understand how the value differs with repetition.</p>
</div>
<div id="student-shovels" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Using the shovel 33 times</h3>
<!-- Create this dataset on my own. Approximately the same is fine. -->
<p>Each of our 33 groups of friends will do the following:</p>
<ul>
<li>Use the shovel to remove 50 balls each.</li>
<li>Count the number of red balls and thus compute the proportion of the 50 balls that are red.</li>
<li>Return the balls into the urn.</li>
<li>Mix the contents of the urn a little to not let a previous group's results influence the next group's.</li>
</ul>
<div class="figure"><span id="fig:sampling-exercise-3b"></span>
<p class="caption marginnote shownote">
FIGURE 1.4: Repeating sampling activity 33 times.
</p>
<img src="06-sampling/images/tactile_2_a.jpg" alt="Repeating sampling activity 33 times." width="30%"  /><img src="06-sampling/images/tactile_2_b.jpg" alt="Repeating sampling activity 33 times." width="30%"  /><img src="06-sampling/images/tactile_2_c.jpg" alt="Repeating sampling activity 33 times." width="30%"  />
</div>
<p>Each of our 33 groups of friends make note of their proportion of red balls from their sample collected. Each group then marks their proportion of their 50 balls that were red in the appropriate bin in a hand-drawn histogram as seen in Figure <a href="#fig:sampling-exercise-4">1.5</a>.</p>
<div class="figure"><span id="fig:sampling-exercise-4"></span>
<p class="caption marginnote shownote">
FIGURE 1.5: Constructing a histogram of proportions.
</p>
<img src="06-sampling/images/tactile_3_a.jpg" alt="Constructing a histogram of proportions." width="80%"  />
</div>
<p>Recall from Section <a href="#histograms"><strong>??</strong></a> that histograms allow us to visualize the <em>distribution</em>  of a numerical variable. In particular, where the center of the values falls and how the values vary. A partially completed histogram of the first 10 out of 33 groups of friends' results can be seen in Figure <a href="#fig:sampling-exercise-5">1.6</a>.</p>
<div class="figure"><span id="fig:sampling-exercise-5"></span>
<p class="caption marginnote shownote">
FIGURE 1.6: Hand-drawn histogram of first 10 out of 33 proportions.
</p>
<img src="06-sampling/images/tactile_3_c.jpg" alt="Hand-drawn histogram of first 10 out of 33 proportions." width="70%"  />
</div>
<p>Observe the following in the histogram in Figure <a href="#fig:sampling-exercise-5">1.6</a>:</p>
<ul>
<li>At the low end, one group removed 50 balls from the urn with proportion red between 0.20 and 0.25.</li>
<li>At the high end, another group removed 50 balls from the urn with proportion between 0.45 and 0.5 red.</li>
<li>However, the most frequently occurring proportions were between 0.30 and 0.35 red, right in the middle of the distribution.</li>
<li>The shape of this distribution is somewhat bell-shaped.</li>
</ul>
<p>Let's construct this same hand-drawn histogram in R using your data visualization skills that you honed in Chapter <a href="#viz"><strong>??</strong></a>. The 33 groups of friends' results are saved in the <code>tactile_prop_red</code> data frame included in the <strong>moderndive</strong> package. Run the following to display the first 10 of 33 rows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(moderndive)

tactile_prop_red</code></pre></div>
<pre><code>## # A tibble: 33 x 4
##    group            replicate red_balls prop_red
##    &lt;chr&gt;                &lt;int&gt;     &lt;int&gt;    &lt;dbl&gt;
##  1 Ilyas, Yohan             1        21     0.42
##  2 Morgan, Terrance         2        17     0.34
##  3 Martin, Thomas           3        21     0.42
##  4 Clark, Frank             4        21     0.42
##  5 Riddhi, Karina           5        18     0.36
##  6 Andrew, Tyler            6        19     0.38
##  7 Julia                    7        19     0.38
##  8 Rachel, Lauren           8        11     0.22
##  9 Daniel, Caroline         9        15     0.3 
## 10 Josh, Maeve             10        17     0.34
## # … with 23 more rows</code></pre>
<p>Observe for each <code>group</code> that we have their names, the number of <code>red_balls</code> they obtained, and the corresponding proportion out of 50 balls that were red named <code>prop_red</code>. We also have a <code>replicate</code> variable enumerating each of the 33 groups. We chose this name because each row can be viewed as one instance of a replicated (in other words repeated) activity: using the shovel to remove 50 balls and computing the proportion of those balls that are red.</p>
<p>Let's visualize the distribution of these 33 proportions using <code>geom_histogram()</code> with <code>binwidth = 0.05</code> in Figure <a href="#fig:samplingdistribution-tactile">1.7</a>. This is a computerized and complete version of the partially completed hand-drawn histogram you saw in Figure <a href="#fig:sampling-exercise-5">1.6</a>. Note that setting <code>boundary = 0.4</code> indicates that we want a binning scheme such that one of the bins' boundary is at 0.4. This helps us to more closely align this histogram with the hand-drawn histogram in Figure <a href="#fig:sampling-exercise-5">1.6</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tactile_prop_red <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Distribution of 33 proportions red&quot;</span>) </code></pre></div>
<div class="figure"><span id="fig:samplingdistribution-tactile"></span>
<p class="caption marginnote shownote">
FIGURE 1.7: Distribution of 33 proportions based on 33 samples of size 50.
</p>
<img src="06-sampling_files/figure-html/samplingdistribution-tactile-1.png" alt="Distribution of 33 proportions based on 33 samples of size 50." width="672"  />
</div>
</div>
<div id="what-did-we-just-do" class="section level3">
<h3><span class="header-section-number">1.1.4</span> What did we just do?</h3>
<p>What we just demonstrated in this activity is the statistical concept of  <em>sampling</em>. We would like to know the proportion of the urn's balls that are red. Because the urn has a large number of balls, performing an exhaustive count of the red and white balls would be time-consuming. We thus extracted a <em>sample</em> of 50 balls using the shovel to make an <em>estimate</em>. Using this sample of 50 balls, we estimated the proportion of the <em>urn's</em> balls that are red to be 34%.</p>
<p>Moreover, because we mixed the balls before each use of the shovel, the samples were randomly drawn. Because each sample was drawn at random, the samples were different from each other. Because the samples were different from each other, we obtained the different proportions red observed in Figure <a href="#fig:samplingdistribution-tactile">1.7</a>. This is known as the concept of <em>sampling variation</em>. </p>
<p>The purpose of this sampling activity is to develop an understanding of two key concepts relating to sampling:</p>
<ol style="list-style-type: decimal">
<li>Understanding the effect of sampling variation.</li>
<li>Understanding the effect of sample size on sampling variation.</li>
</ol>
<p>In Section <a href="#sampling-simulation">1.2</a>, we'll mimic the hands-on sampling activity we just performed on a computer. This will allow us not only to repeat the sampling exercise much more than 33 times, but it will also allow us to use shovels with different numbers of slots than just 50.</p>
<p>Afterwards, we'll present you with definitions, terminology, and notation related to sampling in Section <a href="#sampling-framework">1.3</a>. As in many disciplines, such necessary background knowledge may seem inaccessible and even confusing at first. However, as with many difficult topics, if you truly understand the underlying concepts and practice, practice, practice, you'll be able to master them.</p>
<p>To tie the contents of this chapter to the real world, we'll present an example of one of the most recognizable uses of sampling: polls. In Section <a href="#sampling-case-study">1.4</a> we'll look at a particular case study: a 2013 poll on then U.S. President Barack Obama's popularity among young Americans, conducted by Kennedy School's Institute of Politics at Harvard University. To close this chapter, we'll generalize the &quot;sampling from a urn&quot; exercise to other sampling scenarios and present a theoretical result known as the <em>Central Limit Theorem</em>.</p>
</div>
</div>
<div id="sampling-simulation" class="section level2">
<h2><span class="header-section-number">1.2</span> Virtual sampling</h2>
<p>In the previous Section <a href="#sampling-activity">1.1</a>, we performed a <em>tactile</em> sampling activity by hand. In other words, we used a physical urn of balls and a physical shovel. We performed this sampling activity by hand first so that we could develop a firm understanding of the root ideas behind sampling. In this section, we'll mimic this tactile sampling activity with a <em>virtual</em> sampling activity using a computer. In other words, we'll use a virtual analog to the urn of balls and a virtual analog to the shovel.</p>
<div id="using-the-virtual-shovel-once" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Using the virtual shovel once</h3>
<p>Let's start by performing the virtual analog of the tactile sampling exercise we performed in Section <a href="#sampling-activity">1.1</a>. We first need a virtual analog of the urn seen in Figure <a href="#fig:sampling-exercise-1">1.1</a>. To this end, we creat a data frame named <code>urn</code>. The rows of <code>urn</code> correspond exactly with the contents of the actual urn.</p>
<!-- Per the style guide, these comments will need to be removed from the code chunk and explained in the paragraph above. -->
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># sample_frac() just re-arranges the rows of the tibble. We use set.seed() to</span>
<span class="co"># ensure that the beads in the urn are always in the same order. This ensures</span>
<span class="co"># that figures in the book match their written descriptions.</span>

<span class="kw">set.seed</span>(<span class="dv">9</span>)

urn &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">color =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;red&quot;</span>, <span class="dv">900</span>), <span class="kw">rep</span>(<span class="st">&quot;white&quot;</span>, <span class="dv">1500</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_frac</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ball_ID =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2400</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(ball_ID, color)

urn  </code></pre></div>
<pre><code>## # A tibble: 2,400 x 2
##    ball_ID color
##      &lt;int&gt; &lt;chr&gt;
##  1       1 white
##  2       2 white
##  3       3 white
##  4       4 white
##  5       5 red  
##  6       6 red  
##  7       7 white
##  8       8 red  
##  9       9 red  
## 10      10 red  
## # … with 2,390 more rows</code></pre>
<p>Observe that <code>urn</code> has 2400 rows, telling us that the urn contains 2400 equally sized balls. The first variable <code>ball_ID</code> is used as an <em>identification variable</em> as discussed in Subsection <a href="#identification-vs-measurement-variables"><strong>??</strong></a>; none of the balls in the actual urn are marked with numbers. The second variable <code>color</code> indicates whether a particular virtual ball is red or white. View the contents of the urn in RStudio's data viewer and scroll through the contents to convince yourself that <code>urn</code> is indeed a virtual analog of the actual urn in Figure <a href="#fig:sampling-exercise-1">1.1</a>.</p>
<p>Now that we have a virtual analog of our urn, we now need a virtual analog to the shovel seen in Figure <a href="#fig:sampling-exercise-2">1.2</a> to generate virtual samples of 50 balls. We're going to use the <code>rep_sample_n()</code> function included in the <strong>infer</strong> package. This function allows us to take <code>rep</code>eated, or <code>rep</code>licated, <code>samples</code> of size <code>n</code>.</p>
<p>Let's show an example of this function in action. Let's first use the <code>tibble()</code> function to manually create a data frame of five fruit called <code>fruit_basket</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fruit_basket &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">fruit =</span> <span class="kw">c</span>(<span class="st">&quot;Mango&quot;</span>, <span class="st">&quot;Tangerine&quot;</span>, <span class="st">&quot;Apricot&quot;</span>, <span class="st">&quot;Pamplemousse&quot;</span>, <span class="st">&quot;Lime&quot;</span>)
)</code></pre></div>
<p>We'll then <code>%&gt;%</code> pipe the <code>fruit_basket</code> data frame into the <code>rep_sample_n()</code> function and set <code>size = 3</code>, indicating that we want to sample three fruit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fruit_basket <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>## # A tibble: 3 x 2
## # Groups:   replicate [1]
##   replicate fruit       
##       &lt;int&gt; &lt;chr&gt;       
## 1         1 Lime        
## 2         1 Mango       
## 3         1 Pamplemousse</code></pre>
<p>Your results will likely be different, since we are taking a <em>random</em> sample of size 3. Now let's see what happens when we try to sample six fruit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fruit_basket <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">6</span>)</code></pre></div>
<pre><code>Error in sample.int(n, size, replace = replace, prob = prob) : 
  cannot take a sample larger than the population when &#39;replace = FALSE&#39;</code></pre>
<p>We get an error message telling us that we cannot take a sample that has more rows than the original data frame. This is because <code>rep_sample_n()</code> by defaults samples <em>without replacement</em>. Once it samples a fruit from the basket, it does not put it back in.</p>
<!-- Is this section on rep_sample_n() and replacement irrelevant once we remove the infer package? -->
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(infer)

virtual_shovel &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)
virtual_shovel</code></pre></div>
<pre><code>## # A tibble: 50 x 3
## # Groups:   replicate [1]
##    replicate ball_ID color
##        &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
##  1         1    1152 white
##  2         1     716 white
##  3         1     667 red  
##  4         1     773 red  
##  5         1      91 white
##  6         1     896 red  
##  7         1    2104 white
##  8         1    2276 white
##  9         1     410 white
## 10         1     832 white
## # … with 40 more rows</code></pre>
<p>Observe that <code>virtual_shovel</code> has 50 rows corresponding to our virtual sample of size 50. The <code>ball_ID</code> variable identifies which of the 2400 balls from <code>urn</code> are included in our sample of 50 balls while <code>color</code> denotes its color. However, what does the <code>replicate</code> variable indicate? In <code>virtual_shovel</code>'s case, <code>replicate</code> is equal to 1 for all 50 rows. This is telling us that these 50 rows correspond to the first repeated/replicated use of the shovel, in our case our first sample. We'll see shortly that when we &quot;virtually&quot; take 33 samples, <code>replicate</code> will take values between 1 and 33.</p>
<p>Let's compute the proportion of balls in our virtual sample that are red using the <strong>dplyr</strong> data wrangling verbs you learned in Chapter <a href="#wrangling"><strong>??</strong></a>. First, for each of our 50 sampled balls, let's identify if it is red or not using a test for equality with <code>==</code>. Let's create a new Boolean variable <code>is_red</code> using the <code>mutate()</code> function from Section <a href="#mutate"><strong>??</strong></a>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> (color <span class="op">==</span><span class="st"> &quot;red&quot;</span>))</code></pre></div>
<pre><code>## # A tibble: 50 x 4
## # Groups:   replicate [1]
##    replicate ball_ID color is_red
##        &lt;int&gt;   &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; 
##  1         1    1152 white FALSE 
##  2         1     716 white FALSE 
##  3         1     667 red   TRUE  
##  4         1     773 red   TRUE  
##  5         1      91 white FALSE 
##  6         1     896 red   TRUE  
##  7         1    2104 white FALSE 
##  8         1    2276 white FALSE 
##  9         1     410 white FALSE 
## 10         1     832 white FALSE 
## # … with 40 more rows</code></pre>
<p>Observe that for every row where <code>color == &quot;red&quot;</code>, the Boolean (logical) value <code>TRUE</code> is returned and for every row where <code>color</code> is not equal to <code>&quot;red&quot;</code>, the Boolean <code>FALSE</code> is returned.</p>
<p>Second, let's compute the number of balls out of 50 that are red using the <code>summarize()</code> function. Recall from Section <a href="#summarize"><strong>??</strong></a> that <code>summarize()</code> takes a data frame with many rows and returns a data frame with a single row containing summary statistics, like the <code>mean()</code> or <code>median()</code>. In this case, we use the <code>sum()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> (color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(is_red))</code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   replicate num_red
##       &lt;int&gt;   &lt;int&gt;
## 1         1      13</code></pre>
<p>Why does this work? Because R treats <code>TRUE</code> like the number <code>1</code> and <code>FALSE</code> like the number <code>0</code>. So summing the number of <code>TRUE</code>s and <code>FALSE</code>s is equivalent to summing <code>1</code>'s and <code>0</code>'s. In the end, this operation counts the number of balls where <code>color</code> is <code>red</code>. In our case, 13 of the 50 balls were red. However, you might have gotten a different number red because of the randomness of the virtual sampling.</p>
<p>Third and lastly, let's compute the proportion of the 50 sampled balls that are red by dividing <code>num_red</code> by 50:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> color <span class="op">==</span><span class="st"> &quot;red&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(is_red)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> num_red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate num_red prop_red
##       &lt;int&gt;   &lt;int&gt;    &lt;dbl&gt;
## 1         1      13     0.26</code></pre>
<p>In other words, 26% of this virtual sample's balls were red. Let's make this code a little more compact and succinct by combining the first <code>mutate()</code> and the <code>summarize()</code> as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> num_red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate num_red prop_red
##       &lt;int&gt;   &lt;int&gt;    &lt;dbl&gt;
## 1         1      13     0.26</code></pre>
<p>Great! 26% of <code>virtual_shovel</code>'s 50 balls were red! So based on this particular sample of 50 balls, our guess at the proportion of the <code>urn</code>'s balls that are red is 26%. But remember from our earlier tactile sampling activity that if we repeat this sampling, we will not necessarily obtain the same value of 26% again. There will likely be some variation. In fact, our 33 groups of friends computed 33 such proportions whose distribution we visualized in Figure <a href="#fig:sampling-exercise-5">1.6</a>. We saw that these estimates <em>varied</em>. Let's now perform the virtual analog of having 33 groups of students use the sampling shovel!</p>
</div>
<div id="using-the-virtual-shovel-33-times" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Using the virtual shovel 33 times</h3>
<p>Recall that in our tactile sampling exercise in Section <a href="#sampling-activity">1.1</a>, we had 33 groups of students each use the shovel, yielding 33 samples of size 50 balls. We then used these 33 samples to compute 33 proportions. In other words, we repeated/replicated using the shovel 33 times. We can perform this repeated/replicated sampling virtually by once again using our virtual shovel function <code>rep_sample_n()</code>, but by adding the <code>reps = 33</code> argument. This is telling R that we want to repeat the sampling 33 times.</p>
<p>We'll save these results in a data frame called <code>virtual_samples</code>. While we provide a preview of the first 10 rows of <code>virtual_samples</code> in what follows, we highly suggest you scroll through its contents using RStudio's spreadsheet viewer by running <code>View(virtual_samples)</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_samples &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">33</span>)
virtual_samples</code></pre></div>
<pre><code>## # A tibble: 1,650 x 3
## # Groups:   replicate [33]
##    replicate ball_ID color
##        &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
##  1         1    2143 white
##  2         1    2347 white
##  3         1    2005 white
##  4         1    1912 white
##  5         1    1068 white
##  6         1    2322 red  
##  7         1    1241 white
##  8         1     676 white
##  9         1    2007 red  
## 10         1    1698 red  
## # … with 1,640 more rows</code></pre>
<p>Observe in the spreadsheet viewer that the first 50 rows of <code>replicate</code> are equal to <code>1</code> while the next 50 rows of <code>replicate</code> are equal to <code>2</code>. This is telling us that the first 50 rows correspond to the first sample of 50 balls while the next 50 rows correspond to the second sample of 50 balls. This pattern continues for all <code>reps = 33</code> replicates and thus <code>virtual_samples</code> has 33 <span class="math inline">\(\cdot\)</span> 50 = 1650 rows.</p>
<p>Let's now take <code>virtual_samples</code> and compute the resulting 33 proportions red. We'll use the same <strong>dplyr</strong> verbs as before, but this time with an additional <code>group_by()</code> of the <code>replicate</code> variable. Recall from Section <a href="#groupby"><strong>??</strong></a> that by assigning the grouping variable &quot;meta-data&quot; before we <code>summarize()</code>, we'll obtain 33 different proportions red. We display a preview of the first 10 out of 33 rows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_prop_red &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)
virtual_prop_red</code></pre></div>
<pre><code>## # A tibble: 33 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    16     0.32
##  2         2    22     0.44
##  3         3    18     0.36
##  4         4    18     0.36
##  5         5    14     0.28
##  6         6    15     0.3 
##  7         7    26     0.52
##  8         8    23     0.46
##  9         9    21     0.42
## 10        10    18     0.36
## # … with 23 more rows</code></pre>
<p>As with our 33 groups of friends' tactile samples, there is variation in the resulting 33 virtual proportions red. Let's visualize this variation in a histogram in Figure <a href="#fig:samplingdistribution-virtual">1.8</a>. Note that we add <code>binwidth = 0.05</code> and <code>boundary = 0.4</code> arguments as well. Recall that setting <code>boundary = 0.4</code> ensures a binning scheme with one of the bins' boundaries at 0.4. Since the <code>binwidth = 0.05</code> is also set, this will create bins with boundaries at 0.30, 0.35, 0.45, 0.5, etc. as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(virtual_prop_red, <span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Distribution of 33 proportions red&quot;</span>) </code></pre></div>
<div class="figure"><span id="fig:samplingdistribution-virtual"></span>
<p class="caption marginnote shownote">
FIGURE 1.8: Distribution of 33 proportions based on 33 samples of size 50.
</p>
<img src="06-sampling_files/figure-html/samplingdistribution-virtual-1.png" alt="Distribution of 33 proportions based on 33 samples of size 50." width="672"  />
</div>
<p>Observe that we occasionally obtained proportions red that are less than 30%. On the other hand, we occasionally obtained proportions that are greater than 45%. However, the most frequently occurring proportions were between 35% and 40% (for 11 out of 33 samples). Why do we have these differences in proportions red? Because of <em>sampling variation</em>.</p>
<p>Let's now compare our virtual results with our tactile results from the previous section in Figure <a href="#fig:tactile-vs-virtual">1.9</a>. Observe that both histograms are somewhat similar in their center and variation, although not identical. These slight differences are again due to random sampling variation. Furthermore, observe that both distributions are somewhat bell-shaped.</p>
<div class="figure"><span id="fig:tactile-vs-virtual"></span>
<p class="caption marginnote shownote">
FIGURE 1.9: Comparing 33 virtual and 33 tactile proportions red.
</p>
<img src="06-sampling_files/figure-html/tactile-vs-virtual-1.png" alt="Comparing 33 virtual and 33 tactile proportions red." width="672"  />
</div>
</div>
<div id="shovel-1000-times" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Using the virtual shovel 1,000 times</h3>
<p>Now say we want to study the effects of sampling variation not for 33 samples, but rather for a larger number of samples, say 1,000. We have two choices at this point. We could have our groups of friends manually take 1,000 samples of 50 balls and compute the corresponding 1,000 proportions. However, this would be a tedious and time-consuming task. This is where computers excel: automating long and repetitive tasks while performing them quite quickly. Thus, at this point we will abandon tactile sampling in favor of only virtual sampling. Let's once again use the <code>rep_sample_n()</code> function with sample <code>size</code> set to be 50 once again, but this time with the number of replicates <code>reps</code> set to <code>1000</code>. Be sure to scroll through the contents of <code>virtual_samples</code> in RStudio's viewer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_samples &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)
virtual_samples</code></pre></div>
<pre><code>## # A tibble: 50,000 x 3
## # Groups:   replicate [1,000]
##    replicate ball_ID color
##        &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
##  1         1     824 white
##  2         1    1906 red  
##  3         1     344 white
##  4         1    1598 red  
##  5         1    1869 white
##  6         1     934 red  
##  7         1      39 red  
##  8         1     696 white
##  9         1      13 white
## 10         1     747 white
## # … with 49,990 more rows</code></pre>
<p>Observe that now <code>virtual_samples</code> has 1,000 <span class="math inline">\(\cdot\)</span> 50 = 50,000 rows, instead of the 33 <span class="math inline">\(\cdot\)</span> 50 = 1650 rows from earlier. Using the same data wrangling code as earlier, let's take the data frame <code>virtual_samples</code> with 1,000 <span class="math inline">\(\cdot\)</span> 50 = 50,000 rows and compute the resulting 1,000 proportions of red balls.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_prop_red &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)
virtual_prop_red</code></pre></div>
<pre><code>## # A tibble: 1,000 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    23     0.46
##  2         2    17     0.34
##  3         3    19     0.38
##  4         4    20     0.4 
##  5         5    16     0.32
##  6         6    19     0.38
##  7         7    21     0.42
##  8         8    17     0.34
##  9         9    18     0.36
## 10        10    22     0.44
## # … with 990 more rows</code></pre>
<p>Observe that we now have 1,000 replicates of <code>prop_red</code>, the proportion of 50 balls that are red. Using the same code as earlier, let's now visualize the distribution of these 1,000 replicates of <code>prop_red</code> in a histogram in Figure <a href="#fig:samplingdistribution-virtual-1000">1.10</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(virtual_prop_red, <span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, 
       <span class="dt">title =</span> <span class="st">&quot;Distribution of 1,000 proportions red&quot;</span>) </code></pre></div>
<div class="figure"><span id="fig:samplingdistribution-virtual-1000"></span>
<p class="caption marginnote shownote">
FIGURE 1.10: Distribution of 1,000 proportions based on 1,000 samples of size 50.
</p>
<img src="06-sampling_files/figure-html/samplingdistribution-virtual-1000-1.png" alt="Distribution of 1,000 proportions based on 1,000 samples of size 50." width="672"  />
</div>
<p>Once again, the most frequently occurring proportions of red balls occur between 35% and 40%. Every now and then, we obtain proportions as low as between 20% and 25%, and others as high as between 55% and 60%. These are rare, however. Furthermore, observe that we now have a much more symmetric and smoother bell-shaped distribution. This distribution is, in fact, approximated well by a normal distribution. At this point we recommend you read the &quot;Normal distribution&quot; section (Appendix <a href="#appendix-normal-curve"><strong>??</strong></a>) for a brief discussion on the properties of the normal distribution.</p>
<!-- Gambling might flow naturally here. -->
</div>
<div id="different-shovels" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Using different shovels</h3>
<p>Now say instead of just one shovel, you have three choices of shovels to extract a sample of balls with: shovels of size 25, 50, and 100.</p>
<div class="figure" style="text-align: center"><span id="fig:three-shovels"></span>
<p class="caption marginnote shownote">
FIGURE 1.11: Three shovels to extract three different sample sizes.
</p>
<img src="06-sampling/images/three_shovels.png" alt="Three shovels to extract three different sample sizes." width="100%"  />
</div>
<p>If your goal is still to estimate the proportion of the urn's balls that are red, which shovel would you choose? In our experience, most people would choose the largest shovel with 100 slots because it would yield the &quot;best&quot; guess of the proportion of the urn's balls that are red. Let's define some criteria for &quot;best&quot; in this subsection.</p>
<p>Using our newly developed tools for virtual sampling, let's unpack the effect of having different sample sizes! In other words, let's use <code>rep_sample_n()</code> with <code>size</code> set to <code>25</code>, <code>50</code>, and <code>100</code>, respectively, while keeping the number of repeated/replicated samples at 1,000:</p>
<ol style="list-style-type: decimal">
<li>Virtually use the appropriate shovel to generate 1,000 samples with <code>size</code> balls.</li>
<li>Compute the resulting 1,000 replicates of the proportion of the shovel's balls that are red.</li>
<li>Visualize the distribution of these 1,000 proportions red using a histogram.</li>
</ol>
<p>Run each of the following code segments individually and then compare the three resulting histograms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Segment 1: sample size = 25 ------------------------------</span>
<span class="co"># 1.a) Virtually use shovel 1,000 times</span>

virtual_samples_<span class="dv">25</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)

<span class="co"># 1.b) Compute resulting 1,000 replicates of proportion red</span>

virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">25</span>)

<span class="co"># 1.c) Plot distribution via a histogram</span>

virtual_prop_red_<span class="dv">25</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 25 balls that were red&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;25&quot;</span>) 


<span class="co"># Segment 2: sample size = 50 ------------------------------</span>
<span class="co"># 2.a) Virtually use shovel 1,000 times</span>

virtual_samples_<span class="dv">50</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)

<span class="co"># 2.b) Compute resulting 1,000 replicates of proportion red</span>

virtual_prop_red_<span class="dv">50</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">50</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)

<span class="co"># 2.c) Plot distribution via a histogram</span>

virtual_prop_red_<span class="dv">50</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;50&quot;</span>)  


<span class="co"># Segment 3: sample size = 100 ------------------------------</span>
<span class="co"># 3.a) Virtually using shovel with 100 slots 1,000 times</span>

virtual_samples_<span class="dv">100</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">100</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)

<span class="co"># 3.b) Compute resulting 1,000 replicates of proportion red</span>

virtual_prop_red_<span class="dv">100</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">100</span>)

<span class="co"># 3.c) Plot distribution via a histogram</span>

virtual_prop_red_<span class="dv">100</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Proportion of 100 balls that were red&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;100&quot;</span>) </code></pre></div>
<p>For easy comparison, we present the three resulting histograms in a single row with matching x and y axes in Figure <a href="#fig:comparing-sampling-distributions">1.12</a>.</p>
<div class="figure"><span id="fig:comparing-sampling-distributions"></span>
<p class="caption marginnote shownote">
FIGURE 1.12: Comparing the distributions of proportion red for different sample sizes.
</p>
<img src="06-sampling_files/figure-html/comparing-sampling-distributions-1.png" alt="Comparing the distributions of proportion red for different sample sizes." width="672"  />
</div>
<p>Observe that as the sample size increases, the variation of the 1,000 replicates of the proportion of red decreases. In other words, as the sample size increases, there are fewer differences due to sampling variation and the distribution centers more tightly around the same value. Eyeballing Figure <a href="#fig:comparing-sampling-distributions">1.12</a>, all three histograms appear to center around roughly 40%.</p>
<!-- Though standard deviation is an important part of the shovel size difference, this section is already pretty long and might be fine without the next code chunk. -->
<p>We can be numerically explicit about the amount of variation in our three sets of 1,000 values of <code>prop_red</code> using the  <em>standard deviation</em>. A standard deviation is a summary statistic that measures the amount of variation within a numerical variable. For all three sample sizes, let's compute the standard deviation of the 1,000 proportions red by running the following data wrangling code that uses the <code>sd()</code> summary function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># n = 25</span>

virtual_prop_red_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red))

<span class="co"># n = 50</span>

virtual_prop_red_<span class="dv">50</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red))

<span class="co"># n = 100</span>

virtual_prop_red_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red))</code></pre></div>
<p>Let's compare these three measures of distributional variation in Table <a href="#tab:comparing-n">1.1</a>.</p>
<!-- I think the idea of "as the sample size goes up, variation goes down" is already clear without this next addition. -->
<table class="table" style="font-size: 16px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:comparing-n">TABLE 1.1: </span>Comparing standard deviations of proportions red for three different shovels
</caption>
<thead>
<tr>
<th style="text-align:right;">
Number of slots in shovel
</th>
<th style="text-align:right;">
Standard deviation of proportions red
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
0.096
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0.067
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
0.046
</td>
</tr>
</tbody>
</table>
<p>As we observed in Figure <a href="#fig:comparing-sampling-distributions">1.12</a>, as the sample size increases, the variation decreases. In other words, there is less variation in the 1,000 values of the proportion red. So as the sample size increases, our guesses at the true proportion of the urn's balls that are red get more precise.</p>
<!-- MF: This seems to indicate that the larger shovel is, as expected, the most precise. Maybe an additional paragraph explicitly stating which shovel size is best should be added here. -->
</div>
<div id="using-many-shovels-at-once" class="section level3">
<h3><span class="header-section-number">1.2.5</span> Using many shovels at once</h3>
<p>Note that in the last section, we ran more or less the same code three times, but with different sizes for our shovel (25, 50, and 100). Whenever you find yourself writing the same code three or more times, you should write a <em>function</em> that does the same thing. Let's look at the code that used a shovel of size 25 and calculated the proportion of balls that were red one more time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_samples_<span class="dv">25</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)

virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">25</span>)</code></pre></div>
<p>We will break this into two functions, one called <code>use_shovel()</code> which will use a shovel of the specified size, and another called <code>prop_red()</code> which will calculate the proportion of red for a shovel of the specified size.</p>
<p>First, let's create <code>use_shovel()</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">use_shovel &lt;-<span class="st"> </span><span class="cf">function</span>(x, size, reps) {
  x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> size, <span class="dt">reps =</span> reps)
}

<span class="kw">use_shovel</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre></div>
<pre><code>## # A tibble: 25,000 x 3
## # Groups:   replicate [1,000]
##    replicate ball_ID color
##        &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
##  1         1     241 white
##  2         1     663 white
##  3         1    1329 red  
##  4         1    1239 white
##  5         1    1803 white
##  6         1    1660 white
##  7         1    2335 red  
##  8         1    1735 white
##  9         1     158 white
## 10         1      40 red  
## # … with 24,990 more rows</code></pre>
<p>See that we now can create the object <code>virtual_samples_25</code> with the code <code>virtual_samples_25 &lt;- use_shovel(x = urn, size = 25, reps = 1000)</code>. This is far more succinct than our previous code, and it allows us to use a shovel of any size we'd like.</p>
<!-- MF: Why use two functions, rather than one? Given that functions aren't covered much prior to this chapter, it might be easier to interpret this section with one function and more clarification of how the function itself is working. -->
<p>Now, we can use our <code>use_shovel()</code> function to develop another function, <code>prop_red()</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prop_red &lt;-<span class="st"> </span><span class="cf">function</span>(x, size, reps) {
  <span class="kw">use_shovel</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> size, <span class="dt">reps =</span> reps) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span>size)
}

<span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre></div>
<pre><code>## # A tibble: 1,000 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    10     0.4 
##  2         2     9     0.36
##  3         3     9     0.36
##  4         4     9     0.36
##  5         5     6     0.24
##  6         6    10     0.4 
##  7         7     8     0.32
##  8         8     8     0.32
##  9         9     9     0.36
## 10        10    12     0.48
## # … with 990 more rows</code></pre>
<p>See how this just uses the code we had before to create <code>virtual_prop_red_25</code>, but generalizes it. Now we can create the same tibbles we did before, ready to plot the histograms, with only three lines of code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)
virtual_prop_red_<span class="dv">50</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)
virtual_prop_red_<span class="dv">100</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">100</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</code></pre></div>
<p>But this still isn't the best way. Note that we have three objects we need to deal with, <code>virtual_prop_red_25</code>, <code>virtual_prop_red_50</code>, and <code>virtual_prop_red_100</code>. Furthermore, we don't actually know that the names are accurate! Perhaps we made a mistake and created <code>virtual_prop_red_50</code> with the code <code>virtual_prop_red_50 &lt;- prop_red(25)</code>; our object name will now be misleading as to what's actually in the object.</p>
<!-- MF: Maybe a different introduction to storing in a tibble... -->
<p>Instead, let's store our results in a single tibble. How can we do this? By using <code>map()</code> to create a list column!</p>
<p>First, we'll create a tibble called <code>shovels</code> that will have a variable named <code>shovel_size</code> with our values (25, 50, 100):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shovels &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">shovel_size =</span> <span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>))</code></pre></div>
<p>Next, we'll create list columns called <code>use_shovel_results</code> and <code>prop_red_results</code> that are the outputs of <code>use_shovel()</code> and <code>prop_red</code>, respectively:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shovels &lt;-<span class="st"> </span>shovels <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">use_shovel_results =</span> <span class="kw">map</span>(shovel_size,
                                  <span class="op">~</span><span class="st"> </span><span class="kw">use_shovel</span>(<span class="dt">x =</span> urn,
                                               <span class="dt">size =</span> .x,
                                               <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_results =</span> <span class="kw">map</span>(shovel_size,
                                <span class="op">~</span><span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, 
                                           <span class="dt">size =</span> .x, 
                                           <span class="dt">reps =</span> <span class="dv">1000</span>)))

<span class="kw">glimpse</span>(shovels)</code></pre></div>
<pre><code>## Observations: 3
## Variables: 3
## $ shovel_size        &lt;dbl&gt; 25, 50, 100
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[25000 x 3]&gt;, &lt;grouped_df[50000 x 3]&gt;…
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…</code></pre>
<p>Adding another <code>map_*</code> function will let us get the standard deviations of our estimated proportions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shovels &lt;-<span class="st"> </span>shovels <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_sd =</span> <span class="kw">map_dbl</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()))

<span class="kw">glimpse</span>(shovels)</code></pre></div>
<pre><code>## Observations: 3
## Variables: 4
## $ shovel_size        &lt;dbl&gt; 25, 50, 100
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[25000 x 3]&gt;, &lt;grouped_df[50000 x 3]&gt;…
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…
## $ prop_red_sd        &lt;dbl&gt; 0.09942621, 0.06623292, 0.04560038</code></pre>
<p>But now that we have this framework, there's no need to limit ourselves to the sizes 25, 50, and 100. Why not try all integers from 1 to 100? We can use the same code, except we'll now set <code>shovel_size = 1:100</code> when initializing the tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shovels_<span class="dv">100</span> &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">shovel_size =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">use_shovel_results =</span> <span class="kw">map</span>(shovel_size,
                                  <span class="op">~</span><span class="st"> </span><span class="kw">use_shovel</span>(<span class="dt">x =</span> urn,
                                               <span class="dt">size =</span> .x,
                                               <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_results =</span> <span class="kw">map</span>(shovel_size,
                                <span class="op">~</span><span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, 
                                           <span class="dt">size =</span> .x, 
                                           <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_sd =</span> <span class="kw">map_dbl</span>(prop_red_results, 
                               <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()))


<span class="kw">glimpse</span>(shovels_<span class="dv">100</span>)</code></pre></div>
<pre><code>## Observations: 100
## Variables: 4
## $ shovel_size        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[1000 x 3]&gt;, &lt;grouped_df[2000 x 3]&gt;, …
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…
## $ prop_red_sd        &lt;dbl&gt; 0.48462239, 0.34354880, 0.28958394, 0.23754827, 0.…</code></pre>
<p>Now, we have the standard deviation of <code>prop_red</code> for all shovel sizes from 1 to 100. Let's plot that value to see how it changes as the shovel gets larger:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">shovels_<span class="dv">100</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> shovel_size, <span class="dt">y =</span> prop_red_sd)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Shovel size&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Standard deviation of the proportion red&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-32"></span>
<p class="caption marginnote shownote">
FIGURE 1.13: Comparing standard deviations of proportions red for 100 different shovels
</p>
<img src="06-sampling_files/figure-html/unnamed-chunk-32-1.png" alt="Comparing standard deviations of proportions red for 100 different shovels" width="672"  />
</div>
<p>This is interesting! You may recognize that the standard deviation of the proportion red is declining at a rate proportional to the square root of the shovel size. This is something you could have discovered by finding a formula in a statistics textbook, but it's easier to understand if you see it for yourself.</p>
<!-- MF: The square root of the shovel size comment might confuse readers. Is there a way to say this differently? Maybe in terms of exponential decrease? -->
<p>This is the power of running many analyses at once using <code>map_*</code> functions and list columns: before, we could tell that the standard deviation was decreasing as the shovel size increased, but when only looking at shovel sizes of 25, 50, and 100, it wasn't very clear <em>how quickly</em> it was decreasing.</p>
</div>
</div>
<div id="sampling-framework" class="section level2">
<h2><span class="header-section-number">1.3</span> Sampling framework</h2>
<p>In both our tactile and our virtual sampling activities, we used sampling for the purpose of estimation. We extracted samples in order to <em>estimate</em> the proportion of the urn's balls that are red. We used sampling as a less time-consuming approach than performing an exhaustive count of all the balls. Our virtual sampling activity built up to the results shown in Figure <a href="#fig:comparing-sampling-distributions">1.12</a> and Table <a href="#tab:comparing-n">1.1</a>: comparing 1,000 proportions red based on samples of size 25, 50, and 100, and finally expanding that to all the sizes between 1 and 100. This was our first attempt at understanding two key concepts relating to sampling for estimation:</p>
<ol style="list-style-type: decimal">
<li>The effect of <em>sampling variation</em> on our estimates.</li>
<li>The effect of sample size on <em>sampling variation</em>.</li>
</ol>
<p>Let's now introduce some terminology and notation as well as statistical definitions related to sampling. Given the number of new words you'll need to learn, you will likely have to read this section a few times. Keep in mind, however, that all of the concepts underlying these terminology, notation, and definitions tie directly to the concepts underlying our tactile and virtual sampling activities. It will simply take time and practice to master them.</p>
<div id="terminology-and-notation" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Terminology and notation</h3>
<p>Here is a list of terminology and mathematical notation relating to sampling.</p>
<p>First, a <strong>population</strong> is a collection of individuals or observations we are interested in. This is also commonly denoted as a <strong>study population</strong>. We mathematically denote the population's size using upper-case <span class="math inline">\(N\)</span>. In our sampling activities, the (study) population is the collection of <span class="math inline">\(N\)</span> = 2400 identically sized red and white balls contained in the urn.</p>
<p>Second, a <strong>population parameter</strong> is a numerical summary quantity about the population that is unknown, but you wish you knew. For example, when this quantity is a mean, the population parameter of interest is the <em>population mean</em>. This is mathematically denoted with the Greek letter <span class="math inline">\(\mu\)</span> pronounced &quot;mu&quot; (we'll see a sampling activity involving means in the upcoming Section <a href="#resampling-tactile"><strong>??</strong></a>). In our earlier sampling from the urn activity, however, since we were interested in the proportion of the urn's balls that were red, the population parameter is the <em>population proportion</em>. This is mathematically denoted with the letter <span class="math inline">\(p\)</span>.</p>
<p>Third, a <strong>census</strong> is an exhaustive enumeration or counting of all <span class="math inline">\(N\)</span> individuals or observations in the population in order to compute the population parameter's value <em>exactly</em>. In our sampling activity, this would correspond to counting the number of balls out of <span class="math inline">\(N\)</span> = 2400 that are red and computing the <em>population proportion</em> <span class="math inline">\(p\)</span> that are red <em>exactly</em>. When the number <span class="math inline">\(N\)</span> of individuals or observations in our population is large as was the case with our urn, a census can be quite expensive in terms of time, energy, and money.</p>
<p>Fourth, <strong>sampling</strong> is the act of collecting a sample from the population when we don't have the means to perform a census. We mathematically denote the sample's size using lower case <span class="math inline">\(n\)</span>, as opposed to upper case <span class="math inline">\(N\)</span> which denotes the population's size. Typically the sample size <span class="math inline">\(n\)</span> is much smaller than the population size <span class="math inline">\(N\)</span>. Thus sampling is a much cheaper alternative than performing a census. In our sampling activities, we used shovels with varying slots to extract samples of size <span class="math inline">\(n\)</span> = 1 through <span class="math inline">\(n\)</span> = 100.</p>
<p>Fifth, a <strong>point estimate (AKA sample statistic)</strong> is a summary statistic computed from a sample that <em>estimates</em> an unknown population parameter. In our sampling activities, recall that the unknown population parameter was the population proportion and that this is mathematically denoted with <span class="math inline">\(p\)</span>. Our point estimate is the <em>sample proportion</em>: the proportion of the shovel's balls that are red. In other words, it is our guess of the proportion of the urn's balls that are red. We mathematically denote the sample proportion using <span class="math inline">\(\widehat{p}\)</span>. The &quot;hat&quot; on top of the <span class="math inline">\(p\)</span> indicates that it is an estimate of the unknown population proportion <span class="math inline">\(p\)</span>.</p>
<p>Sixth is the idea of <strong>representative sampling</strong>. A sample is said to be a <em>representative sample</em> if it roughly <em>looks like</em> the population. In other words, are the sample's characteristics a good representation of the population's characteristics? In our sampling activity, are the samples of <span class="math inline">\(n\)</span> balls extracted using our shovels representative of the urn's <span class="math inline">\(N\)</span> = 2400 balls?</p>
<p>Seventh is the idea of <strong>generalizability</strong>. We say a sample is generalizable if any results based on the sample can generalize to the population. In other words, does the value of the point estimate <em>generalize</em> to the population? In our sampling activity, can we generalize the sample proportion from our shovels to the entire urn? Using our mathematical notation, this is akin to asking if <span class="math inline">\(\widehat{p}\)</span> is a &quot;good guess&quot; of <span class="math inline">\(p\)</span>?</p>
<p>Eighth, we say <strong>biased sampling</strong> occurs if certain individuals or observations in a population have a higher chance of being included in a sample than others. We say a sampling procedure is <em>unbiased</em> if every observation in a population had an equal chance of being sampled. In our sampling activities, since we mixed all <span class="math inline">\(N = 2400\)</span> balls prior to each group's sampling and since each of the equally sized balls had an equal chance of being sampled, our samples were unbiased.</p>
<!-- MF: This may be a good location for an example of biased sampling. -->
<p>Ninth and lastly, the idea of <strong>random sampling</strong>. We say a sampling procedure is <em>random</em> if we sample randomly from the population in an unbiased fashion. In our sampling activities, this would correspond to sufficiently mixing the urn before each use of the shovel.</p>
<p>Phew, that's a lot of new terminology and notation to learn! Let's put them all together to describe the paradigm of sampling.</p>
<p><strong>In general:</strong></p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>&quot;good guess&quot;</strong> of the unknown population parameter, thus</li>
<li>instead of performing a census, we can <strong>infer</strong> about the population using sampling.</li>
</ul>
<p><strong>Specific to our sampling activity:</strong></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n=50\)</span> balls at <strong>random</strong>, in other words, we mix all of the equally sized balls before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn's 2400 balls, thus</li>
<li>any result based on the shovel's balls can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the <span class="math inline">\(n=50\)</span> balls in the shovel that are red is a <strong>&quot;good guess&quot;</strong> of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N=2400\)</span> balls that are red, thus</li>
<li>instead of manually going over all 2400 balls in the urn, we can <strong>infer</strong> about the urn using the shovel.</li>
</ul>
<p>Note that last word we wrote in bold: <strong>infer</strong>. The act of &quot;inferring&quot; means to deduce or conclude information from evidence and reasoning. In our sampling activities, we wanted to infer about the proportion of the urn's balls that are red. <a href="https://en.wikipedia.org/wiki/Statistical_inference"><em>Statistical inference</em></a> is the &quot;theory, methods, and practice of forming judgments about the parameters of a population and the reliability of statistical relationships, typically on the basis of random sampling.&quot; In other words, statistical inference is the act of inference via sampling.</p>
</div>
<div id="sampling-definitions" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Statistical definitions</h3>
<p>Now, for some important statistical definitions related to sampling. As a refresher of our 1,000 repeated/replicated virtual samples of size <span class="math inline">\(n\)</span> = 25, <span class="math inline">\(n\)</span> = 50, and <span class="math inline">\(n\)</span> = 100 in Section <a href="#sampling-simulation">1.2</a>, let's display Figure <a href="#fig:comparing-sampling-distributions">1.12</a> again as Figure <a href="#fig:comparing-sampling-distributions-1b">1.14</a>.</p>
<div class="figure"><span id="fig:comparing-sampling-distributions-1b"></span>
<p class="caption marginnote shownote">
FIGURE 1.14: Previously seen three distributions of the sample proportion <span class="math inline">\(\widehat{p}\)</span>.
</p>
<img src="06-sampling_files/figure-html/comparing-sampling-distributions-1b-1.png" alt="Previously seen three distributions of the sample proportion $\widehat{p}$." width="672"  />
</div>
<p>These types of distributions have a special name: <strong>sampling distributions</strong>;  their visualization displays the effect of sampling variation on the distribution of any point estimate, in this case, the sample proportion <span class="math inline">\(\widehat{p}\)</span>. Using these sampling distributions, for a given sample size <span class="math inline">\(n\)</span>, we can make statements about what values we can typically expect.</p>
<p>For example, observe the centers of all three sampling distributions: they are all roughly centered around <span class="math inline">\(0.4 = 40\%\)</span>. Furthermore, observe that while we are somewhat likely to observe sample proportions of red balls of <span class="math inline">\(0.2 = 20\%\)</span> when using the shovel with 25 slots, we will almost never observe a proportion of 20% when using the shovel with 100 slots. Observe also the effect of sample size on the sampling variation. As the sample size <span class="math inline">\(n\)</span> increases from 25 to 50 to 100,  the variation of the sampling distribution decreases and thus the values cluster more and more tightly around the same center of around 40%. We quantified this variation using the standard deviation of our sample proportions, seeing that the standard deviation decreases with the square root of the sample size:</p>
<div class="figure"><span id="fig:unnamed-chunk-33"></span>
<p class="caption marginnote shownote">
FIGURE 1.15: Previously seen comparing standard deviations of proportions red for 100 different shovels
</p>
<img src="06-sampling_files/figure-html/unnamed-chunk-33-1.png" alt="Previously seen comparing standard deviations of proportions red for 100 different shovels" width="672"  />
</div>
<p>So as the sample size increases, the standard deviation of the proportion of red balls decreases. This type of standard deviation has another special name:  <strong>standard error</strong>. Standard errors quantify the effect of sampling variation induced on our estimates. In other words, they quantify how much we can expect different proportions of a shovel's balls that are red <em>to vary</em> from one sample to another sample to another sample, and so on. As a general rule, as sample size increases, the standard error decreases.</p>
<p>Unfortunately, these names confuse many people who are new to statistical inference. For example, it's common for people who are new to statistical inference to call the &quot;sampling distribution&quot; the &quot;sample distribution.&quot; Another additional source of confusion is the name &quot;standard deviation&quot; and &quot;standard error.&quot; Remember that a standard error is merely a <em>kind</em> of standard deviation: the standard deviation of any point estimate from sampling. In other words, all standard errors are standard deviations, but not every standard deviation is necessarily a standard error.</p>
<p>To help reinforce these concepts, let's re-display Figure <a href="#fig:comparing-sampling-distributions">1.12</a> but using our new terminology, notation, and definitions relating to sampling in Figure <a href="#fig:comparing-sampling-distributions-2">1.16</a>.</p>
<div class="figure"><span id="fig:comparing-sampling-distributions-2"></span>
<p class="caption marginnote shownote">
FIGURE 1.16: Three sampling distributions of the sample proportion <span class="math inline">\(\widehat{p}\)</span>.
</p>
<img src="06-sampling_files/figure-html/comparing-sampling-distributions-2-1.png" alt="Three sampling distributions of the sample proportion $\widehat{p}$." width="672"  />
</div>
<p>Furthermore, let's display the graph of standard errors for <span class="math inline">\(n = 1\)</span> to <span class="math inline">\(n = 100\)</span> using our new terminology, notation, and definitions relating to sampling.</p>
<div class="figure"><span id="fig:unnamed-chunk-34"></span>
<p class="caption marginnote shownote">
FIGURE 1.17: Standard errors of the sample proportion based on sample sizes of 1 to 100
</p>
<img src="06-sampling_files/figure-html/unnamed-chunk-34-1.png" alt="Standard errors of the sample proportion based on sample sizes of 1 to 100" width="672"  />
</div>
<p>Remember the key message of this last table: that as the sample size <span class="math inline">\(n\)</span> goes up, the &quot;typical&quot; error of your point estimate will go down, as quantified by the <em>standard error</em>.</p>
</div>
<div id="moral-of-the-story" class="section level3">
<h3><span class="header-section-number">1.3.3</span> The moral of the story</h3>
<p>Let's recap this section so far. We've seen that if a sample is generated at random, then the resulting point estimate is a &quot;good guess&quot; of the true unknown population parameter. In our sampling activities, since we made sure to mix the balls first before extracting a sample with the shovel, the resulting sample proportion <span class="math inline">\(\widehat{p}\)</span> of the shovel's balls that were red was a &quot;good guess&quot; of the population proportion <span class="math inline">\(p\)</span> of the urn's balls that were red.</p>
<p>However, what do we mean by our point estimate being a &quot;good guess&quot;? Sometimes, we'll get an estimate that is less than the true value of the population parameter, while at other times we'll get an estimate that is greater. This is due to sampling variation. However, despite this sampling variation, our estimates will &quot;on average&quot; be correct and thus will be centered at the true value. This is because our sampling was done at random and thus in an unbiased fashion.</p>
<p>In our sampling activities, sometimes our sample proportion <span class="math inline">\(\widehat{p}\)</span> was less than the true population proportion <span class="math inline">\(p\)</span>, while at other times it was greater. This was due to the sampling variability. However, despite this sampling variation, our sample proportions <span class="math inline">\(\widehat{p}\)</span> were &quot;on average&quot; correct and thus were centered at the true value of the population proportion <span class="math inline">\(p\)</span>. This is because we mixed our urn before taking samples and thus the sampling was done at random and thus in an unbiased fashion. This is also known as having an <em>accurate</em> estimate.</p>
<p>What was the value of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N\)</span> = 2400 balls in the actual urn that were red? There were 900 red balls, for a proportion red of 900/2400 = 0.375 = 37.5%! How do we know this? Did the authors do an exhaustive count of all the balls? No! They were listed in the contents of the box that the urn came in! Hence we were able to make the contents of the virtual <code>urn</code> match the tactile urn:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">urn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sum_red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> &quot;red&quot;</span>), 
            <span class="dt">sum_not_red =</span> <span class="kw">sum</span>(color <span class="op">!=</span><span class="st"> &quot;red&quot;</span>))</code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   sum_red sum_not_red
##     &lt;int&gt;       &lt;int&gt;
## 1     900        1500</code></pre>
<p>Let's re-display our sampling distributions from Figures <a href="#fig:comparing-sampling-distributions">1.12</a> and <a href="#fig:comparing-sampling-distributions-2">1.16</a>, but now with a vertical red line marking the true population proportion <span class="math inline">\(p\)</span> of balls that are red = 37.5% in Figure <a href="#fig:comparing-sampling-distributions-3">1.18</a>. We see that while there is a certain amount of error in the sample proportions <span class="math inline">\(\widehat{p}\)</span> for all three sampling distributions, on average the <span class="math inline">\(\widehat{p}\)</span> are centered at the true population proportion red <span class="math inline">\(p\)</span>.</p>
<div class="figure"><span id="fig:comparing-sampling-distributions-3"></span>
<p class="caption marginnote shownote">
FIGURE 1.18: Three sampling distributions with population proportion <span class="math inline">\(p\)</span> marked by vertical line.
</p>
<img src="06-sampling_files/figure-html/comparing-sampling-distributions-3-1.png" alt="Three sampling distributions with population proportion $p$ marked by vertical line." width="672"  />
</div>
<p>We also saw in this section that as your sample size <span class="math inline">\(n\)</span> increases, your point estimates will vary less and less and be more and more concentrated around the true population parameter. This variation is quantified by the decreasing <em>standard error</em>. In other words, the typical error of your point estimates will decrease. In our sampling exercise, as the sample size increased, the variation of our sample proportions <span class="math inline">\(\widehat{p}\)</span> decreased. You can observe this behavior in Figure <a href="#fig:comparing-sampling-distributions-3">1.18</a>. This is also known as having a <em>precise</em> estimate.</p>
<p>So random sampling ensures our point estimates are <em>accurate</em>, while on the other hand having a large sample size ensures our point estimates are <em>precise</em>. While the terms &quot;accuracy&quot; and &quot;precision&quot; may sound like they mean the same thing, there is a subtle difference. Accuracy describes how &quot;on target&quot; our estimates are, whereas precision describes how &quot;consistent&quot; our estimates are. Figure <a href="#fig:accuracy-vs-precision">1.19</a> illustrates the difference.</p>
<!-- MF: So which one of the simulated sampling activities was most precise & accurate? The 100 shovel performed 1000 times? -->
<div class="figure"><span id="fig:accuracy-vs-precision"></span>
<p class="caption marginnote shownote">
FIGURE 1.19: Comparing accuracy and precision.
</p>
<img src="06-sampling/images/accuracy_vs_precision.jpg" alt="Comparing accuracy and precision." width="75%" height="75%"  />
</div>
<!-- MF: Maybe apply the sample examples done in this chapter overlayed over the image? For example, under high precision/low accurancy, put "biased sampling with large sample size". Under low precision/low accuracy, put "biased sample with small sample size", etc. -->
<p>At this point, you might be asking yourself: &quot;If we already knew the true proportion of the urn's balls that are red was 37.5%, then why did we do any sampling?&quot; You might also be asking: &quot;Why did we take 1,000 repeated samples of various sizes (n = 1 to n = 100)? Shouldn't we be taking only <em>one</em> sample that's as large as possible?&quot;. If you did ask yourself these questions, your suspicion is merited!</p>
<p>The sampling activity involving the urn is merely an <em>idealized version</em> of how sampling is done in real life. We performed this exercise only to study and understand:</p>
<ol style="list-style-type: decimal">
<li>The effect of sampling variation.</li>
<li>The effect of sample size on sampling variation.</li>
</ol>
<p>This is not how sampling is done in real life. In a real-life scenario, we won't know what the true value of the population parameter is. Furthermore, we wouldn't take 1,000 repeated/replicated samples, but rather a single sample that's as large as we can afford. In the next section, let's now study a real-life example of sampling: polls.</p>
</div>
</div>
<div id="sampling-case-study" class="section level2">
<h2><span class="header-section-number">1.4</span> Case study: Polls</h2>
<p>Let's now switch gears to a more realistic sampling scenario than our urn activity: a poll. In practice, pollsters do not take 1,000 repeated samples as we did in our previous sampling activities, but rather take only a <em>single sample</em> that's as large as possible.</p>
<p>On December 4, 2013, National Public Radio in the US reported on a poll of President Obama's approval rating among young Americans aged 18-29 in an article, <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">&quot;Poll: Support For Obama Among Young Americans Eroding.&quot;</a> The poll was conducted by the Kennedy School's Institute of Politics at Harvard University. A quote from the article:</p>
<blockquote>
<p>After voting for him in large numbers in 2008 and 2012, young Americans are souring on President Obama.</p>
<p>According to a new Harvard University Institute of Politics poll, just 41 percent of millennials — adults ages 18-29 — approve of Obama's job performance, his lowest-ever standing among the group and an 11-point drop from April.</p>
</blockquote>
<p>Let's tie elements of the real-life poll in this new article with our &quot;tactile&quot; and &quot;virtual&quot; urn activity from Sections <a href="#sampling-activity">1.1</a> and <a href="#sampling-simulation">1.2</a> using the terminology, notations, and definitions we learned in Section <a href="#sampling-framework">1.3</a>. You'll see that our sampling activity with the urn is an idealized version of what pollsters are trying to do in real life.</p>
<p>First, who is the <strong>(Study) Population</strong> of <span class="math inline">\(N\)</span> individuals or observations of interest? </p>
<ul>
<li>Urn: <span class="math inline">\(N\)</span> = 2400 identically sized red and white balls</li>
<li>Obama poll: <span class="math inline">\(N\)</span> = ? young Americans aged 18-29</li>
</ul>
<p>Second, what is the <strong>population parameter</strong>? </p>
<ul>
<li>Urn: The population proportion <span class="math inline">\(p\)</span> of <em>all</em> the balls in the urn that are red.</li>
<li>Obama poll: The population proportion <span class="math inline">\(p\)</span> of <em>all</em> young Americans who approve of Obama's job performance.</li>
</ul>
<p>Third, what would a <strong>census</strong> look like? </p>
<ul>
<li>Urn: Manually going over all <span class="math inline">\(N\)</span> = 2400 balls and exactly computing the population proportion <span class="math inline">\(p\)</span> of the balls that are red.</li>
<li>Obama poll: Locating all <span class="math inline">\(N\)</span> young Americans and asking them all if they approve of Obama's job performance. In this case, we don't even know what the population size <span class="math inline">\(N\)</span> is!</li>
</ul>
<p>Fourth, how do you perform <strong>sampling</strong> to obtain a sample of size <span class="math inline">\(n\)</span>? </p>
<ul>
<li>Urn: Using a shovel with <span class="math inline">\(n\)</span> slots.</li>
<li>Obama poll: One method is to get a list of phone numbers of all young Americans and pick out <span class="math inline">\(n\)</span> phone numbers. In this poll's case, the sample size of this poll was <span class="math inline">\(n = 2089\)</span> young Americans.</li>
</ul>
<p>Fifth, what is your <strong>point estimate (AKA sample statistic)</strong> of the unknown population parameter?</p>
<ul>
<li>Urn: The sample proportion <span class="math inline">\(\widehat{p}\)</span> of the balls in the shovel that were red.</li>
<li>Obama poll: The sample proportion <span class="math inline">\(\widehat{p}\)</span> of young Americans in the sample that approve of Obama's job performance. In this poll's case, <span class="math inline">\(\widehat{p} = 0.41 = 41\%\)</span>, the quoted percentage in the second paragraph of the article.  </li>
</ul>
<p>Sixth, is the sampling procedure <strong>representative</strong>? </p>
<ul>
<li>Urn: Are the contents of the shovel representative of the contents of the urn? Because we mixed the urn before sampling, we can feel confident that they are.</li>
<li>Obama poll: Is the sample of <span class="math inline">\(n = 2089\)</span> young Americans representative of <em>all</em> young Americans aged 18-29? This depends on whether the sampling was random.</li>
</ul>
<p>Seventh, are the samples <strong>generalizable</strong> to the greater population? </p>
<ul>
<li>Urn: Is the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the shovel's balls that are red a &quot;good guess&quot; of the population proportion <span class="math inline">\(p\)</span> of the urn's balls that are red? Given that the sample was representative, the answer is yes.</li>
<li>Obama poll: Is the sample proportion <span class="math inline">\(\widehat{p} = 0.41\)</span> of the sample of young Americans who supported Obama a &quot;good guess&quot; of the population proportion <span class="math inline">\(p\)</span> of all young Americans who supported Obama at this time in 2013? In other words, can we confidently say that roughly 41% of <em>all</em> young Americans approved of Obama at the time of the poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Eighth, is the sampling procedure <strong>unbiased</strong>? In other words, do all observations have an equal chance of being included in the sample? </p>
<ul>
<li>Urn: Since each ball was equally sized and we mixed the urn before using the shovel, each ball had an equal chance of being included in a sample and hence the sampling was unbiased.</li>
<li>Obama poll: Did all young Americans have an equal chance at being represented in this poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Ninth and lastly, was the sampling done at <strong>random</strong>? </p>
<ul>
<li>Urn: As long as you mixed the urn sufficiently before sampling, your samples would be random.</li>
<li>Obama poll: Was the sample conducted at random? We can't answer this question without knowing about the <em>sampling methodology</em> used by Kennedy School's Institute of Politics at Harvard University. We'll discuss this more at the end of this section.</li>
</ul>
<p>In other words, the poll by Kennedy School's Institute of Politics at Harvard University can be thought of as <em>an instance</em> of using the shovel to sample balls from the urn. Furthermore, if another polling company conducted a similar poll of young Americans at roughly the same time, they would likely get a different estimate than 41%. This is due to <em>sampling variation</em>.</p>
<p>Let's now revisit the sampling paradigm from Subsection <a href="#terminology-and-notation">1.3.1</a>:</p>
<p><strong>In general</strong>:</p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>&quot;good guess&quot;</strong> of the unknown population parameter, thus</li>
<li>instead of performing a census, we can <strong>infer</strong> about the population using sampling.</li>
</ul>
<p>**Specific to the <a href="urn:**" class="uri">urn:**</a></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n = 50\)</span> balls at <strong>random</strong>, in other words, we mix all of the equally sized balls before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn's 2400 balls, thus</li>
<li>any result based on the shovel's balls can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\widehat{p}\)</span> of the <span class="math inline">\(n = 50\)</span> balls in the shovel that are red is a <strong>&quot;good guess&quot;</strong> of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N = 2400\)</span> balls that are red, thus</li>
<li>instead of manually going over all 2400 balls in the urn, we can <strong>infer</strong> about the urn using the shovel.</li>
</ul>
<p><strong>Specific to the Obama poll:</strong></p>
<ul>
<li>If we had a way of contacting a <strong>randomly</strong> chosen sample of 2089 young Americans and polling their approval of President Obama in 2013, then</li>
<li>these 2089 young Americans would be an <strong>unbiased</strong> and <strong>representative</strong> sample of <em>all</em> young Americans in 2013, thus</li>
<li>any results based on this sample of 2089 young Americans can <strong>generalize</strong> to the entire population of <em>all</em> young Americans in 2013, thus</li>
<li>the reported sample approval rating of 41% of these 2089 young Americans is a <strong>good guess</strong> of the true approval rating among all young Americans in 2013, thus</li>
<li>instead of performing an expensive census of all young Americans in 2013, we can <strong>infer</strong> about all young Americans in 2013 using polling.</li>
</ul>
<p>So as you can see, it was critical for the sample obtained by Kennedy School's Institute of Politics at Harvard University to be truly random in order to infer about <em>all</em> young Americans' opinions about Obama. Was their sample truly random? It's hard to answer such questions without knowing about the <em>sampling methodology</em> they used. For example, if this poll was conducted using only mobile phone numbers, people without mobile phones would be left out and therefore not represented in the sample. What about if Kennedy School's Institute of Politics at Harvard University conducted this poll on an internet news site? Then people who don't read this particular internet news site would be left out. Ensuring that our samples were random was easy to do in our sampling urn exercises; however, in a real-life situation like the Obama poll, this is much harder to do.</p>
<div id="sampling-conclusion-central-limit-theorem" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Central Limit Theorem</h3>
<p>What you visualized in Figures <a href="#fig:comparing-sampling-distributions">1.12</a> and <a href="#fig:comparing-sampling-distributions-2">1.16</a> and summarized in Table <a href="#tab:comparing-n">1.1</a> was a demonstration of a famous theorem, or mathematically proven truth, called the  <em>Central Limit Theorem</em>. It loosely states that when sample means are based on larger and larger sample sizes, the sampling distribution of these sample means becomes both more and more normally shaped and more and more narrow.</p>
<p>In other words, their sampling distribution increasingly follows a <em>normal distribution</em> and the variation of these sampling distributions gets smaller, as quantified by their standard errors.</p>
<p>Shuyi Chiou, Casey Dunn, and Pathikrit Bhattacharyya created a 3-minute and 38-second video at <a href="https://youtu.be/jvoxEYmQHNM" class="uri">https://youtu.be/jvoxEYmQHNM</a> explaining this crucial statistical theorem using the average weight of wild bunny rabbits and the average wingspan of dragons as examples. Figure <a href="#fig:CLT-video-preview">1.20</a> shows a preview of this video.</p>
<div class="figure"><span id="fig:CLT-video-preview"></span>
<p class="caption marginnote shownote">
FIGURE 1.20: Preview of Central Limit Theorem video.
</p>
<img src="06-sampling/images/CLT_video_preview.png" alt="Preview of Central Limit Theorem video." width="75%"  />
</div>
</div>
</div>
<div id="rubin-causal-model" class="section level2">
<h2><span class="header-section-number">1.5</span> Rubin Causal Model</h2>
<!-- MF: Here, we are taking the blood pressure example and applying it to sampling/RCM by placing the unknown condition as the population that didn't respond to the query? -->
<!-- With a big enough sample, we can probably get a pretty good measure of the average blood pressure for that sample.  Have we solved our problem?  That is, can we now assume that our estimate of the average blood pressure in our sample is a good estimate of the average blood pressure in the U.S. adult population? -->
<!-- DK: Where should we talk about sampling? Let's put this entire discussion into the . . . sampling chapter. Throughout this chapter we should pretend that we are looking at the entire universe of people we care about. -->
<!-- Well, let's see how many of the missing values we have filled in to our table of the population: -->
<!-- ```{r, echo = FALSE} -->
<!-- # First, we create a tibble with the values we want for the table -->
<!-- tibble(subject = c("Person 1", "Person 2", "Person 3", "...", "Person N"), -->
<!--        `Blood Pressure` = c("?", "?", "?", "...", "?")) %>% -->
<!--   # Then, we use the gt function to make it pretty -->
<!--   gt() %>% -->
<!--   cols_label(subject = md("**Person**")) %>% -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = vars(subject))) %>% -->
<!--   tab_style(cell_text(weight = "bold"), -->
<!--             location = cells_body(columns = vars(subject))) -->
<!-- ``` -->
<!-- Alas, since the U.S. population is over 300 million, we can't even see our 1,000 respondents!  If we want to assume that our estimate for our respondents is a good estimate for the population, we need to assume that their blood pressures are, on average, the same as the blood pressures of the people we *didn't* survey. -->
<!-- For that to be true, it means that the *sampling mechanism* can't be related to someone's blood pressure.  For example, let's say that we surveyed 1,000 Harvard undergraduates.  Do we think that Harvard undergraduates have average blood pressure? No! Harvard undergraduates are younger than average, and younger people have lower blood pressures on average. -->
<!-- So we should *randomly* sample the population.  Then, there won't be any systematic relationship between being chosen for our sample and blood pressure.  (There may be a relationship by chance, but taking a bigger sample reduces that possibility.) -->
<!-- But even randomly choosing whom to survey may not totally solve our problem.  Some people may not fill out our survey, after all.  So our table for our survey may look like this: -->
<!-- ```{r, echo = FALSE} -->
<!-- # First, we create a tibble with the values we want for the table -->
<!-- tibble(subject = c("Respondent 1", "Respondent 2", "Respondent 3", "...", "Respondent 1,000"), -->
<!--        `Blood Pressure` = c("130", "?", "115", "...", "140")) %>% -->
<!--   # Then, we use the gt function to make it pretty -->
<!--   gt() %>% -->
<!--   cols_label(subject = md("**Respondent**")) %>% -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = vars(subject))) %>% -->
<!--   tab_style(cell_text(weight = "bold"), -->
<!--             location = cells_body(columns = vars(subject))) -->
<!-- ``` -->
<!-- So not only do we have all the ? values in the population table, we also have a ? for one of our survey respondents (Respondent 2). -->
<!-- Can we just fill in the ? for Respondent 2 with the average of the other respondents?  Only if the factors that led Respondent 2 not to answer the survey had nothing to do with blood pressure.  Let's say that poorer respondents were less likely to fill out the survey, for example.  If poorer respondents also had higher blood pressure on average, our estimate of the average blood pressure *among those who answered the survey* will be biased downwards as an estimate for the population, even if we surveyed people at random.  -->
<!-- So missing data is not just a problem for estimating causal effects.  The mechanisms by which you find out some things and don't find out other things are critical to understand when trying to make statistical inferences. -->
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">1.6</span> Conclusion</h2>
<p>In this chapter, we performed both tactile and virtual sampling exercises to infer about an unknown proportion. We also presented a case study of sampling in real life with polls. In each case, we used the sample proportion <span class="math inline">\(\widehat{p}\)</span> to estimate the population proportion <span class="math inline">\(p\)</span>. However, we are not just limited to scenarios related to proportions. In other words, we can use sampling to estimate other population parameters using other point estimates as well.</p>
<p>Recall in our Obama poll case study in Section <a href="#sampling-case-study">1.4</a> that based on this particular sample, the best guess by Kennedy School's Institute of Politics at Harvard University of the U.S. President Obama's approval rating among all young Americans was 41%. However, this isn't the end of the story. If you read the article further, it states:</p>
<blockquote>
<p>The online survey of 2,089 adults was conducted from Oct. 30 to Nov. 11, just weeks after the federal government shutdown ended and the problems surrounding the implementation of the Affordable Care Act began to take center stage. The poll's margin of error was plus or minus 2.1 percentage points.</p>
</blockquote>
<!-- MF: What is the relevance of the above passage, other than the margin of error? To clarify, the shutdown & ACA comment seems irrelevant. -->
<p>Note the term <em>margin of error</em>, which here is &quot;plus or minus 2.1 percentage points.&quot; Most polls won't produce an estimate that's perfectly right; there will always be a certain amount of error caused by <em>sampling variation</em>. The margin of error of plus or minus 2.1 percentage points is saying that a typical range of errors for polls of this type is about <span class="math inline">\(\pm\)</span> 2.1%, in words from about 2.1% too small to about 2.1% too big. We can restate this as the interval of <span class="math inline">\([41\% - 2.1\%, 41\% + 2.1\%] = [37.9\%, 43.1\%]\)</span> (this notation indicates the interval contains all values between 37.9% and 43.1%, including the end points of 37.9% and 43.1%). We'll see in the next chapter that such intervals are known as <em>confidence intervals</em>.</p>
</div>
<!-- </div> -->
<!--bookdown:body:end-->



</body>
</html>
