<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 11 Continuous Response | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 11 Continuous Response | Gov 50: Data">

<title>Chapter 11 Continuous Response | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="pitfalls.html"><span class="toc-section-number">10</span> Pitfalls</a>
<a id="active-page" href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a><ul class="toc-sections">
<li class="toc"><a href="#exploratory-data-analysis"> Exploratory Data Analysis</a></li>
<li class="toc"><a href="#lm"> <code>lm()</code></a></li>
<li class="toc"><a href="#NA"> Using <code>stan_glm()</code></a></li>
<li class="toc"><a href="#using-a-neural-network"> Using a neural network</a></li>
<li class="toc"><a href="#model-selection"> Model selection</a></li>
<li class="toc"><a href="#wrap-up"> Wrap-Up</a></li>
</ul>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="rubin-causal-model.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="continuous-response" class="section level1">
<h1>
<span class="header-section-number">Chapter 11</span> Continuous Response</h1>
<!-- Overview: The main structure of the this chapter is three full scale linear modeling approaches to the same data set, where the response variable is continuous. (Maybe we have two data sets, and apply all three models to each one?) In each case, we use the tidymodels framework. I am not sure what the best dataset would be. I am not sure what the three approaches should be. Presumably lm() and stan_glm() would be included. Maybe gam() also. Or loess(). Or robust_lm(). Could be something fancier like svm(). Or neural network. -->
<!-- 0) Preamble. Plan out to chapter. Nothing more to learn. Just apply. Review themes.Rmd, and the three problems which we confronted in 9 and solved in 10. What specific questions are we going to answer? -->
<!-- 1) EDA of nes. drop na. Talk about Prudence at the end. It's own ### and with image in the side margin. OK if its only a paragraph or two.  -->
<!-- 2) Preview the three models. Justice. Review the Preceptor. Discuss Predictive. Might it be Causal. Show some math.  Courage, which is just code. -->
<!-- $$y_i = f(x_{i1}, x_{i2}, ..., \beta)$$ -->
<!-- 2) lm. Use all all variables. Go through the process. Use CV to provide a measure of how well it does. Use new_data. And make some predictions. Not noticing that this is a bad model because of overrfitting. -->
<!-- 3) stan_glm Do the same thing. Notice that CV measures are much better! Oh! Lesson: Be wary of overfitting. Maybe go back and re-estimate lm with fewer variables. Or not. -->
<!-- 4) Neural network. https://www.tidymodels.org/learn/models/parsnip-nnet/ All the same things apply. How well in a CV. predictions with new data.  -->
<!-- 5) How do we select among the models? Temperance -->
<!-- 6) Answer the questions we started with. -->
<!-- 2. Use a different model, like loess, to solve the exact same problem. Go through the same overview, but more quickly. Not everything will work. For example, there are no parameter estimates for loess, or at least none that are easily visible. -->
<!-- 3. How do we decide? lm() or loess() or something? Incorporate (i.e., copy and paste) chapter 14 material. Don't do anything with tidymodel syntax. All that falls to chapter 11. But you are explaining every concept. -->
<!-- In loess section, grab a copy of this xkcd and use it: https://xkcd.com/2048/ -->
<p>In the last two chapters, we covered regressions and common pitfalls. This chapter will be all about applying these concepts using the <code>tidymodels</code> framework.</p>
<p>The dataset we will be using is <code>nes</code> from the <code>PPBDS.data</code> package. <code>nes</code> contains data from the American National Election Survey, conducted every presidential election cycle. Along with demographic details, such as race, gender, and age, the survey also contains respondents’ ideological identification. Because <code>ideology</code> is measured on a scale from 1 to 7, we can treat it as our continuous outcome variable.</p>
<p>Wouldn’t it be interesting to predict <code>ideology</code> based off of other variables? This question has wide-reaching consequences for political polling and election outcomes. Throughout this chapter, we seek to answer this question: Which factors influences one’s ideology, and how so?</p>
<div id="exploratory-data-analysis" class="section level2">
<h2>
<span class="header-section-number">11.1</span> Exploratory Data Analysis</h2>
<p>Load <code>PPBDS.data</code> and <code>skimr</code>. <code>skim()</code> the dataset.</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="continuous-response.html#cb978-1"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb978-2"><a href="continuous-response.html#cb978-2"></a><span class="kw">library</span>(skimr)</span>
<span id="cb978-3"><a href="continuous-response.html#cb978-3"></a><span class="kw">skim</span>(nes)</span></code></pre></div>
<table style="width: auto;" class="table table-condensed">
<caption>
<span id="tab:unnamed-chunk-714">TABLE 11.1: </span>Data summary
</caption>
<thead><tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
Name
</td>
<td style="text-align:left;">
nes
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of rows
</td>
<td style="text-align:left;">
38558
</td>
</tr>
<tr>
<td style="text-align:left;">
Number of columns
</td>
<td style="text-align:left;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
_______________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Column type frequency:
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
character
</td>
<td style="text-align:left;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
factor
</td>
<td style="text-align:left;">
3
</td>
</tr>
<tr>
<td style="text-align:left;">
numeric
</td>
<td style="text-align:left;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
________________________
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Group variables
</td>
<td style="text-align:left;">
None
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead><tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
<th style="text-align:right;">
empty
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:right;">
whitespace
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
state
</td>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
gender
</td>
<td style="text-align:right;">
141
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
race
</td>
<td style="text-align:right;">
287
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
pres_appr
</td>
<td style="text-align:right;">
9646
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
voted
</td>
<td style="text-align:right;">
4078
</td>
<td style="text-align:right;">
0.89
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<thead><tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:left;">
ordered
</th>
<th style="text-align:right;">
n_unique
</th>
<th style="text-align:left;">
top_counts
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
income
</td>
<td style="text-align:right;">
2517
</td>
<td style="text-align:right;">
0.93
</td>
<td style="text-align:left;">
TRUE
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:left;">
34 : 11740, 68 : 9974, 0 -: 6300, 17 : 6213
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
450
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:left;">
TRUE
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
25 : 7669, 35 : 7342, 45 : 6545, 55 : 6021
</td>
</tr>
<tr>
<td style="text-align:left;">
education
</td>
<td style="text-align:right;">
397
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:left;">
TRUE
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:left;">
Hig: 9269, Som: 8540, Col: 5540, Som: 4688
</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead><tr>
<th style="text-align:left;">
skim_variable
</th>
<th style="text-align:right;">
n_missing
</th>
<th style="text-align:right;">
complete_rate
</th>
<th style="text-align:right;">
mean
</th>
<th style="text-align:right;">
sd
</th>
<th style="text-align:right;">
p0
</th>
<th style="text-align:right;">
p25
</th>
<th style="text-align:right;">
p50
</th>
<th style="text-align:right;">
p75
</th>
<th style="text-align:right;">
p100
</th>
<th style="text-align:left;">
hist
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
year
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
1989.40
</td>
<td style="text-align:right;">
20.5
</td>
<td style="text-align:right;">
1952
</td>
<td style="text-align:right;">
1972
</td>
<td style="text-align:right;">
1992
</td>
<td style="text-align:right;">
2012
</td>
<td style="text-align:right;">
2016
</td>
<td style="text-align:left;">
▃▃▃▃▇
</td>
</tr>
<tr>
<td style="text-align:left;">
ideology
</td>
<td style="text-align:right;">
619
</td>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
-0.38
</td>
<td style="text-align:right;">
2.1
</td>
<td style="text-align:right;">
-3
</td>
<td style="text-align:right;">
-2
</td>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:left;">
▇▂▂▂▅
</td>
</tr>
</tbody>
</table>
<p>Great! Before we dive in, let’s identify the variables available to us in <code>nes</code>:</p>
<ul>
<li>
<code>year</code>: the year the study was conducted</li>
<li>
<code>state</code>: the two-letter abbreviation corresponding to the state of the respondent</li>
<li>
<code>gender</code>: identifies respondents with values “Male” and “Female”</li>
<li>
<code>race</code>: race/ethnicity respondent identification</li>
<li>
<code>income</code>: 5 income groups: 1 as 0-16th percentile, 2 as 17-33rd, 3 as 34 to 67, 4 as 68 to 95, 5 as 96 to 100</li>
<li>
<code>age</code>: respondents’ age ranges</li>
<li>
<code>education</code>: 7 tier delineation of educational achievement</li>
<li>
<code>pres_appr</code>: respondents’ self-reported approval of the sitting president</li>
<li>
<code>voted</code>: whether the respondent had voted in the presidential election</li>
<li>
<code>ideology</code> a continuous variable with 1 corresponding to strongly Democrat and 7 corresponding to strongly Republican and 0 if NA.</li>
</ul>
<p>If we were given a new person who was not surveyed, and the above variables, our goal is to predict their ideology correctly.</p>
<p>As you also saw, there are a lot of data points in this dataset. <code>nes</code> covers 1954 through 2016, but for our sake, we will narrow our scope to just 2016. Because of the changing nature of what makes someone ideologically liberal or ideologically conservative over time, it is best to construct a model in which we eliminate as much of this variance as possible. Keep in mind that, when feeding in new data to our model, it is most accurately applied to voters in or around 2016. Indeed, a 1954 voter might act very differently than a 2016 voter.</p>
<p>Filter the data to only show <code>year == 2016</code>.</p>
<div class="sourceCode" id="cb979"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb979-1"><a href="continuous-response.html#cb979-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb979-2"><a href="continuous-response.html#cb979-2"></a>nes <span class="op">%&gt;%</span></span>
<span id="cb979-3"><a href="continuous-response.html#cb979-3"></a><span class="st">  </span><span class="kw">select</span>(year, state, gender, race, income, age, education, ideology) <span class="op">%&gt;%</span></span>
<span id="cb979-4"><a href="continuous-response.html#cb979-4"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2016</span>)</span></code></pre></div>
<pre><code>## # A tibble: 4,270 x 8
##     year state gender race  income   age     education       ideology
##    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;ord&gt;    &lt;ord&gt;   &lt;ord&gt;              &lt;int&gt;
##  1  2016 LA    Male   White 34 - 67  25 - 34 Highschool             3
##  2  2016 AR    Male   White 34 - 67  25 - 34 College                2
##  3  2016 MS    Male   White 17 - 33  17 - 24 Highschool            -1
##  4  2016 TN    Male   White 68 - 95  55 - 64 Highschool             1
##  5  2016 OH    Female White 0 - 16   35 - 44 Highschool            -1
##  6  2016 NJ    Male   White 0 - 16   55 - 64 Adv. Degree            1
##  7  2016 NY    Male   Black 68 - 95  55 - 64 Some Highschool       -3
##  8  2016 NJ    Female White 96 - 100 55 - 64 Highschool             0
##  9  2016 TX    Male   Other 34 - 67  45 - 54 Highschool             1
## 10  2016 MS    Female White 34 - 67  25 - 34 Some College          -1
## # … with 4,260 more rows</code></pre>
<p>Note from our previous skimming of the data that all of the variables are incomplete, meaning they contain <code>NA</code> values. While there are methods to impute missing data, we will simply remove these values for now. We will save this filtered and cleaned dataset as <code>nes_2016</code>.</p>
<div class="sourceCode" id="cb981"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb981-1"><a href="continuous-response.html#cb981-1"></a>nes_<span class="dv">2016</span> &lt;-<span class="st"> </span>nes <span class="op">%&gt;%</span></span>
<span id="cb981-2"><a href="continuous-response.html#cb981-2"></a><span class="st">  </span><span class="kw">filter</span>(year <span class="op">==</span><span class="st"> </span><span class="dv">2016</span>) <span class="op">%&gt;%</span></span>
<span id="cb981-3"><a href="continuous-response.html#cb981-3"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>year) <span class="op">%&gt;%</span></span>
<span id="cb981-4"><a href="continuous-response.html#cb981-4"></a><span class="st">  </span><span class="kw">drop_na</span>()</span>
<span id="cb981-5"><a href="continuous-response.html#cb981-5"></a></span>
<span id="cb981-6"><a href="continuous-response.html#cb981-6"></a>nes_<span class="dv">2016</span></span></code></pre></div>
<pre><code>## # A tibble: 3,433 x 9
##    state gender income   age     education       race  ideology pres_appr  voted
##    &lt;chr&gt; &lt;chr&gt;  &lt;ord&gt;    &lt;ord&gt;   &lt;ord&gt;           &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;
##  1 LA    Male   34 - 67  25 - 34 Highschool      White        3 Disapprove Yes  
##  2 AR    Male   34 - 67  25 - 34 College         White        2 Disapprove Yes  
##  3 MS    Male   17 - 33  17 - 24 Highschool      White       -1 Disapprove No   
##  4 TN    Male   68 - 95  55 - 64 Highschool      White        1 Disapprove Yes  
##  5 OH    Female 0 - 16   35 - 44 Highschool      White       -1 Disapprove Yes  
##  6 NJ    Male   0 - 16   55 - 64 Adv. Degree     White        1 Disapprove Yes  
##  7 NY    Male   68 - 95  55 - 64 Some Highschool Black       -3 Approve    Yes  
##  8 NJ    Female 96 - 100 55 - 64 Highschool      White        0 Disapprove Yes  
##  9 TX    Male   34 - 67  45 - 54 Highschool      Other        1 Disapprove No   
## 10 MS    Female 34 - 67  25 - 34 Some College    White       -1 Approve    Yes  
## # … with 3,423 more rows</code></pre>
<div id="prudence" class="section level3">
<h3>
<span class="header-section-number">11.1.1</span> Prudence</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/prudence.jpg" alt=" " width="1280"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Recall the first of the four Cardinal Virtues of data science. We need to carefully consider how we would like to approach our problem. In fact, what is our problem to solve?</p>
<p>Our problem is that we may not know someone’s ideology right off of the bat. This is true in real life, in which it is an awkward question to pose a stranger. This is also true in surveys that may not have asked respondents to politically self-identify, but would find that information useful. What we are given, however, are a number of demographic variables that can be used to predict someone’s ideology. We need to keep the defining problem (How can we predict someone’s ideology based off of certain demographic variables) in mind as we navigate the models ahead.</p>
<p>Taking a look again at the variables in <code>nes_2016</code>, we might decide against including <code>pres_appr</code> and <code>voted</code> in our models. Why exclude variables, especially variables that may make your model even better?</p>
<p>From glimpsing <code>ch11</code>, we see that there are three data types: factors, characters, and integers. However, <code>income</code>, <code>age</code>, and <code>education</code> are ordered factors. This means that each factor level is considered additively. Ordered factors are dangerous because we do not know how they will interact with our regression models. Therefore, we will use <code>factor()</code> and <code>ordered = FALSE</code> to remove their level orders.</p>
<div class="sourceCode" id="cb983"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb983-1"><a href="continuous-response.html#cb983-1"></a>ch11 &lt;-<span class="st"> </span>nes_<span class="dv">2016</span> <span class="op">%&gt;%</span></span>
<span id="cb983-2"><a href="continuous-response.html#cb983-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">income =</span> <span class="kw">factor</span>(income, <span class="dt">ordered =</span> <span class="ot">FALSE</span>),</span>
<span id="cb983-3"><a href="continuous-response.html#cb983-3"></a>         <span class="dt">age =</span> <span class="kw">factor</span>(age, <span class="dt">ordered =</span> <span class="ot">FALSE</span>),</span>
<span id="cb983-4"><a href="continuous-response.html#cb983-4"></a>         <span class="dt">education =</span> <span class="kw">factor</span>(education, <span class="dt">ordered=</span> <span class="ot">FALSE</span>))</span></code></pre></div>
<p>While we’re paying attention to data types, it is best practice to change character variables to factors.</p>
<div class="sourceCode" id="cb984"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb984-1"><a href="continuous-response.html#cb984-1"></a>ch11 &lt;-<span class="st"> </span>ch11 <span class="op">%&gt;%</span></span>
<span id="cb984-2"><a href="continuous-response.html#cb984-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.factor</span>(state),</span>
<span id="cb984-3"><a href="continuous-response.html#cb984-3"></a>         <span class="dt">gender =</span> <span class="kw">as.factor</span>(gender),</span>
<span id="cb984-4"><a href="continuous-response.html#cb984-4"></a>         <span class="dt">race =</span> <span class="kw">as.factor</span>(race))</span></code></pre></div>
</div>
<div id="justice" class="section level3">
<h3>
<span class="header-section-number">11.1.2</span> Justice</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/justice.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Recall the virtue of Justice: <strong>We want to make sure our models are as just and representative of the real world as possible.</strong> As such, we will split our <code>nes_2016</code> data into two sets: a training set and a testing set. We can do so using the <strong><em>rsample</em></strong> function, <code>initial_split()</code>.</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb985-1"><a href="continuous-response.html#cb985-1"></a><span class="kw">library</span>(tidymodels)</span>
<span id="cb985-2"><a href="continuous-response.html#cb985-2"></a><span class="kw">library</span>(rsample)</span>
<span id="cb985-3"><a href="continuous-response.html#cb985-3"></a></span>
<span id="cb985-4"><a href="continuous-response.html#cb985-4"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb985-5"><a href="continuous-response.html#cb985-5"></a>ch11_split &lt;-<span class="st"> </span><span class="kw">initial_split</span>(ch11)</span>
<span id="cb985-6"><a href="continuous-response.html#cb985-6"></a></span>
<span id="cb985-7"><a href="continuous-response.html#cb985-7"></a>ch11_training &lt;-<span class="st"> </span>ch11_split <span class="op">%&gt;%</span></span>
<span id="cb985-8"><a href="continuous-response.html#cb985-8"></a><span class="st">  </span><span class="kw">training</span>()</span>
<span id="cb985-9"><a href="continuous-response.html#cb985-9"></a>ch11_testing &lt;-<span class="st"> </span>ch11_split <span class="op">%&gt;%</span></span>
<span id="cb985-10"><a href="continuous-response.html#cb985-10"></a><span class="st">  </span><span class="kw">testing</span>()</span></code></pre></div>
<p><em>We will not be touching the testing set.</em> The testing set can be thought of as the final test to analyze the fit of the model. Never will we use the testing set to train the model. After all, that is what the training set is for! And what exactly does training the model mean? Training is simply the process in which we take the components of the given data and create as accurate a predictive machine as possible.</p>
<p>We have mentioned that the following models will be <em>predictive</em>, not <em>causal</em>. Recall that all we care about in a predictive model is forecasting some value <span class="math inline">\(y_i\)</span> given that we know <span class="math inline">\(x_{i_1}, x_{i_2}, ... x_{i_n}\)</span>. The <span class="math inline">\(y_i\)</span> in our case is <code>ideology</code>. The <span class="math inline">\(x_{i_1}, x_{i_2}, ... x_{i_n}\)</span> in this case are certain known variables, such as <code>state</code>, <code>age</code>, and <code>income</code>, among others.</p>
<p>However, we cannot infer what would happen to someone’s <code>ideology</code> if their <code>income</code> level was within the 16th percentile, versus within the 96th percentile. The aforementioned inference would be a causal inference, which ignores the possibility that there are confounding variables. In our case, there are many possible confounding variables that are not represented, such as family socioeconomic background and immigration status.</p>
<p>Keep in mind that our goal is to create the best possible model to predict one’s ideology given a number of demographic variables. That is to say, we plan on re-using our model on out-of-sample data. Hence, we have set the testing set aside to serve as one instance in which to re-use our model to make predictions.</p>
<p>Besides the testing set, new out-of-sample data could come from other surveys that collect demographic information, or from website traffic data. These data most likely will not contain information on whether the respondent approves of the president or whether they voted in the presidential election. In order for our model to be relevant to our question, we will assume that new data will <em>not</em> provide <code>pres_appr</code> and <code>voted</code>. When defining our formula later on, we will keep this in mind.</p>
</div>
<div id="fortitude" class="section level3">
<h3>
<span class="header-section-number">11.1.3</span> Fortitude</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/fortitude.jpg" alt=" " width="1024"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>We will be using three different engines as models: <code>lm</code>, <code>stan</code>, and <code>nnet</code>. We will be using <code>lm</code> to fit a standard linear regression and <code>stan</code> to fit a Bayesian linear regression. You have encountered these two engines in previous chapters in the form of the functions <code>lm()</code> and <code>stan_glm()</code>. The last engine is based on multilayer perceptron neural networks, a supervised machine learning process in which data can be evaluated non-linearly.</p>
<p>We have two linear regression models and one potentially non-linear model. How can we illustrate how each model will map the predictor variables to <code>ideology</code>?</p>
<p>We can do so by writing an equation in which the <code>ideology</code> of the <em>i</em>th respondent, <span class="math inline">\(y_i\)</span>, is a function of certain linear and/or non-linear parameters.</p>
<p><span class="math display">\[y_i = f(x_{i_1}, x_{i_2}, ..., \beta)\]</span>
Now, all that’s left is to code. Let’s dive right in to the first model.</p>
</div>
</div>
<div id="lm" class="section level2">
<h2>
<span class="header-section-number">11.2</span> <code>lm()</code>
</h2>
<p>First, we have to construct the linear regression model.</p>
<div class="sourceCode" id="cb986"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb986-1"><a href="continuous-response.html#cb986-1"></a>lm_model &lt;-</span>
<span id="cb986-2"><a href="continuous-response.html#cb986-2"></a><span class="st">    </span><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb986-3"><a href="continuous-response.html#cb986-3"></a><span class="st">    </span><span class="kw">set_engine</span>(<span class="st">"lm"</span>) <span class="op">%&gt;%</span></span>
<span id="cb986-4"><a href="continuous-response.html#cb986-4"></a><span class="st">    </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)</span></code></pre></div>
<p>Here, we are using the <strong><em>parsnip</em></strong> package to create an engine that can run this linear regression model easily and repeatedly. <code>linear_reg()</code> tells the engine that this is a linear regression. <code>set_engine("lm")</code> tells the engine to use the <code>lm()</code> function. <code>set_mode()</code> has to options, “regression” and “classification”. Since our left-hand variable is a continuous one, we will set it to “regression”. If it were categorical, we would set the mode to “classification”.</p>
<p>Fit the model to the data. We will first create a regression formula and save it as an R object for future recall. There are a lot of different combinations we could use for the formula, but which will yield the <em>best</em> model? In previous chapters, we discussed this dilemma. For now, we will build a full model containing all of the predictor variables and some interactions.</p>
<div class="sourceCode" id="cb987"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb987-1"><a href="continuous-response.html#cb987-1"></a>full_form &lt;-<span class="st"> </span><span class="kw">formula</span>(ideology <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>state <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education)</span></code></pre></div>
<div class="sourceCode" id="cb988"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb988-1"><a href="continuous-response.html#cb988-1"></a><span class="kw">fit</span>(lm_model, full_form, ch11_training)</span></code></pre></div>
<p>Note that we can use <code>tidy()</code>, just like we did in previous chapters, to take a look at the results:</p>
<div class="sourceCode" id="cb989"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb989-1"><a href="continuous-response.html#cb989-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb989-2"><a href="continuous-response.html#cb989-2"></a><span class="kw">fit</span>(lm_model, full_form, ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb989-3"><a href="continuous-response.html#cb989-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb989-4"><a href="continuous-response.html#cb989-4"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<pre><code>## # A tibble: 73 x 4
##    term                estimate conf.low conf.high
##    &lt;chr&gt;                  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept)          0.838    -3.19       4.87 
##  2 genderMale           0.361     0.205      0.518
##  3 genderOther         -0.960    -2.58       0.658
##  4 raceBlack           -1.79     -2.33      -1.25 
##  5 raceHispanic        -0.695    -1.22      -0.166
##  6 raceNative American -0.300    -1.50       0.905
##  7 raceOther            0.00288  -0.603      0.608
##  8 raceWhite            0.447    -0.0282     0.922
##  9 stateAL             -0.910    -4.86       3.04 
## 10 stateAR             -2.18     -6.12       1.75 
## # … with 63 more rows</code></pre>
<p>How do we know if this is a good model? We can check using cross-validation. Cross-validation seeks to minimizes the MSE (mean squared error) of its predicted and real outcomes. There are two important characteristics of the MSE we should always keep in mind:</p>
<ol style="list-style-type: decimal">
<li><p>We can think our estimate of the MSE is a random variable. For example, the dataset we have may be a random sample from a larger population. An algorithm may have a lower apparent error than another algorithm due to luck.</p></li>
<li><p>If we train an algorithm on the same dataset that we use to compute the MSE, we might be overtraining. In general, when we do this, the apparent error will be an underestimate of the true error.</p></li>
</ol>
<p>Cross validation is a technique that permits us to alleviate both these problems. To understand cross validation, it helps to think of the <em>true error</em>, a theoretical quantity, as the average of many <em>apparent errors</em> obtained by applying the algorithm to new random samples of the data, none of them used to train the algorithm.</p>
<p>However, we only have available one set of outcomes: the ones we actually observed. Cross validation is based on the idea of generating a series of different random samples on which to apply our algorithm. There are several approaches we can use, but the general idea for all of them is to randomly generate smaller datasets that are not used for training, and instead used to estimate the true error.</p>
<div id="k-fold-cross-validation" class="section level3">
<h3>
<span class="header-section-number">11.2.1</span> K-Fold Cross-validation</h3>
<p>Generally speaking, a machine learning challenge starts with a dataset. We need to build an algorithm using this dataset that will eventually be used in completely independent datasets.</p>
<p>So to imitate this situation, we carve out a piece of our dataset and pretend it is an independent dataset: previously, we divided the dataset into a <em>training set</em> and a <em>test set</em>. We will train our algorithm exclusively on the training set and use the test set <em>only for evaluation purposes</em>.</p>
<p>We usually try to select a small piece of the dataset so that we have as much data as possible to train. However, we also want the test set to be large so that we obtain a stable estimate of the loss without fitting an impractical number of models. The <code>initial_split()</code> function reserves 25% of the data for testing by default.</p>
<p>Remember, we cannot touch the testing set! One way we can check whether the model we created works is to use cross-validation, which avoids the problem of overtraining by splitting the data into smaller sections. We’ll show you how to do using the <strong><em>rsample</em></strong> package.</p>
<p>The function <code>vfold_cv()</code> splits your training set into <code>v</code>, a specified number of smaller sections. The most common values for <code>v</code> are 5 and 10. To keep things simple, we will be using <code>v = 5</code> to keep the individual sections large enough to accurately train the models. The first four folds will be used to train the model, and the last fold is always used to assess the accuracy of the model.</p>
<p>Below, we will create a new object called <code>ch11_folds</code> that contains equally sized sections of <code>ch11_training</code>.</p>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb991-1"><a href="continuous-response.html#cb991-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb991-2"><a href="continuous-response.html#cb991-2"></a>ch11_folds &lt;-<span class="st"> </span>ch11_training <span class="op">%&gt;%</span></span>
<span id="cb991-3"><a href="continuous-response.html#cb991-3"></a><span class="st">  </span><span class="kw">vfold_cv</span>(<span class="dt">v =</span> <span class="dv">5</span>)</span></code></pre></div>
<p>How can we work with the <code>ch11_folds</code> object? <strong>tidymodels</strong> makes it easy by using the <code>fit_resamples()</code> function in the <strong>tune</strong> package. The <code>fit_resamples()</code> function takes as its first argument a model specification (such as <code>lm_model</code>). It takes a formula as its second argument, either in traditional form or as a <code>recipe()</code>.</p>
<p><label for="tufte-mn-64" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-64" class="margin-toggle"><span class="marginnote"><span style="display: block;">Recipes are what <strong><em>tidymodels</em></strong> use in lieu of defining a formula traditionally. <code>recipe()</code> is useful because you can define both the formula and any transformations you want to make with the data. Recipes are easily called and re-used, making it easy to use the same recipe with different models.</span>
<span style="display: block;">There are a number of useful functions that can be piped into recipes. One particularly useful family of functions is the family of step functions. These functions conduct a variety of transformations, from removing variables with high correlations to other variables (<code>step_corr()</code>) to adding in an interaction term (<code>step_interact()</code>). To learn more about recipes, you can visit the <a href="https://recipes.tidymodels.org/reference/index.html">Tidymodels website.</a></span></span></p>
<!-- EC: Commented out because not relevant: Usually, a simple formula without interaction terms can be plugged right in to `fit_resamples()`. However, ***tidymodels*** does not allow in-line functions in recipes, meaning we need to use a `step_*` function to add the interaction terms. Let's create our recipe. First, we define a formula without interaction terms. Then, using `step_interact()`, we add in the relevant interaction terms.   -->
<p>We need to convert all of the nominal variables, which are unordered character values, to dummy variables. Dummy variables are binary variables that are 1 when the categorical event occurs and 0 when it does not occur. For example, each level within <code>education</code> would be converted into its own variable, with the value 1 if the respondent had that level of education, and 0 otherwise.</p>
<div class="sourceCode" id="cb992"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb992-1"><a href="continuous-response.html#cb992-1"></a><span class="co"># formula_rec &lt;- recipe(ideology ~ gender + race + state + income + age + education, data = ch11_training) %&gt;%</span></span>
<span id="cb992-2"><a href="continuous-response.html#cb992-2"></a><span class="co">#   step_interact(terms = ~ gender*race + state*income) %&gt;%</span></span>
<span id="cb992-3"><a href="continuous-response.html#cb992-3"></a><span class="co">#   step_dummy(all_nominal())</span></span>
<span id="cb992-4"><a href="continuous-response.html#cb992-4"></a></span>
<span id="cb992-5"><a href="continuous-response.html#cb992-5"></a>formula_rec &lt;-<span class="st"> </span><span class="kw">recipe</span>(ideology <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>state <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb992-6"><a href="continuous-response.html#cb992-6"></a><span class="st">  </span><span class="kw">step_dummy</span>(<span class="kw">all_nominal</span>())</span></code></pre></div>
<p>Finally, the <code>resamples</code> argument is where you input the cross-validation dataset.</p>
<div class="sourceCode" id="cb993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb993-1"><a href="continuous-response.html#cb993-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb993-2"><a href="continuous-response.html#cb993-2"></a><span class="kw">fit_resamples</span>(<span class="dt">object =</span> lm_model,</span>
<span id="cb993-3"><a href="continuous-response.html#cb993-3"></a>              <span class="dt">preprocessor =</span> formula_rec,</span>
<span id="cb993-4"><a href="continuous-response.html#cb993-4"></a>              <span class="dt">resamples =</span> ch11_folds)</span></code></pre></div>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## ! Fold2: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## Warning: This tuning result has notes. Example notes on model fitting include:
## model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## # Resampling results
## # 5-fold cross-validation 
## # A tibble: 5 x 4
##   splits             id    .metrics         .notes          
##   &lt;list&gt;             &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          
## 1 &lt;split [2.1K/515]&gt; Fold1 &lt;tibble [2 × 3]&gt; &lt;tibble [0 × 1]&gt;
## 2 &lt;split [2.1K/515]&gt; Fold2 &lt;tibble [2 × 3]&gt; &lt;tibble [1 × 1]&gt;
## 3 &lt;split [2.1K/515]&gt; Fold3 &lt;tibble [2 × 3]&gt; &lt;tibble [0 × 1]&gt;
## 4 &lt;split [2.1K/515]&gt; Fold4 &lt;tibble [2 × 3]&gt; &lt;tibble [0 × 1]&gt;
## 5 &lt;split [2.1K/515]&gt; Fold5 &lt;tibble [2 × 3]&gt; &lt;tibble [0 × 1]&gt;</code></pre>
<p>Because the metrics are in list-columns, we can extract the average metrics across all the folds using the <code>collect_metrics()</code> function:</p>
<div class="sourceCode" id="cb1017"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1017-1"><a href="continuous-response.html#cb1017-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1017-2"><a href="continuous-response.html#cb1017-2"></a><span class="kw">fit_resamples</span>(lm_model,</span>
<span id="cb1017-3"><a href="continuous-response.html#cb1017-3"></a>              formula_rec,</span>
<span id="cb1017-4"><a href="continuous-response.html#cb1017-4"></a>              ch11_folds) <span class="op">%&gt;%</span></span>
<span id="cb1017-5"><a href="continuous-response.html#cb1017-5"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span></code></pre></div>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## ! Fold2: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## New names:
## * income_X17...33 -&gt; income_X17
## * income_X34...67 -&gt; income_X34
## * income_X68...95 -&gt; income_X68
## * income_X96...100 -&gt; income_X96</code></pre>
<pre><code>## New names:
## * age_X25...34 -&gt; age_X25
## * age_X35...44 -&gt; age_X35
## * age_X45...54 -&gt; age_X45
## * age_X55...64 -&gt; age_X55
## * age_X65...74 -&gt; age_X65</code></pre>
<pre><code>## # A tibble: 2 x 5
##   .metric .estimator  mean     n std_err
##   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1 rmse    standard   2.01      5  0.0321
## 2 rsq     standard   0.133     5  0.0171</code></pre>
<p>Now that we’ve viewed the cross-validation metrics, it’s time to use new data: namely, the testing set. Remember, we only touch the testing set for evaluation purposes. To apply our model to <code>ch11_testing</code>, use the <code>predict()</code> function.</p>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1040-1"><a href="continuous-response.html#cb1040-1"></a>lm_model <span class="op">%&gt;%</span></span>
<span id="cb1040-2"><a href="continuous-response.html#cb1040-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1040-3"><a href="continuous-response.html#cb1040-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_testing)</span></code></pre></div>
<pre><code>## # A tibble: 858 x 1
##     .pred
##     &lt;dbl&gt;
##  1 -2.09 
##  2  0.114
##  3  0.653
##  4  0.858
##  5  0.408
##  6  0.545
##  7 -1.28 
##  8  0.225
##  9 -2.25 
## 10  0.860
## # … with 848 more rows</code></pre>
<p>To extract the rmse, we set the “truth” to <code>ideology</code> so this function can compare our predicted values to the true values.</p>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="continuous-response.html#cb1042-1"></a>lm_model <span class="op">%&gt;%</span></span>
<span id="cb1042-2"><a href="continuous-response.html#cb1042-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1042-3"><a href="continuous-response.html#cb1042-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1042-4"><a href="continuous-response.html#cb1042-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1042-5"><a href="continuous-response.html#cb1042-5"></a><span class="st">  </span><span class="kw">rmse</span>(<span class="dt">truth =</span> ideology, <span class="dt">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        2.06</code></pre>
<p>The mean squared error is about 2.06.</p>
<p>What if we create completely new data outside of the testing set? Time to make up some imaginary people. Let’s say we have four individuals whose ideology in 2016 we wanted to predict. We can create a tibble with the values of their demographic information, like so:</p>
<!-- Just because you have a variable in this training data today, does not mean you are going to get it in your production data tomorrow. -->
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="continuous-response.html#cb1044-1"></a>new_people &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="st">"Name"</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">"Alice"</span>, <span class="st">"Bob"</span>, <span class="st">"Chelsea"</span>, <span class="st">"Darren"</span>),</span>
<span id="cb1044-2"><a href="continuous-response.html#cb1044-2"></a>                     <span class="st">"state"</span> =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">c</span>(<span class="st">"VA"</span>, <span class="st">"AL"</span>, <span class="st">"VA"</span>, <span class="st">"AL"</span>)),</span>
<span id="cb1044-3"><a href="continuous-response.html#cb1044-3"></a>                     <span class="st">"gender"</span> =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">c</span>(<span class="st">"Female"</span>, <span class="st">"Male"</span>, <span class="st">"Female"</span>, <span class="st">"Male"</span>)),</span>
<span id="cb1044-4"><a href="continuous-response.html#cb1044-4"></a>                     <span class="st">"income"</span> =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">c</span>(<span class="st">"34 - 67"</span>, <span class="st">"0 - 16"</span>, <span class="st">"34 - 67"</span>, <span class="st">"96 - 100"</span>)),</span>
<span id="cb1044-5"><a href="continuous-response.html#cb1044-5"></a>                     <span class="st">"age"</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">"35 - 44"</span>, <span class="st">"55 - 64"</span>, <span class="st">"35 - 44"</span>, <span class="st">"55 - 64"</span>),</span>
<span id="cb1044-6"><a href="continuous-response.html#cb1044-6"></a>                     <span class="st">"education"</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">"Elementary"</span>, <span class="st">"Highschool"</span>, <span class="st">"Adv. Degree"</span>, <span class="st">"Highschool"</span>),</span>
<span id="cb1044-7"><a href="continuous-response.html#cb1044-7"></a>                     <span class="st">"race"</span> =<span class="st"> </span><span class="kw">c</span>(<span class="st">"White"</span>, <span class="st">"White"</span>, <span class="st">"White"</span>, <span class="st">"White"</span>))</span></code></pre></div>
<p>Now, let’s predict each new person’s ideology using the linear regression model we just created.</p>
<div class="sourceCode" id="cb1045"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1045-1"><a href="continuous-response.html#cb1045-1"></a>lm_model <span class="op">%&gt;%</span></span>
<span id="cb1045-2"><a href="continuous-response.html#cb1045-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1045-3"><a href="continuous-response.html#cb1045-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> new_people) <span class="op">%&gt;%</span></span>
<span id="cb1045-4"><a href="continuous-response.html#cb1045-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(new_people) <span class="op">%&gt;%</span></span>
<span id="cb1045-5"><a href="continuous-response.html#cb1045-5"></a><span class="st">  </span><span class="kw">rename</span>(<span class="st">"ideology"</span> =<span class="st"> ".pred"</span>)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 8
##   ideology Name    state gender income   age     education   race 
##      &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;
## 1   -0.629 Alice   VA    Female 34 - 67  35 - 44 Elementary  White
## 2    1.88  Bob     AL    Male   0 - 16   55 - 64 Highschool  White
## 3   -0.327 Chelsea VA    Female 34 - 67  35 - 44 Adv. Degree White
## 4    2.40  Darren  AL    Male   96 - 100 55 - 64 Highschool  White</code></pre>
<p>As you can see, the two women, Alice and Chelsea, have similar values for their variables save for one: education. Alice is educated at the elementary level, whereas Chelsea holds an advanced degree. Their predicted ideologies are 2.22 and 2.42 respectively, showing that a 35-44 year old white woman from Virginia who approved of the sitting President in 2016 with an advanced degree was on average 0.20 more conservative than her counterpart with an elementary degree.</p>
<p>Meanwhile, white 55-64 year old men with high school diplomas from Alabama differ in their income; Bob is two standard deviations above average, whereas Darren is two standard deviations below average in earnings. All else held equal, Bob’s ideology was estimated to be more conservative than Darren’s by 0.13. Let’s see if these observations hold up with our other models.</p>
</div>
</div>
<div id="using-stan_glm" class="section level2">
<h2>
<span class="header-section-number">11.3</span> Using <code>stan_glm()</code>
</h2>
<p>The <strong><em>rstanarm</em></strong> package contains a lot of powerful functions that conduct Bayesian data analysis by using priors. One such function is <code>stan_glm()</code>, which you can think of as the Bayesian way of fitting a regression model.</p>
<p>We will be following the exact same steps as before. First, we will construct a <strong><em>parsnip</em></strong> model that uses the “stan” engine.</p>
<div class="sourceCode" id="cb1047"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1047-1"><a href="continuous-response.html#cb1047-1"></a><span class="kw">library</span>(rstanarm)</span>
<span id="cb1047-2"><a href="continuous-response.html#cb1047-2"></a></span>
<span id="cb1047-3"><a href="continuous-response.html#cb1047-3"></a>stan_model &lt;-</span>
<span id="cb1047-4"><a href="continuous-response.html#cb1047-4"></a><span class="st">    </span><span class="kw">linear_reg</span>() <span class="op">%&gt;%</span></span>
<span id="cb1047-5"><a href="continuous-response.html#cb1047-5"></a><span class="st">    </span><span class="kw">set_engine</span>(<span class="st">"stan"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1047-6"><a href="continuous-response.html#cb1047-6"></a><span class="st">    </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>)</span></code></pre></div>
<p>Next, let’s fit this model using the formula we specified before. We can select for the relevant terms after using <code>tidy()</code> to make our tibble viewable.</p>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1048-1"><a href="continuous-response.html#cb1048-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1048-2"><a href="continuous-response.html#cb1048-2"></a><span class="kw">fit</span>(stan_model, full_form, ch11_training)</span></code></pre></div>
<pre><code>## parsnip model object
## 
## Fit time:  18.5s 
## stan_glm
##  family:       gaussian [identity]
##  formula:      ideology ~ gender + race + state + income + age + education
##  observations: 2575
##  predictors:   73
## ------
##                          Median MAD_SD
## (Intercept)               0.5    1.9  
## genderMale                0.4    0.1  
## genderOther              -0.9    0.8  
## raceBlack                -1.8    0.3  
## raceHispanic             -0.7    0.3  
## raceNative American      -0.3    0.6  
## raceOther                 0.0    0.3  
## raceWhite                 0.4    0.2  
## stateAL                  -0.5    1.9  
## stateAR                  -1.8    1.9  
## stateAZ                  -1.6    1.8  
## stateCA                  -2.1    1.8  
## stateCO                  -2.0    1.8  
## stateCT                  -2.1    1.8  
## stateDE                  -2.3    2.0  
## stateFL                  -1.7    1.8  
## stateGA                  -1.4    1.8  
## stateHI                  -2.2    2.0  
## stateIA                  -1.1    1.9  
## stateID                  -1.8    1.8  
## stateIL                  -2.4    1.8  
## stateIN                  -1.7    1.8  
## stateKS                  -2.0    1.8  
## stateKY                  -1.8    1.9  
## stateLA                  -1.3    1.8  
## stateMA                  -2.4    1.8  
## stateMD                  -2.2    1.8  
## stateME                  -1.2    1.9  
## stateMI                  -2.2    1.8  
## stateMN                  -2.6    1.8  
## stateMO                  -1.9    1.8  
## stateMS                  -2.1    1.8  
## stateMT                  -1.7    1.9  
## stateNC                  -1.8    1.8  
## stateND                  -0.5    2.0  
## stateNE                  -2.3    1.9  
## stateNH                  -2.7    1.9  
## stateNJ                  -2.5    1.8  
## stateNM                  -1.4    1.9  
## stateNV                  -1.6    1.8  
## stateNY                  -2.1    1.8  
## stateOH                  -1.7    1.8  
## stateOK                  -1.4    1.8  
## stateOR                  -3.0    1.9  
## statePA                  -2.4    1.8  
## stateRI                  -2.9    2.1  
## stateSC                  -1.7    1.8  
## stateSD                  -2.0    1.9  
## stateTN                  -1.4    1.8  
## stateTX                  -1.4    1.8  
## stateUT                  -2.0    1.9  
## stateVA                  -1.5    1.8  
## stateVT                  -3.2    2.0  
## stateWA                  -2.7    1.8  
## stateWI                  -2.2    1.8  
## stateWV                  -2.1    1.9  
## stateWY                  -1.5    2.1  
## income17 - 33            -0.1    0.1  
## income34 - 67             0.2    0.1  
## income68 - 95             0.3    0.1  
## income96 - 100            0.5    0.3  
## age25 - 34                0.0    0.2  
## age35 - 44               -0.2    0.2  
## age45 - 54                0.0    0.2  
## age55 - 64                0.1    0.2  
## age65 - 74                0.0    0.2  
## age75 +                   0.2    0.2  
## educationSome Highschool  0.7    0.5  
## educationHighschool       1.0    0.5  
## educationHighschool +     1.2    0.5  
## educationSome College     1.1    0.5  
## educationCollege          1.1    0.5  
## educationAdv. Degree      0.3    0.5  
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 2.0    0.0   
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="continuous-response.html#cb1050-1"></a>  <span class="co"># tidy() %&gt;%</span></span>
<span id="cb1050-2"><a href="continuous-response.html#cb1050-2"></a>  <span class="co"># select(term, estimate, std.error)</span></span></code></pre></div>
<!-- EC: How to fix  $ operator is invalid for atomic vectors error that occurs with tidy? -->
<div id="verifying-fit-using-cross-validation" class="section level3">
<h3>
<span class="header-section-number">11.3.1</span> Verifying fit using cross-validation</h3>
<p>Let’s practice K-Fold validation with the <code>stan</code> model.</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="continuous-response.html#cb1051-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1051-2"><a href="continuous-response.html#cb1051-2"></a><span class="kw">fit_resamples</span>(<span class="dt">object =</span> stan_model,</span>
<span id="cb1051-3"><a href="continuous-response.html#cb1051-3"></a>              <span class="dt">preprocessor =</span> formula_rec,</span>
<span id="cb1051-4"><a href="continuous-response.html#cb1051-4"></a>              <span class="dt">resamples =</span> ch11_folds)</span></code></pre></div>
<div class="sourceCode" id="cb1052"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1052-1"><a href="continuous-response.html#cb1052-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1052-2"><a href="continuous-response.html#cb1052-2"></a><span class="kw">fit_resamples</span>(stan_model,</span>
<span id="cb1052-3"><a href="continuous-response.html#cb1052-3"></a>              formula_rec,</span>
<span id="cb1052-4"><a href="continuous-response.html#cb1052-4"></a>              ch11_folds) <span class="op">%&gt;%</span></span>
<span id="cb1052-5"><a href="continuous-response.html#cb1052-5"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span></code></pre></div>
<p>Let’s test the stan model using our four <code>new_people</code>.</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="continuous-response.html#cb1053-1"></a>stan_model <span class="op">%&gt;%</span></span>
<span id="cb1053-2"><a href="continuous-response.html#cb1053-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1053-3"><a href="continuous-response.html#cb1053-3"></a><span class="st">  </span><span class="kw">predict</span>(new_people) <span class="op">%&gt;%</span></span>
<span id="cb1053-4"><a href="continuous-response.html#cb1053-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(new_people) <span class="op">%&gt;%</span></span>
<span id="cb1053-5"><a href="continuous-response.html#cb1053-5"></a><span class="st">  </span><span class="kw">rename</span>(<span class="st">"ideology"</span> =<span class="st"> ".pred"</span>)</span></code></pre></div>
<p>What if we created a bunch of different formulas that used different permutations of predictor variables? For example, one would exclude <code>state</code>, which has 50 different levels.</p>
<p>First, let’s create a basic formula that only takes in <code>race</code>.</p>
<div class="sourceCode" id="cb1054"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1054-1"><a href="continuous-response.html#cb1054-1"></a>race_form &lt;-<span class="st"> </span><span class="kw">formula</span>(ideology <span class="op">~</span><span class="st"> </span>race)</span></code></pre></div>
<p>Next, we can use <code>update()</code> to create the more complicated formulas. <code>update()</code> takes as its first argument a formula and as its second argument the additions you want to make. To keep all the predictors from the first formula and add more, you will start with <code>~ . +</code> and then add more predictors, like so:</p>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="continuous-response.html#cb1055-1"></a>race_gender_form &lt;-<span class="st"> </span><span class="kw">update</span>(race_form,</span>
<span id="cb1055-2"><a href="continuous-response.html#cb1055-2"></a>                    <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>race<span class="op">:</span>gender)</span>
<span id="cb1055-3"><a href="continuous-response.html#cb1055-3"></a></span>
<span id="cb1055-4"><a href="continuous-response.html#cb1055-4"></a>demo_form &lt;-<span class="st"> </span><span class="kw">formula</span>(ideology <span class="op">~</span><span class="st"> </span>race <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>education)</span>
<span id="cb1055-5"><a href="continuous-response.html#cb1055-5"></a></span>
<span id="cb1055-6"><a href="continuous-response.html#cb1055-6"></a>interact_form &lt;-<span class="st"> </span><span class="kw">update</span>(race_gender_form,</span>
<span id="cb1055-7"><a href="continuous-response.html#cb1055-7"></a>                        <span class="op">~</span><span class="st"> </span>. <span class="op">+</span><span class="st"> </span>income<span class="op">*</span>age <span class="op">+</span><span class="st"> </span>education)</span></code></pre></div>
<p>Next, we will save these different formulas, along with the original <code>interact_form</code>, in a tibble to easily remember and recall the formulas.</p>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="continuous-response.html#cb1056-1"></a>ch11_formulas &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">formula =</span> <span class="kw">c</span>(race_form,</span>
<span id="cb1056-2"><a href="continuous-response.html#cb1056-2"></a>                                   race_gender_form,</span>
<span id="cb1056-3"><a href="continuous-response.html#cb1056-3"></a>                                   demo_form,</span>
<span id="cb1056-4"><a href="continuous-response.html#cb1056-4"></a>                                   full_form,</span>
<span id="cb1056-5"><a href="continuous-response.html#cb1056-5"></a>                                   interact_form),</span>
<span id="cb1056-6"><a href="continuous-response.html#cb1056-6"></a>                       <span class="dt">group =</span> <span class="kw">c</span>(<span class="st">"Race only model"</span>,</span>
<span id="cb1056-7"><a href="continuous-response.html#cb1056-7"></a>                                 <span class="st">"Race and gender model"</span>,</span>
<span id="cb1056-8"><a href="continuous-response.html#cb1056-8"></a>                                 <span class="st">"Demographic model"</span>,</span>
<span id="cb1056-9"><a href="continuous-response.html#cb1056-9"></a>                                 <span class="st">"Full model without interaction"</span>,</span>
<span id="cb1056-10"><a href="continuous-response.html#cb1056-10"></a>                                 <span class="st">"Sensible interaction model"</span>))</span></code></pre></div>
<p>Now, we can use <code>map_*</code> to apply all of these models and view their metrics to see which ones have the lowest rmse values.</p>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1057-1"><a href="continuous-response.html#cb1057-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1057-2"><a href="continuous-response.html#cb1057-2"></a>folds_metrics&lt;-<span class="st"> </span>ch11_formulas <span class="op">%&gt;%</span></span>
<span id="cb1057-3"><a href="continuous-response.html#cb1057-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">metrics =</span> <span class="kw">map</span>(formula, <span class="op">~</span><span class="st"> </span><span class="kw">fit_resamples</span>(<span class="dt">object =</span> lm_model,</span>
<span id="cb1057-4"><a href="continuous-response.html#cb1057-4"></a>                                                <span class="dt">preprocessor =</span> .,</span>
<span id="cb1057-5"><a href="continuous-response.html#cb1057-5"></a>                                                <span class="dt">resamples =</span> ch11_folds) <span class="op">%&gt;%</span></span>
<span id="cb1057-6"><a href="continuous-response.html#cb1057-6"></a><span class="st">                         </span><span class="kw">collect_metrics</span>()))</span></code></pre></div>
<pre><code>## ! Fold1: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold2: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold3: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold4: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold5: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold2: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold1: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold2: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold3: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold4: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<pre><code>## ! Fold5: model (predictions): prediction from a rank-deficient fit may be misleading</code></pre>
<p>Let’s present the results stored in our <code>folds_metrics</code> object. We are simply extracting the <code>rmse</code> metric from each formula:</p>
<div class="sourceCode" id="cb1069"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1069-1"><a href="continuous-response.html#cb1069-1"></a>folds_metrics <span class="op">%&gt;%</span></span>
<span id="cb1069-2"><a href="continuous-response.html#cb1069-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mean_rmse =</span> <span class="kw">map_dbl</span>(metrics, <span class="op">~</span><span class="st"> </span><span class="kw">filter</span>(., .metric <span class="op">==</span><span class="st"> "rmse"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(mean)),</span>
<span id="cb1069-3"><a href="continuous-response.html#cb1069-3"></a>         <span class="dt">se_rmse =</span> <span class="kw">map_dbl</span>(metrics, <span class="op">~</span><span class="st"> </span><span class="kw">filter</span>(., .metric <span class="op">==</span><span class="st"> "rmse"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(std_err))) <span class="op">%&gt;%</span></span>
<span id="cb1069-4"><a href="continuous-response.html#cb1069-4"></a><span class="st">  </span><span class="kw">select</span>(group, mean_rmse, se_rmse)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 3
##   group                          mean_rmse se_rmse
##   &lt;chr&gt;                              &lt;dbl&gt;   &lt;dbl&gt;
## 1 Race only model                     2.04  0.0232
## 2 Race and gender model               2.03  0.0246
## 3 Demographic model                   2.02  0.0281
## 4 Full model without interaction      2.01  0.0321
## 5 Sensible interaction model          2.04  0.0315</code></pre>
<p>Looking at the results, all of the formulas seem to yield a relatively close mean <code>rmse</code>.</p>
<p>The models with the lowest rmse values seem to be the Full model without interaction and the Demographic model. The Demographic model includes the following variables:</p>
<ul>
<li><code>education</code></li>
<li><code>race</code></li>
<li><code>gender</code></li>
<li><code>age</code></li>
<li><code>income</code></li>
</ul>
<p>It is very similar to the Full model without interaction, which includes <code>state</code> in addition.</p>
<p>Let’s test the Demographic model on the testing set.</p>
<div class="sourceCode" id="cb1071"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1071-1"><a href="continuous-response.html#cb1071-1"></a>lm_model <span class="op">%&gt;%</span></span>
<span id="cb1071-2"><a href="continuous-response.html#cb1071-2"></a><span class="st">  </span><span class="kw">fit</span>(demo_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1071-3"><a href="continuous-response.html#cb1071-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_testing)</span></code></pre></div>
<pre><code>## # A tibble: 858 x 1
##      .pred
##      &lt;dbl&gt;
##  1 -1.67  
##  2  0.591 
##  3  0.232 
##  4  0.581 
##  5  0.0230
##  6  0.0651
##  7 -0.659 
##  8  0.641 
##  9 -1.76  
## 10  0.719 
## # … with 848 more rows</code></pre>
<p>To extract the rmse, we set the “truth” to <code>ideology</code> so this function can compare our predicted values to the true values.</p>
<div class="sourceCode" id="cb1073"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1073-1"><a href="continuous-response.html#cb1073-1"></a>lm_model <span class="op">%&gt;%</span></span>
<span id="cb1073-2"><a href="continuous-response.html#cb1073-2"></a><span class="st">  </span><span class="kw">fit</span>(demo_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1073-3"><a href="continuous-response.html#cb1073-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1073-4"><a href="continuous-response.html#cb1073-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1073-5"><a href="continuous-response.html#cb1073-5"></a><span class="st">  </span><span class="kw">rmse</span>(<span class="dt">truth =</span> ideology, <span class="dt">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        2.09</code></pre>
</div>
</div>
<div id="using-a-neural-network" class="section level2">
<h2>
<span class="header-section-number">11.4</span> Using a neural network</h2>
<p>Let’s dive into the world of machine learning. Neural networks are useful for mimicking how humans make decisions. Thanks to the <strong><em>parsnip</em></strong> package, there are functions available that can fit regression models using neural networks.</p>
<p>Let’s create the neural network engine.</p>
<div class="sourceCode" id="cb1075"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1075-1"><a href="continuous-response.html#cb1075-1"></a>nnet_model &lt;-<span class="st"> </span><span class="kw">mlp</span>(<span class="dt">hidden_units =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span></span>
<span id="cb1075-2"><a href="continuous-response.html#cb1075-2"></a><span class="st">  </span><span class="kw">set_mode</span>(<span class="st">"regression"</span>) <span class="op">%&gt;%</span></span>
<span id="cb1075-3"><a href="continuous-response.html#cb1075-3"></a><span class="st">  </span><span class="kw">set_engine</span>(<span class="st">"nnet"</span>)</span>
<span id="cb1075-4"><a href="continuous-response.html#cb1075-4"></a></span>
<span id="cb1075-5"><a href="continuous-response.html#cb1075-5"></a>nnet_model <span class="op">%&gt;%</span></span>
<span id="cb1075-6"><a href="continuous-response.html#cb1075-6"></a><span class="st">  </span><span class="kw">translate</span>()</span></code></pre></div>
<pre><code>## Single Layer Neural Network Specification (regression)
## 
## Main Arguments:
##   hidden_units = 5
## 
## Computational engine: nnet 
## 
## Model fit template:
## nnet::nnet(formula = missing_arg(), data = missing_arg(), weights = missing_arg(), 
##     size = 5, trace = FALSE, linout = TRUE)</code></pre>
<p>Next, let’s fit the model.</p>
<!-- EC: Tidy method for nnet doesn't exist? -->
<div class="sourceCode" id="cb1077"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1077-1"><a href="continuous-response.html#cb1077-1"></a>nnet_model <span class="op">%&gt;%</span></span>
<span id="cb1077-2"><a href="continuous-response.html#cb1077-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1077-3"><a href="continuous-response.html#cb1077-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb1077-4"><a href="continuous-response.html#cb1077-4"></a><span class="st">  </span><span class="kw">select</span>(term, estimate, conf.low, conf.high)</span></code></pre></div>
<div id="verifying-fit-with-cross-validation" class="section level3">
<h3>
<span class="header-section-number">11.4.1</span> Verifying fit with cross-validation</h3>
<p>Let’s cross-validate our predictions using <code>vfold_cv()</code>.</p>
<div class="sourceCode" id="cb1078"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1078-1"><a href="continuous-response.html#cb1078-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1078-2"><a href="continuous-response.html#cb1078-2"></a><span class="kw">fit_resamples</span>(<span class="dt">object =</span> nnet_model,</span>
<span id="cb1078-3"><a href="continuous-response.html#cb1078-3"></a>              <span class="dt">preprocessor =</span> formula_rec,</span>
<span id="cb1078-4"><a href="continuous-response.html#cb1078-4"></a>              <span class="dt">resamples =</span> ch11_folds)</span></code></pre></div>
<div class="sourceCode" id="cb1079"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1079-1"><a href="continuous-response.html#cb1079-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb1079-2"><a href="continuous-response.html#cb1079-2"></a><span class="kw">fit_resamples</span>(nnet_model,</span>
<span id="cb1079-3"><a href="continuous-response.html#cb1079-3"></a>              formula_rec,</span>
<span id="cb1079-4"><a href="continuous-response.html#cb1079-4"></a>              ch11_folds) <span class="op">%&gt;%</span></span>
<span id="cb1079-5"><a href="continuous-response.html#cb1079-5"></a><span class="st">  </span><span class="kw">collect_metrics</span>()</span></code></pre></div>
</div>
<div id="predicting-new-data" class="section level3">
<h3>
<span class="header-section-number">11.4.2</span> Predicting new data</h3>
<p>Lastly, let’s apply our neural network model to the testing set.</p>
<div class="sourceCode" id="cb1080"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1080-1"><a href="continuous-response.html#cb1080-1"></a>nnet_model <span class="op">%&gt;%</span></span>
<span id="cb1080-2"><a href="continuous-response.html#cb1080-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1080-3"><a href="continuous-response.html#cb1080-3"></a><span class="st">  </span><span class="kw">predict</span>(<span class="dt">new_data =</span> ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1080-4"><a href="continuous-response.html#cb1080-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(ch11_testing) <span class="op">%&gt;%</span></span>
<span id="cb1080-5"><a href="continuous-response.html#cb1080-5"></a><span class="st">  </span><span class="kw">rmse</span>(<span class="dt">truth =</span> ideology, <span class="dt">estimate =</span> .pred)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        2.25</code></pre>
<p>Now, let’s predict each new person’s ideology using the <code>nnet</code> model we created, like before.</p>
<div class="sourceCode" id="cb1082"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1082-1"><a href="continuous-response.html#cb1082-1"></a>nnet_model <span class="op">%&gt;%</span></span>
<span id="cb1082-2"><a href="continuous-response.html#cb1082-2"></a><span class="st">  </span><span class="kw">fit</span>(full_form, <span class="dt">data =</span> ch11_training) <span class="op">%&gt;%</span></span>
<span id="cb1082-3"><a href="continuous-response.html#cb1082-3"></a><span class="st">  </span><span class="kw">predict</span>(new_people) <span class="op">%&gt;%</span></span>
<span id="cb1082-4"><a href="continuous-response.html#cb1082-4"></a><span class="st">  </span><span class="kw">bind_cols</span>(new_people) <span class="op">%&gt;%</span></span>
<span id="cb1082-5"><a href="continuous-response.html#cb1082-5"></a><span class="st">  </span><span class="kw">rename</span>(<span class="st">"ideology"</span> =<span class="st"> ".pred"</span>)</span></code></pre></div>
</div>
</div>
<div id="model-selection" class="section level2">
<h2>
<span class="header-section-number">11.5</span> Model selection</h2>
<p>By now, we have created three different linear regression models: one using the <code>lm</code> engine, one using the Bayesian <code>stan</code> engine, and one using the machine learning <code>nnet</code> engine. We have also explored K-fold cross-validation to verify the fit of the model on out-of-sample data. Lastly, we’ve seen how variable selection can change our models.</p>
<p>So many options! How do we choose which model is the best?</p>
<p>First, we should only favor more complex models (or formulas) if the additional complexity is <em>warranted</em>. This is a philosophical principle known as “Occam’s Razor.” It states that, “all other things being equal, simpler solutions are more likely to be correct than complex ones.” When viewed in a modeling framework, Occam’s Razor can be restated as, “all other things being equal, simpler models are to be preferred over complex ones.” In other words, we should only favor the more complex model/formula if the additional complexity is <em>warranted</em>.</p>
<p>Secondly, we have two quantitative metrics to help guide our decision: the <code>rmse</code> and <code>rsq</code> values. Lower <code>rmse</code> values are more desired because they indicate a higher accuracy in predicting the outcome variable. Higher <code>rsq</code> values are better because that means that more of the variation in the dataset can be explained by the predictor variables in the formula.</p>
<p>However, remember that <code>rmse</code> and <code>rsq</code> values are not end-all-be-all. There are other ways to to determine the best model: Did it predict low ideologies well? What about high ideologies? Did it do a good job of generally sorting people into the right end of politically liberal or politically conservative? Were there frequent outlandish answers generated, such as a quantity of <code>ideology</code> too high to exist?</p>
</div>
<div id="wrap-up" class="section level2">
<h2>
<span class="header-section-number">11.6</span> Wrap-Up</h2>
<p>So, how can we predict someone’s ideology based off of other information?</p>
<ul>
<li><code>pres_appr</code></li>
<li>trends in <code>age</code>, <code>income</code>, <code>gender</code>, <code>race</code>, <code>education</code>
</li>
<li>caveat interaction variables</li>
<li>caveat applying to other data before 2016</li>
</ul>
<!-- Outline: --><!-- 1) Preamble: Intro paragraph to classification in general, both 0/1 and multiple categories. Discuss different approaches, all for solving the same problem. --><!-- 2) EDA of cces (meaning just the columns we care about). Start with the usual EDA of the subset of cces data which we are using (only 2018 for now), which will be state, age, gender, race, education.   --><!-- 3) Logistic Regression. Go through all our themes. --><!-- 4) CART --><!-- 5) Random Forest --><!-- 6) Comparing the models. Advice. --><!-- 7) Multi-category question. Deep learning. --><!-- Other stuff: --><!-- * tidymodels always. stan_glm from the start. Cover the highlights on Gelman. Divide by 4. predictions are all matter. don't bother with posterior_linpred().  --><!-- * Then CART using tidymodels on exactly this data and this problem. Maybe we go slowly, showing how CART works with one variable (numeric and categorical) first. Or maybe we just go straight to the full model.  --><!-- * Then random forests using tidymodels on exactly this data and this problem. --><!-- * Do we have time to explore Gelman's magic trick: Showing the values of key coefficients when the model is refit to each year separately? That is, how much is age associated with being conservative over time? I hope so! But maybe not. --><!-- * Do we have time to do a model which predicts a category with more than 0/1 possible values? I am not sure. If we were going to, we would want to pick something that is not an ordered category, I think. In this data, only race would meet that criteria. Let's revisit this later. -->
</div>
</div></body></html>

<p style="text-align: center;">
<a href="pitfalls.html"><button class="btn btn-default">Previous</button></a>
<a href="discrete-response.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-11
</p>
</div>
</div>



</body>
</html>
