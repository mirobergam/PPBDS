<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 6 One Parameter | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 6 One Parameter | Gov 50: Data">

<title>Chapter 6 One Parameter | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a id="active-page" href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a><ul class="toc-sections">
<li class="toc"><a href="#sampling-activity"> Real sampling activity</a></li>
<li class="toc"><a href="#sampling-simulation"> Virtual sampling</a></li>
<li class="toc"><a href="#returning-to-our-question"> Returning to our question</a></li>
<li class="toc"><a href="#sampling-framework"> Sampling framework</a></li>
<li class="toc"><a href="#sampling-case-study"> Case study: Polls</a></li>
<li class="toc"><a href="#sampling-mechanism"> Sampling Mechanism</a></li>
<li class="toc"><a href="#key-themes"> Key Themes</a></li>
<li class="toc"><a href="#conclusion"> Conclusion</a></li>
</ul>
<a href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="pitfalls.html"><span class="toc-section-number">10</span> Pitfalls</a>
<a href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="rubin-causal-model.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="one-parameter" class="section level1">
<h1>
<span class="header-section-number">Chapter 6</span> One Parameter</h1>
<!-- Priorities:  -->
<!-- 1) Fix Eddard Stark quote. Perhaps: "One does not simply sample . . . without understanding the sampling distribution. REMOVED FOR NOW. -->
<!-- 2) Switch bead_ID to ID, throughout, including all table. The columns with names/numbers/whatever is always "ID". DONE. -->
<!-- 3) Add red line for root(n) to figure 17. Trick is stat_function: https://ggplot2.tidyverse.org/reference/stat_function.html. QUESTION BELOW.-->
<!-- 4) Add the four themes to the Obama poll example. Prudence, the notion "validity". Is the data I have relevant to my real question? You never really care about what someone answers to a survey, because IT JUST DOESN't MATTER. Justice: Assumptions. Courage. Temperance. "humility". Include the jpg of each in the side margin, just like in chapter 3. MOSTLY DONE. -->
<!-- 5) There are two "previously seen" versions of the main plot. Is that sensible? Or a sign of bad organization? Feel free to keep all three, but make a code comment to explain you reasoning as a benefit to future authors. -->
<!-- 6) Add a discussion  about the tradeoffs between accuracy/precision, also known as bias/variance. This is important stuff. Give an example where you might want more bias in return for lower variance. Make it concrete. Run a simulation. Use fake costs/benefit numbers, perhaps. Or maybe we discuss this under Prudence? Or maybe under Courage? -->
<!-- 1) Make a 15 second video, put it on YouTube, add it as as sidemargin. "We don't estimate parameters because we care about parameters. Parameters are imaginary! Like unicorns! [Put finger on forehead and imitate unicorn.] We estimate parameters to build Data Generating Mechanisms. And with a DGM, you can move the world!" NOTE: will do when I can get access to better internet. -->
<!-- 3) What is the posterior for the number of red beads? **What is your posterior distribution for p, which is the same thing as number of red beads divided by 2400?** Everything has been frequentist so far. Nothing has been Bayesian yet.  Connect to joint distribution, marginal distribution, posterior distribution. One new complexity with the notion of the "model" is that we can "parameterize" the same thing in different ways. We want to show that. First, we parameterize it in the same way as chapter 5. There is a p, which can have certain values, but we restrict the set of possible values. Although perhaps making it different from previously. Maybe 0 to 1 by 0.05, so 21 values. Then we do the same thing as before, look at one sample from the urn, look at the marginal distribution, posterior predict the outcomes of the next draw, and so on. Just like before. We might make the transition from this case to the next by noting two things:  First, even though we often assume that p is continuous, it never really is. In this case, since we are told that there are 2400 beads, p can only take on 2401 possible values. Second, we can (sort of!) use some prior knowledge by noting that values near p = 0 and p = 1 are impossible. Just look at the urn! It is wasteful to even consider those possibilities in doing our analysis. Better to consider more values of p in a more plausible range. Our second parameterization might, instead of looking at p, look at specific values of the number of red beans (out of 2400), chosen from near where we thing the truth might be. These are now the numbers of the y-axis. Note how this elides the distinction between a "model" and the "data". (Keep in mind that the data in the x-axis the data we gathered in our experiment.) The data of the number of red beads in the urn is an empirical reality of the world, something independent of us and our experiment. "Model" just means "Assumption about the world." Same steps afterward as above, although maybe more precise, since we have narrowed our search.  -->
<!-- 2) Set up Zoom with Vivian. Draw direct connection to her coin example. Advice about how to create your joint distribution. Do it simple first. Meaning only every 100 beads. Only 25 models. But you can have 51 possible data results of the experiment. We need to provide a Bayes scatterplot which is the next step in complexity from the ones we finished with in chapter 5. The x-axis is the number of red beads pulled in the sample, a number which varies from 0 to 25. (And we can discuss how different paddles would lead to different displays.) The y-axis is the model. -->
<!-- 3) Set up Zoom with Tahmid. Talk about how your discussion of Tables connects to his. Maybe you don't discuss the Data Generating Mechanism. Or you do? Recall what we are trying to accomplish? What questions did the chapter start with? DONE. -->
<!-- For later: -->
<!-- Does the map_ function stuff go too fast? Go through the interim steps more slowly, examining each of the new columns? -->
<!-- Without what range would you offer 50/50 odds that the true percentage lies? -->
<!-- Revisit Albert's functions. Is it OK that urn is just treated as a global variable? Or should it be passed in as an argument. Also, are two functions really necessary? -->
<!-- Discuss hypothesis tests and why we hate them. See style.Rmd for details. -->
<!-- Discuss hypothesis tests and why we hate them. See themes.Rmd for details. -->
<!-- Also interesting to think about tables which we know are finite but we don't ever know how many rows, like number of living people in US right now (i.e., includes planes landing? someone whose heart has stopped beating but has not been "pronounced" dead?)  -->
<!-- How about an urn with more than two colors? An urn with an income is written on the bead? -->
<!-- Might also use Topic 16 from the Workshop here, or save it for the next chapter. -->
<p>Last chapter, we learned about probability, the act of quantifying uncertainty. This chapter, we will be learning about <em>sampling</em>, the beginning of our journey toward inference. When we sample, we take a <em>portion</em> of a total population and attempt to draw a conclusion about the portion that is generalizable to the total population. One of the most common forms of sampling in real life is polling.</p>
<p>When we see a headline of the approval rating of a politician, we are <strong>not</strong> being given a number that represents the approval rating of every citizen in the total population. We are looking at an inference based on a much smaller sample of people. If the source is reputable, this sample mirrors the real world as closely as possible. That being said, there will be a lot of variation in the reported approval rating depending on the specific sample taken that day. This is why we see different approval ratings for different news sources.</p>
<p>Despite this variation, we <em>normally</em> see estimates that are in the same ballpark. It would be surprising to see two approval ratings that are more than 10% apart on any given day. It is possible, however! There could be a number of reasons for such a large gap, many of which result from errors in the sampling itself. It could also just be a consequence of <strong>sampling variation</strong>.</p>
<p>Let’s assume our process of sampling is unbiased, representative, and valid, eliminating all possible error with the sampling mechanism. How many people would we need to survey to have a 90% chance of being within 5% of the true approval rating?</p>
<p>Because we cannot conduct polling, let’s look instead at an easier scenario. Observe the urn in Figure 6.1. It has a certain number of red and a certain number of white beads all of equal size. It appears the urn has been mixed beforehand, as there does not seem to be any coherent pattern to the spatial distribution of the red and white beads.</p>
<p>Let’s now ask ourselves, what proportion of this urn’s beads are red?</p>
<div class="figure">
<span id="fig:unnamed-chunk-517"></span>
<p class="caption marginnote shownote">
FIGURE 6.1: An urn with red and white beads.
</p>
<img src="06-one-parameter/images/sampling_bowl_1.jpg" alt="An urn with red and white beads." width="2656">
</div>
<p>One way to answer this question would be to perform an exhaustive count: remove each bead individually, count the number of red beads and the number of white beads, and divide the number of red beads by the total number of beads. However, this would be a long and tedious process. Therefore, we will use sampling!</p>
<p>The final question, derived from the polling example, is how many beads must we sample to have a 90% chance of being within 5% of the true proportion of red beads in the entire urn?</p>
<p>As always, we will need the <strong>tidyverse</strong> package. The <strong>infer</strong> package has a handy function, <code>rep_sample_n()</code>, for simulating the process of sampling.</p>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="one-parameter.html#cb771-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb771-2"><a href="one-parameter.html#cb771-2"></a><span class="kw">library</span>(infer)</span></code></pre></div>
<div id="sampling-activity" class="section level2">
<h2>
<span class="header-section-number">6.1</span> Real sampling activity</h2>
<div class="figure">
<span id="fig:unnamed-chunk-520"></span>
<p class="caption marginnote shownote">
FIGURE 6.2: An urn with red and white beads.
</p>
<img src="06-one-parameter/images/sampling_bowl_1.jpg" alt="An urn with red and white beads." width="2656">
</div>
<div id="using-the-shovel-method-once" class="section level3">
<h3>
<span class="header-section-number">6.1.1</span> Using the shovel method once</h3>
<p>Instead of performing an exhaustive count, let’s insert a shovel into the urn as seen in Figure 6.2. Using the shovel, let’s remove <span class="math inline">\(5 \cdot 10 = 50\)</span> beads, as seen in Figure 6.3. Here, we are taking a <em>sample</em> of the total population of beads.</p>
<div class="figure">
<span id="fig:unnamed-chunk-521"></span>
<p class="caption marginnote shownote">
FIGURE 6.3: Inserting a shovel into the urn.
</p>
<img src="06-one-parameter/images/sampling_bowl_2.jpg" alt="Inserting a shovel into the urn." width="2656">
</div>
<div class="figure">
<span id="fig:unnamed-chunk-522"></span>
<p class="caption marginnote shownote">
FIGURE 6.4: Removing 50 beads from the urn.
</p>
<img src="06-one-parameter/images/sampling_bowl_3_cropped.jpg" alt="Removing 50 beads from the urn." width="2142">
</div>
<p>Observe that 17 of the 50 sampled beads are red and thus 17/50 = 0.34 = 34% of the shovel’s beads are red. We can view the proportion of beads that are red in this shovel as a guess of the proportion of beads that are red in the entire urn. While not as exact as doing an exhaustive count of all the beads in the urn, our guess of 34% took much less time and energy to make.</p>
<p>However, say, we started this activity over from the beginning, replacing the 50 beads back into the urn and starting over. Would we remove exactly 17 red beads? Would our guess at the proportion of the urn’s beads that are red be 34% again? Maybe?</p>
<p>What if we repeated this activity <em>many</em> times? Would our guess at the proportion of the urn’s beads that are red be exactly 34% every time? Surely not.</p>
<p>The true proportion of red beads in the urn is our <strong>estimand</strong>, the thing we want to know. Here, we are taking a sample and inferring the estimand from that sample. To give us the best odds of inferring the estimand, let’s repeat this exercise with the help of 33 groups of friends to understand how the value differs with repetition.</p>
</div>
<div id="student-shovels" class="section level3">
<h3>
<span class="header-section-number">6.1.2</span> Using the shovel 33 times</h3>
<p>Each of our 33 groups of friends will do the following:</p>
<ul>
<li>Use the shovel to remove 50 beads each.</li>
<li>Count the number of red beads and compute the proportion of the 50 beads that are red.</li>
<li>Return the beads into the urn.</li>
<li>Mix the contents of the urn to not let a previous group’s results influence the next group’s.</li>
</ul>
<div class="figure">
<span id="fig:unnamed-chunk-523"></span>
<p class="caption marginnote shownote">
FIGURE 6.5: Repeating sampling activity 33 times.
</p>
<img src="06-one-parameter/images/tactile_2_a.jpg" alt="Repeating sampling activity 33 times." width="362"><img src="06-one-parameter/images/tactile_2_b.jpg" alt="Repeating sampling activity 33 times." width="368">
</div>
<p>Each of our 33 groups of friends make note of their proportion of red beads from their sample collected. Each group then marks their proportion of their 50 beads that were red in the appropriate bin in a hand-drawn histogram as seen below.</p>
<div class="figure">
<span id="fig:unnamed-chunk-524"></span>
<p class="caption marginnote shownote">
FIGURE 6.6: Constructing a histogram of proportions.
</p>
<img src="06-one-parameter/images/tactile_3_a.jpg" alt="Constructing a histogram of proportions." width="1286">
</div>
<p>Recall from Section <a href="#histograms"><strong>??</strong></a> that histograms allow us to visualize the <em>distribution</em> of a numerical variable. In particular, where the center of the values falls and how the values vary. A partially completed histogram of the first 10 out of 33 groups of friends’ results can be seen in the figure below.</p>
<div class="figure">
<span id="fig:unnamed-chunk-525"></span>
<p class="caption marginnote shownote">
FIGURE 6.7: Hand-drawn histogram of first 10 out of 33 proportions.
</p>
<img src="06-one-parameter/images/tactile_3_c.jpg" alt="Hand-drawn histogram of first 10 out of 33 proportions." width="1594">
</div>
<p>Observe the following details in the histogram:</p>
<ul>
<li>At the low end, one group removed 50 beads from the urn with proportion red between 0.20 and 0.25.</li>
<li>At the high end, another group removed 50 beads from the urn with proportion between 0.45 and 0.5 red.</li>
<li>However, the most frequently occurring proportions were between 0.30 and 0.35 red, right in the middle of the distribution.</li>
<li>The shape of this distribution is somewhat bell-shaped.</li>
</ul>
<p><code>Tactile_sample_urn</code> saves the results from our 33 groups of friends. Run the following to display the tibble:</p>
<pre><code>## # A tibble: 33 x 4
##    group           red_beads prop_red replicate
##    &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;
##  1 Ilyas, Yohan           21     0.42         1
##  2 Ace, Chris             18     0.36         2
##  3 Paddy, Matt            16     0.32         3
##  4 Sanjana, Yuko          19     0.38         4
##  5 Mark, Ramses           21     0.42         5
##  6 Ellie, Terrance        17     0.34         6
##  7 Katie, Anthony         20     0.4          7
##  8 Mal, Francis           17     0.34         8
##  9 Ian, Iman              18     0.36         9
## 10 Mak, Sophie            17     0.34        10
## # … with 23 more rows</code></pre>
<p>Observe for each <code>group</code> that we have their names, the number of <code>red_beads</code> they obtained, and the corresponding proportion out of 50 beads that were red named <code>prop_red</code>. We also have a <code>replicate</code> variable enumerating each of the 33 groups. We chose this name because each row can be viewed as one instance of a replicated activity: using the shovel to remove 50 beads and computing the proportion of those beads that are red.</p>
<p>Let’s visualize the distribution of these 33 proportions using <code>geom_histogram()</code> with <code>binwidth = 0.05</code> in Figure 6.7 below. This is a computerized and complete version of the partially completed hand-drawn histogram you saw earier.</p>
<p><label for="tufte-mn-51" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-51" class="margin-toggle"><span class="marginnote">Note that setting boundary = 0.4 indicates that we want a binning scheme such that one of the bins’ boundary is at 0.4. The other comment, color = ‘white’, is modifying the color of the boundary for visual clarity. This helps us to more closely align this histogram with the hand-drawn histogram.</span></p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb773-1"><a href="one-parameter.html#cb773-1"></a>tactile_sample_urn <span class="op">%&gt;%</span></span>
<span id="cb773-2"><a href="one-parameter.html#cb773-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb773-3"><a href="one-parameter.html#cb773-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb773-4"><a href="one-parameter.html#cb773-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 50 beads that were red"</span>, </span>
<span id="cb773-5"><a href="one-parameter.html#cb773-5"></a>       <span class="dt">title =</span> <span class="st">"Distribution of 33 proportions red"</span>) </span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-528"></span>
<p class="caption marginnote shownote">
FIGURE 6.8: Distribution of 33 proportions based on 33 samples of size 50.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-528-1.png" alt="Distribution of 33 proportions based on 33 samples of size 50." width="672">
</div>
</div>
<div id="what-did-we-just-do" class="section level3">
<h3>
<span class="header-section-number">6.1.3</span> What did we just do?</h3>
<p>What we just demonstrated in this activity is the statistical concept of <strong>sampling</strong>. We would like to know the proportion of the urn’s beads that are red. Performing an exhaustive count of the red and white beads would be time-consuming. Therefore, we extracted a <em>sample</em> of 50 beads using the shovel. Using this sample of 50 beads, we estimated the proportion of the urn’s beads that are red to be 34%.</p>
<p>Moreover, because we mixed the beads before each use of the shovel, these samples were randomly drawn. Because each sample was drawn at random, the samples were different from each other. Because the samples were different from each other, we obtained the different proportions red observed in the previous histogram. This is known as the concept of <em>sampling variation</em>.</p>
<p>The purpose of this sampling activity is to develop an understanding of two key concepts relating to sampling:</p>
<ol style="list-style-type: decimal">
<li>Understanding the effect of sampling variation.</li>
<li>Understanding the effect of sample size on sampling variation.</li>
</ol>
<p>In Section <a href="one-parameter.html#sampling-simulation">6.2</a>, we’ll mimic the hands-on sampling activity we just performed on a computer. This will allow us not only to repeat the sampling exercise much more than 33 times, but it will also allow us to use shovels with different numbers of slots than just 50.</p>
<p>Afterwards, we’ll present you with definitions, terminology, and notation related to sampling in Section <a href="one-parameter.html#sampling-framework">6.4</a>. As in many disciplines, such necessary background knowledge may seem inaccessible and even confusing at first. However, as with many difficult topics, if you truly understand the underlying concepts and practice, practice, practice, you’ll be able to master them.</p>
<p>To tie the contents of this chapter to the real world, we’ll present an example of one of the most common uses of sampling: polls. In Section <a href="one-parameter.html#sampling-case-study">6.5</a> we’ll look at a particular case study: a 2013 poll on then U.S. President Barack Obama’s popularity among young Americans, conducted by Kennedy School’s Institute of Politics at Harvard University. To close this chapter, we’ll generalize the “sampling from a urn” exercise to other sampling scenarios.</p>
</div>
</div>
<div id="sampling-simulation" class="section level2">
<h2>
<span class="header-section-number">6.2</span> Virtual sampling</h2>
<p>In the previous Section <a href="one-parameter.html#sampling-activity">6.1</a>, we performed a <em>tactile</em> sampling activity by hand. In other words, we used a physical urn of beads and a physical shovel. We performed this sampling activity by hand so that we could develop a firm understanding of the root ideas behind sampling. In this section, we’ll mimic this tactile sampling activity with a <em>virtual</em> sampling activity using a computer. Here, we’ll use a virtual analog to the urn of beads and a virtual analog to the shovel.</p>
<div id="using-the-virtual-shovel-once" class="section level3">
<h3>
<span class="header-section-number">6.2.1</span> Using the virtual shovel once</h3>
<p>Let’s start by performing the virtual analog of the tactile sampling exercise we performed in Section <a href="one-parameter.html#sampling-activity">6.1</a>. We first need a virtual analog of the urn seen in the beginning of our chapter. To this end, we creat a data frame named <code>urn</code>. The rows of <code>urn</code> correspond exactly with the contents of the actual urn.</p>
<p><label for="tufte-mn-52" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-52" class="margin-toggle"><span class="marginnote">For reference, sample-frac() merely re-arranges the rows of the tibble. We use set.seed() to ensure that the beads in our virtual urn are always in the same order. This makes certain that the figures in the book match their written descriptions.</span></p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="one-parameter.html#cb774-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb774-2"><a href="one-parameter.html#cb774-2"></a>urn &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">color =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">"red"</span>, <span class="dv">900</span>), <span class="kw">rep</span>(<span class="st">"white"</span>, <span class="dv">1500</span>))) <span class="op">%&gt;%</span></span>
<span id="cb774-3"><a href="one-parameter.html#cb774-3"></a><span class="st">  </span><span class="kw">sample_frac</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb774-4"><a href="one-parameter.html#cb774-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ID =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2400</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb774-5"><a href="one-parameter.html#cb774-5"></a><span class="st">  </span><span class="kw">select</span>(ID, color)</span>
<span id="cb774-6"><a href="one-parameter.html#cb774-6"></a>urn  </span></code></pre></div>
<pre><code>## # A tibble: 2,400 x 2
##       ID color
##    &lt;int&gt; &lt;chr&gt;
##  1     1 white
##  2     2 white
##  3     3 white
##  4     4 white
##  5     5 red  
##  6     6 red  
##  7     7 white
##  8     8 red  
##  9     9 red  
## 10    10 red  
## # … with 2,390 more rows</code></pre>
<p>Observe that <code>urn</code> has 2400 rows, telling us that the urn contains 2400 equally sized beads. The first variable <code>ID</code> is used as an <em>identification variable</em>; none of the beads in the actual urn are marked with numbers. The second variable <code>color</code> indicates whether a particular virtual bead is red or white. View the contents of the urn in RStudio’s data viewer and scroll through the contents to convince yourself that <code>urn</code> is indeed a virtual analog of the actual urn.</p>
<p>Now that we have a virtual analog of our urn, we need a virtual analog of the shovel seen in Figure 6.2 to generate virtual samples of 50 beads. We’re going to use the <code>rep_sample_n()</code> function included in the <strong>infer</strong> package. This function allows us to take <code>rep</code>eated, or <code>rep</code>licated, <code>samples</code> of size <code>n</code>.</p>
<p>Now, let’s use <code>rep_sample_n()</code> to take a sample of 50 beads (denoted by size = 50) from our virtual urn.</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="one-parameter.html#cb776-1"></a>virtual_shovel &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb776-2"><a href="one-parameter.html#cb776-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>)</span>
<span id="cb776-3"><a href="one-parameter.html#cb776-3"></a>virtual_shovel</span></code></pre></div>
<pre><code>## # A tibble: 50 x 3
## # Groups:   replicate [1]
##    replicate    ID color
##        &lt;int&gt; &lt;int&gt; &lt;chr&gt;
##  1         1  1511 white
##  2         1  1444 white
##  3         1  1988 red  
##  4         1  1152 white
##  5         1   716 white
##  6         1   667 red  
##  7         1   773 red  
##  8         1    91 white
##  9         1   896 red  
## 10         1  2104 white
## # … with 40 more rows</code></pre>
<p>Observe that <code>virtual_shovel</code> has 50 rows corresponding to our virtual sample of size 50. The <code>ID</code> variable identifies which of the 2400 beads from <code>urn</code> are included in our sample of 50 beads while <code>color</code> denotes its color. However, what does the <code>replicate</code> variable indicate? In <code>virtual_shovel</code>’s case, <code>replicate</code> is equal to 1 for all 50 rows. This is telling us that these 50 rows correspond to the first repeated/replicated use of the shovel, in our case our first sample. We’ll see shortly that when we “virtually” take 33 samples, <code>replicate</code> will take values between 1 and 33.</p>
<p>Let’s compute the proportion of beads in our virtual sample that are red using the <strong>dplyr</strong> data wrangling verbs you learned in Chapter <a href="wrangling.html#wrangling">2</a>. First, for each of our 50 sampled beads, let’s identify if it is red or not using a test for equality with <code>==</code>. Let’s create a new Boolean variable <code>is_red</code> using the <code>mutate()</code> function from Section <a href="visualization.html#mutate">1.4.6</a>:</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="one-parameter.html#cb778-1"></a>virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb778-2"><a href="one-parameter.html#cb778-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> (color <span class="op">==</span><span class="st"> "red"</span>))</span></code></pre></div>
<pre><code>## # A tibble: 50 x 4
## # Groups:   replicate [1]
##    replicate    ID color is_red
##        &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; 
##  1         1  1511 white FALSE 
##  2         1  1444 white FALSE 
##  3         1  1988 red   TRUE  
##  4         1  1152 white FALSE 
##  5         1   716 white FALSE 
##  6         1   667 red   TRUE  
##  7         1   773 red   TRUE  
##  8         1    91 white FALSE 
##  9         1   896 red   TRUE  
## 10         1  2104 white FALSE 
## # … with 40 more rows</code></pre>
<p>Observe that for every row where <code>color == "red"</code>, the Boolean (logical) value <code>TRUE</code> is returned and for every row where <code>color</code> is not equal to <code>"red"</code>, the Boolean <code>FALSE</code> is returned.</p>
<p>Second, let’s compute the number of beads out of 50 that are red using the <code>summarize()</code> function. Recall from Section <a href="visualization.html#summarize">1.4.7</a> that <code>summarize()</code> takes a data frame with many rows and returns a data frame with a single row containing summary statistics, like the <code>mean()</code> or <code>median()</code>. In this case, we use the <code>sum()</code>:</p>
<p><label for="tufte-mn-53" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-53" class="margin-toggle"><span class="marginnote">The .groups = drop_last command in summarize is placed to override summarize’s ungrouping default output.</span></p>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="one-parameter.html#cb780-1"></a>virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb780-2"><a href="one-parameter.html#cb780-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> (color <span class="op">==</span><span class="st"> "red"</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb780-3"><a href="one-parameter.html#cb780-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(is_red), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   replicate num_red
##       &lt;int&gt;   &lt;int&gt;
## 1         1      12</code></pre>
<p>Why does this work? Because R treats <code>TRUE</code> like the number <code>1</code> and <code>FALSE</code> like the number <code>0</code>. So summing the number of <code>TRUE</code>s and <code>FALSE</code>s is equivalent to summing <code>1</code>’s and <code>0</code>’s. In the end, this operation counts the number of beads where <code>color</code> is <code>red</code>. In our case, 12 of the 50 beads were red. However, you might have gotten a different number red because of the randomness of the virtual sampling.</p>
<p>Third and lastly, let’s compute the proportion of the 50 sampled beads that are red by dividing <code>num_red</code> by 50:</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="one-parameter.html#cb782-1"></a>virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb782-2"><a href="one-parameter.html#cb782-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">is_red =</span> color <span class="op">==</span><span class="st"> "red"</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb782-3"><a href="one-parameter.html#cb782-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(is_red), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb782-4"><a href="one-parameter.html#cb782-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> num_red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate num_red prop_red
##       &lt;int&gt;   &lt;int&gt;    &lt;dbl&gt;
## 1         1      12     0.24</code></pre>
<p>In other words, 24% of this virtual sample’s beads were red. Let’s make this code a little more compact and succinct by combining the first <code>mutate()</code> and the <code>summarize()</code> as follows:</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="one-parameter.html#cb784-1"></a>virtual_shovel <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb784-2"><a href="one-parameter.html#cb784-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">num_red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb784-3"><a href="one-parameter.html#cb784-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> num_red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   replicate num_red prop_red
##       &lt;int&gt;   &lt;int&gt;    &lt;dbl&gt;
## 1         1      12     0.24</code></pre>
<p>Great! 24% of <code>virtual_shovel</code>’s 50 beads were red! So based on this particular sample of 50 beads, our guess at the proportion of the <code>urn</code>’s beads that are red is 24%. But remember from our earlier tactile sampling activity that if we repeat this sampling, we will not necessarily obtain the same value of 24% again. There will likely be some variation. In fact, our 33 groups of friends computed 33 such proportions whose distribution we previously visualized. We saw that these estimates <em>varied</em>. Let’s now perform the virtual analog of having 33 groups of students use the sampling shovel!</p>
</div>
<div id="using-the-virtual-shovel-33-times" class="section level3">
<h3>
<span class="header-section-number">6.2.2</span> Using the virtual shovel 33 times</h3>
<p>Recall that in our tactile sampling exercise in Section <a href="one-parameter.html#sampling-activity">6.1</a>, we had 33 groups of students each use the shovel, yielding 33 samples of size 50 beads. We then used these 33 samples to compute 33 proportions. We can perform this repeated/replicated sampling virtually by once again using our virtual shovel function <code>rep_sample_n()</code>, adding the <code>reps = 33</code> argument. This is telling R that we want to <em>repeat</em> the sampling 33 times.</p>
<p>We’ll save these results in a data frame called <code>virtual_samples</code>.</p>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="one-parameter.html#cb786-1"></a>virtual_samples &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb786-2"><a href="one-parameter.html#cb786-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">33</span>)</span>
<span id="cb786-3"><a href="one-parameter.html#cb786-3"></a>virtual_samples</span></code></pre></div>
<pre><code>## # A tibble: 1,650 x 3
## # Groups:   replicate [33]
##    replicate    ID color
##        &lt;int&gt; &lt;int&gt; &lt;chr&gt;
##  1         1  1042 red  
##  2         1   265 red  
##  3         1  1079 white
##  4         1  2143 white
##  5         1  2347 white
##  6         1  2005 white
##  7         1  1912 white
##  8         1  1068 white
##  9         1  2322 red  
## 10         1  1241 white
## # … with 1,640 more rows</code></pre>
<p>Observe that the first 50 rows of <code>replicate</code> are equal to <code>1</code> while the next 50 rows of <code>replicate</code> are equal to <code>2</code>. This is telling us that the first 50 rows correspond to the first sample of 50 beads while the next 50 rows correspond to the second sample of 50 beads. This pattern continues for all <code>reps = 33</code> replicates and thus <code>virtual_samples</code> has 33 <span class="math inline">\(\cdot\)</span> 50 = 1650 rows.</p>
<p>Let’s now take <code>virtual_samples</code> and compute the resulting 33 proportions red. We’ll use the same <strong>dplyr</strong> verbs as before, but this time with an additional <code>group_by()</code> of the <code>replicate</code> variable. Recall that by assigning the grouping variable “meta-data” before we <code>summarize()</code>, we’ll obtain 33 different proportions red. We display a preview of the first 10 out of 33 rows:</p>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="one-parameter.html#cb788-1"></a>virtual_prop_red &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb788-2"><a href="one-parameter.html#cb788-2"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb788-3"><a href="one-parameter.html#cb788-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb788-4"><a href="one-parameter.html#cb788-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span>
<span id="cb788-5"><a href="one-parameter.html#cb788-5"></a>virtual_prop_red</span></code></pre></div>
<pre><code>## # A tibble: 33 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    17     0.34
##  2         2    22     0.44
##  3         3    20     0.4 
##  4         4    18     0.36
##  5         5    15     0.3 
##  6         6    16     0.32
##  7         7    25     0.5 
##  8         8    22     0.44
##  9         9    21     0.42
## 10        10    19     0.38
## # … with 23 more rows</code></pre>
<p>As with our 33 groups of friends’ tactile samples, there is variation in the resulting 33 virtual proportions red. Let’s visualize this variation in a histogram in Figure 6.8 below.</p>
<p><label for="tufte-mn-54" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-54" class="margin-toggle"><span class="marginnote">Note that we add ‘binwidth = 0.05’ and ‘boundary = 0.4’ arguments as well. Recall that setting ‘boundary = 0.4’ ensures a binning scheme with one of the bins’ boundaries at 0.4. Since the ‘binwidth = 0.05’ is also set, this will create bins with boundaries at 0.30, 0.35, 0.45, 0.5, etc. as well.</span></p>
<div class="sourceCode" id="cb790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb790-1"><a href="one-parameter.html#cb790-1"></a><span class="kw">ggplot</span>(virtual_prop_red, <span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb790-2"><a href="one-parameter.html#cb790-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb790-3"><a href="one-parameter.html#cb790-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 50 beads that were red"</span>, </span>
<span id="cb790-4"><a href="one-parameter.html#cb790-4"></a>       <span class="dt">title =</span> <span class="st">"Distribution of 33 proportions red"</span>) </span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-540"></span>
<p class="caption marginnote shownote">
FIGURE 6.9: Distribution of 33 proportions based on 33 samples of size 50.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-540-1.png" alt="Distribution of 33 proportions based on 33 samples of size 50." width="672">
</div>
<p>Observe that we occasionally obtained proportions red that are less than 30%. On the other hand, we occasionally obtained proportions that are greater than 45%. However, the most frequently occurring proportions were between 35% and 40% (for 11 out of 33 samples). Why do we have these differences in proportions red? Because of <em>sampling variation</em>.</p>
<p>Let’s now compare our virtual results with our tactile results from the previous section. Observe that both histograms are somewhat similar in their center and variation, although not identical. These slight differences are again due to random sampling variation. Furthermore, observe that both distributions are somewhat bell-shaped.</p>
<div class="figure">
<span id="fig:unnamed-chunk-541"></span>
<p class="caption marginnote shownote">
FIGURE 6.10: Comparing 33 virtual and 33 tactile proportions red.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-541-1.png" alt="Comparing 33 virtual and 33 tactile proportions red." width="672">
</div>
</div>
<div id="shovel-1000-times" class="section level3">
<h3>
<span class="header-section-number">6.2.3</span> Using the virtual shovel 1,000 times</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-542"></span>
<img src="06-one-parameter/images/sample_bernie.png" alt="So much sampling, so little time." width="362"><!--
<p class="caption marginnote">-->FIGURE 6.11: So much sampling, so little time.<!--</p>-->
<!--</div>--></span>
</p>
<p>Now say we want to study the effects of sampling variation not for 33 samples, but rather for a larger number of samples (1000). We have two choices at this point. We could have our groups of friends manually take 1,000 samples of 50 beads and compute the corresponding 1,000 proportions. However, this would be a time-consuming task. This is where computers excel: automating long and repetitive tasks while performing them quite quickly. At this point, we will abandon tactile sampling in favor of only virtual sampling. Let’s once again use the <code>rep_sample_n()</code> function with sample <code>size</code> set to be 50 once again, but this time with the number of replicates <code>reps</code> set to <code>1000</code>. Be sure to scroll through the contents of <code>virtual_samples</code> in RStudio’s viewer.</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="one-parameter.html#cb791-1"></a>virtual_samples &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb791-2"><a href="one-parameter.html#cb791-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb791-3"><a href="one-parameter.html#cb791-3"></a>virtual_samples</span></code></pre></div>
<pre><code>## # A tibble: 50,000 x 3
## # Groups:   replicate [1,000]
##    replicate    ID color
##        &lt;int&gt; &lt;int&gt; &lt;chr&gt;
##  1         1   627 white
##  2         1   824 white
##  3         1  1906 red  
##  4         1   344 white
##  5         1  1598 red  
##  6         1  1869 white
##  7         1   934 red  
##  8         1    39 red  
##  9         1   696 white
## 10         1    13 white
## # … with 49,990 more rows</code></pre>
<p>Observe that now <code>virtual_samples</code> has 1,000 <span class="math inline">\(\cdot\)</span> 50 = 50,000 rows, instead of the 33 <span class="math inline">\(\cdot\)</span> 50 = 1650 rows from earlier. Using the same data wrangling code as earlier, let’s take the data frame <code>virtual_samples</code> with 1,000 <span class="math inline">\(\cdot\)</span> 50 = 50,000 rows and compute the resulting 1,000 proportions of red beads.</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb793-1"><a href="one-parameter.html#cb793-1"></a>virtual_prop_red &lt;-<span class="st"> </span>virtual_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-2"><a href="one-parameter.html#cb793-2"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-3"><a href="one-parameter.html#cb793-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb793-4"><a href="one-parameter.html#cb793-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span>
<span id="cb793-5"><a href="one-parameter.html#cb793-5"></a>virtual_prop_red</span></code></pre></div>
<pre><code>## # A tibble: 1,000 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    21     0.42
##  2         2    18     0.36
##  3         3    19     0.38
##  4         4    19     0.38
##  5         5    16     0.32
##  6         6    19     0.38
##  7         7    21     0.42
##  8         8    16     0.32
##  9         9    19     0.38
## 10        10    22     0.44
## # … with 990 more rows</code></pre>
<p>Observe that we now have 1,000 replicates of <code>prop_red</code>, the proportion of 50 beads that are red. Using the same code as earlier, let’s now visualize the distribution of these 1,000 replicates of <code>prop_red</code> in a histogram in Figure 6.10 below.</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="one-parameter.html#cb795-1"></a><span class="kw">ggplot</span>(virtual_prop_red, <span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb795-2"><a href="one-parameter.html#cb795-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb795-3"><a href="one-parameter.html#cb795-3"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 50 beads that were red"</span>, </span>
<span id="cb795-4"><a href="one-parameter.html#cb795-4"></a>       <span class="dt">title =</span> <span class="st">"Distribution of 1,000 proportions red"</span>) </span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-546"></span>
<p class="caption marginnote shownote">
FIGURE 6.12: Distribution of 1,000 proportions based on 1,000 samples of size 50.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-546-1.png" alt="Distribution of 1,000 proportions based on 1,000 samples of size 50." width="672">
</div>
<p>Once again, the most frequently occurring proportions of red beads occur between 35% and 40%. Every now and then, we obtain proportions as low as between 20% and 25%, and others as high as between 55% and 60%. These are rare, however. Furthermore, observe that we now have a much more symmetric and smoother bell-shaped distribution. This distribution is, in fact, approximated well by a normal distribution.</p>
</div>
<div id="different-shovels" class="section level3">
<h3>
<span class="header-section-number">6.2.4</span> The effect of different shovel sizes</h3>
<p>Now say instead of just one shovel, you have three choices of shovels to extract a sample of beads with: shovels of size 25, 50, and 100.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-547"></span>
<p class="caption marginnote shownote">
FIGURE 6.13: Three shovels to extract three different sample sizes.
</p>
<img src="06-one-parameter/images/three_shovels.png" alt="Three shovels to extract three different sample sizes." width="881">
</div>
<p>If your goal is still to estimate the proportion of the urn’s beads that are red, which shovel would you choose? In our experience, most people would choose the largest shovel with 100 slots because it would yield the “best” guess of the proportion of the urn’s beads that are red. Let’s define some criteria for “best” in this subsection.</p>
<p>Using our newly developed tools for virtual sampling, let’s unpack the effect of having different sample sizes! In other words, let’s use <code>rep_sample_n()</code> with <code>size</code> set to <code>25</code>, <code>50</code>, and <code>100</code>, respectively, while keeping the number of repeated/replicated samples at 1,000:</p>
<ol style="list-style-type: decimal">
<li>Virtually use the appropriate shovel to generate 1,000 samples with <code>size</code> beads.</li>
<li>Compute the resulting 1,000 replicates of the proportion of the shovel’s beads that are red.</li>
<li>Visualize the distribution of these 1,000 proportions red using a histogram.</li>
</ol>
<p>Start by virtually using the shovel 1000 times with <code>rep_sample_n</code>. Then, compute the resulting 1000 replicates of proportion red. Finally, plot the distribution using a histogram.</p>
<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb796-1"><a href="one-parameter.html#cb796-1"></a>virtual_samples_<span class="dv">25</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb796-2"><a href="one-parameter.html#cb796-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb796-3"><a href="one-parameter.html#cb796-3"></a></span>
<span id="cb796-4"><a href="one-parameter.html#cb796-4"></a>virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb796-5"><a href="one-parameter.html#cb796-5"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb796-6"><a href="one-parameter.html#cb796-6"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb796-7"><a href="one-parameter.html#cb796-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">25</span>)</span>
<span id="cb796-8"><a href="one-parameter.html#cb796-8"></a></span>
<span id="cb796-9"><a href="one-parameter.html#cb796-9"></a>virtual_prop_red_<span class="dv">25</span> <span class="op">%&gt;%</span></span>
<span id="cb796-10"><a href="one-parameter.html#cb796-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb796-11"><a href="one-parameter.html#cb796-11"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb796-12"><a href="one-parameter.html#cb796-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 25 beads that were red"</span>, <span class="dt">title =</span> <span class="st">"25"</span>) </span></code></pre></div>
<p>We will repeat this process with a shovel size of <strong>50</strong>.</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="one-parameter.html#cb797-1"></a>virtual_samples_<span class="dv">50</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb797-2"><a href="one-parameter.html#cb797-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb797-3"><a href="one-parameter.html#cb797-3"></a></span>
<span id="cb797-4"><a href="one-parameter.html#cb797-4"></a>virtual_prop_red_<span class="dv">50</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">50</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb797-5"><a href="one-parameter.html#cb797-5"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb797-6"><a href="one-parameter.html#cb797-6"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb797-7"><a href="one-parameter.html#cb797-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">50</span>)</span>
<span id="cb797-8"><a href="one-parameter.html#cb797-8"></a></span>
<span id="cb797-9"><a href="one-parameter.html#cb797-9"></a>virtual_prop_red_<span class="dv">50</span> <span class="op">%&gt;%</span></span>
<span id="cb797-10"><a href="one-parameter.html#cb797-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb797-11"><a href="one-parameter.html#cb797-11"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb797-12"><a href="one-parameter.html#cb797-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 50 beads that were red"</span>, <span class="dt">title =</span> <span class="st">"50"</span>)  </span></code></pre></div>
<p>Finally, we will perform the same process with 1000 replicates to map the histogram using a shovel size of <strong>100</strong>.</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="one-parameter.html#cb798-1"></a>virtual_samples_<span class="dv">100</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb798-2"><a href="one-parameter.html#cb798-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">100</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb798-3"><a href="one-parameter.html#cb798-3"></a></span>
<span id="cb798-4"><a href="one-parameter.html#cb798-4"></a>virtual_prop_red_<span class="dv">100</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb798-5"><a href="one-parameter.html#cb798-5"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb798-6"><a href="one-parameter.html#cb798-6"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb798-7"><a href="one-parameter.html#cb798-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">100</span>)</span>
<span id="cb798-8"><a href="one-parameter.html#cb798-8"></a></span>
<span id="cb798-9"><a href="one-parameter.html#cb798-9"></a>virtual_prop_red_<span class="dv">100</span> <span class="op">%&gt;%</span></span>
<span id="cb798-10"><a href="one-parameter.html#cb798-10"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> prop_red)) <span class="op">+</span></span>
<span id="cb798-11"><a href="one-parameter.html#cb798-11"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.05</span>, <span class="dt">boundary =</span> <span class="fl">0.4</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb798-12"><a href="one-parameter.html#cb798-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Proportion of 100 beads that were red"</span>, <span class="dt">title =</span> <span class="st">"100"</span>) </span></code></pre></div>
<p>For easy comparison, we present the three resulting histograms in a single row with matching x and y axes in Figure 6.12.</p>
<div class="figure">
<span id="fig:unnamed-chunk-551"></span>
<p class="caption marginnote shownote">
FIGURE 6.14: Comparing the distributions of proportion red for different sample sizes.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-551-1.png" alt="Comparing the distributions of proportion red for different sample sizes." width="672">
</div>
<p>Observe that as the sample size increases, the variation of the 1,000 replicates of the proportion of red decreases. In other words, as the sample size increases, there are fewer differences due to sampling variation and the distribution centers more tightly around the same value. Eyebeading Figure 6.12, all three histograms appear to center around roughly 40%.</p>
<p>We can be numerically explicit about the amount of variation in our three sets of 1,000 values of <code>prop_red</code> using the <em>standard deviation</em>. A standard deviation is a summary statistic that measures the amount of variation within a numerical variable. For all three sample sizes, let’s compute the standard deviation of the 1,000 proportions red by running the following data wrangling code that uses the <code>sd()</code> summary function.</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="one-parameter.html#cb799-1"></a><span class="co"># n = 25</span></span>
<span id="cb799-2"><a href="one-parameter.html#cb799-2"></a>virtual_prop_red_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb799-3"><a href="one-parameter.html#cb799-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>)</span>
<span id="cb799-4"><a href="one-parameter.html#cb799-4"></a><span class="co"># n = 50</span></span>
<span id="cb799-5"><a href="one-parameter.html#cb799-5"></a>virtual_prop_red_<span class="dv">50</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb799-6"><a href="one-parameter.html#cb799-6"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>)</span>
<span id="cb799-7"><a href="one-parameter.html#cb799-7"></a><span class="co"># n = 100</span></span>
<span id="cb799-8"><a href="one-parameter.html#cb799-8"></a>virtual_prop_red_<span class="dv">100</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb799-9"><a href="one-parameter.html#cb799-9"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(prop_red), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>)</span></code></pre></div>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#qlwqwyyank .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qlwqwyyank .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qlwqwyyank .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qlwqwyyank .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qlwqwyyank .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qlwqwyyank .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qlwqwyyank .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qlwqwyyank .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qlwqwyyank .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qlwqwyyank .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qlwqwyyank .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qlwqwyyank .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qlwqwyyank .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qlwqwyyank .gt_from_md > :first-child {
  margin-top: 0;
}

#qlwqwyyank .gt_from_md > :last-child {
  margin-bottom: 0;
}

#qlwqwyyank .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qlwqwyyank .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qlwqwyyank .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qlwqwyyank .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qlwqwyyank .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qlwqwyyank .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qlwqwyyank .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qlwqwyyank .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qlwqwyyank .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qlwqwyyank .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qlwqwyyank .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qlwqwyyank .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qlwqwyyank .gt_left {
  text-align: left;
}

#qlwqwyyank .gt_center {
  text-align: center;
}

#qlwqwyyank .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qlwqwyyank .gt_font_normal {
  font-weight: normal;
}

#qlwqwyyank .gt_font_bold {
  font-weight: bold;
}

#qlwqwyyank .gt_font_italic {
  font-style: italic;
}

#qlwqwyyank .gt_super {
  font-size: 65%;
}

#qlwqwyyank .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="qlwqwyyank" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_header">
<tr>
<th colspan="2" class="gt_heading gt_title gt_font_normal" style>Comparing standard deviations of proportions red for three different shovels</th>
    </tr>
<tr>
<th colspan="2" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style></th>
    </tr>
</thead>
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Number of slots in shovel</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Standard deviation of proportions red</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_right">25</td>
      <td class="gt_row gt_right">0.096</td>
    </tr>
<tr>
<td class="gt_row gt_right">50</td>
      <td class="gt_row gt_right">0.067</td>
    </tr>
<tr>
<td class="gt_row gt_right">100</td>
      <td class="gt_row gt_right">0.046</td>
    </tr>
</tbody>
</table></div>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-554"></span>
<img src="06-one-parameter/images/big%20brain.png" alt="Enlightened sampling." width="385"><!--
<p class="caption marginnote">-->FIGURE 6.15: Enlightened sampling.<!--</p>-->
<!--</div>--></span>
</p>
<p>As we observed earlier, as the sample size increases, the variation decreases. In other words, there is less variation in the 1,000 values of the proportion red. So as the sample size increases, our guesses at the true proportion of the urn’s beads that are red get more precise. Therefore, our initial assumption that the larger shovel yields the most precise result is correct!</p>
</div>
<div id="functions-are-your-friend" class="section level3">
<h3>
<span class="header-section-number">6.2.5</span> Functions are your friend!</h3>
<p>Note that in the last section, we ran more or less the same code three times, but with different sizes for our shovel (25, 50, and 100). Whenever you find yourself writing the same code three or more times, you should write a <em>function</em> that does the same thing. Let’s look at the code that used a shovel of size 25 and calculated the proportion of beads that were red one more time:</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="one-parameter.html#cb800-1"></a>virtual_samples_<span class="dv">25</span> &lt;-<span class="st"> </span>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-2"><a href="one-parameter.html#cb800-2"></a><span class="st">  </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb800-3"><a href="one-parameter.html#cb800-3"></a>virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span>virtual_samples_<span class="dv">25</span> <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-4"><a href="one-parameter.html#cb800-4"></a><span class="st">  </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-5"><a href="one-parameter.html#cb800-5"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb800-6"><a href="one-parameter.html#cb800-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span><span class="dv">25</span>)</span></code></pre></div>
<p>We will break this into two functions, one called <code>use_shovel()</code> which will use a shovel of the specified size, and another called <code>prop_red()</code> which will calculate the proportion of red for a shovel of the specified size.</p>
<p>First, let’s create <code>use_shovel()</code>.</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="one-parameter.html#cb801-1"></a>use_shovel &lt;-<span class="st"> </span><span class="cf">function</span>(x, size, reps) {</span>
<span id="cb801-2"><a href="one-parameter.html#cb801-2"></a>  x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep_sample_n</span>(<span class="dt">size =</span> size, <span class="dt">reps =</span> reps)</span>
<span id="cb801-3"><a href="one-parameter.html#cb801-3"></a>}</span>
<span id="cb801-4"><a href="one-parameter.html#cb801-4"></a><span class="kw">use_shovel</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## # A tibble: 25,000 x 3
## # Groups:   replicate [1,000]
##    replicate    ID color
##        &lt;int&gt; &lt;int&gt; &lt;chr&gt;
##  1         1  1660 white
##  2         1  2335 red  
##  3         1  1735 white
##  4         1   158 white
##  5         1    40 red  
##  6         1   255 red  
##  7         1    54 red  
##  8         1  1584 white
##  9         1   106 white
## 10         1  1885 red  
## # … with 24,990 more rows</code></pre>
<p>See that we now can create the object <code>virtual_samples_25</code> with the code <code>virtual_samples_25 &lt;- use_shovel(x = urn, size = 25, reps = 1000)</code>. This is far more succinct than our previous code, and it allows us to use a shovel of any size we’d like.</p>
<p>Now, we can use our <code>use_shovel()</code> function to develop another function, <code>prop_red()</code>:</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="one-parameter.html#cb803-1"></a>prop_red &lt;-<span class="st"> </span><span class="cf">function</span>(x, size, reps) {</span>
<span id="cb803-2"><a href="one-parameter.html#cb803-2"></a>  <span class="kw">use_shovel</span>(<span class="dt">x =</span> x, <span class="dt">size =</span> size, <span class="dt">reps =</span> reps) <span class="op">%&gt;%</span></span>
<span id="cb803-3"><a href="one-parameter.html#cb803-3"></a><span class="st">    </span><span class="kw">group_by</span>(replicate) <span class="op">%&gt;%</span></span>
<span id="cb803-4"><a href="one-parameter.html#cb803-4"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>) <span class="op">%&gt;%</span></span>
<span id="cb803-5"><a href="one-parameter.html#cb803-5"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prop_red =</span> red <span class="op">/</span><span class="st"> </span>size)</span>
<span id="cb803-6"><a href="one-parameter.html#cb803-6"></a>}</span>
<span id="cb803-7"><a href="one-parameter.html#cb803-7"></a><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1,000 x 3
##    replicate   red prop_red
##        &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
##  1         1    10     0.4 
##  2         2     9     0.36
##  3         3     9     0.36
##  4         4     9     0.36
##  5         5     6     0.24
##  6         6    10     0.4 
##  7         7     8     0.32
##  8         8     8     0.32
##  9         9     9     0.36
## 10        10    12     0.48
## # … with 990 more rows</code></pre>
<p>See how this just uses the code we had before to create <code>virtual_prop_red_25</code>, but generalizes it. Now we can create the same tibbles we did before, ready to plot the histograms, with only three lines of code:</p>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="one-parameter.html#cb805-1"></a>virtual_prop_red_<span class="dv">25</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">25</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb805-2"><a href="one-parameter.html#cb805-2"></a>virtual_prop_red_<span class="dv">50</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">50</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb805-3"><a href="one-parameter.html#cb805-3"></a>virtual_prop_red_<span class="dv">100</span> &lt;-<span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, <span class="dt">size =</span> <span class="dv">100</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>But this still isn’t the best way. Note that we have three objects we need to deal with, <code>virtual_prop_red_25</code>, <code>virtual_prop_red_50</code>, and <code>virtual_prop_red_100</code>. Instead, let’s store our results in a single tibble. How can we do this? By using <code>map()</code> to create a list column!</p>
<p>First, we’ll create a tibble called <code>shovels</code> that will have a variable named <code>shovel_size</code> with our values (25, 50, 100):</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="one-parameter.html#cb806-1"></a>shovels &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">shovel_size =</span> <span class="kw">c</span>(<span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>))</span></code></pre></div>
<p>Next, we’ll create list columns called <code>use_shovel_results</code> and <code>prop_red_results</code> that are the outputs of <code>use_shovel()</code> and <code>prop_red</code>, respectively:</p>
<div class="sourceCode" id="cb807"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb807-1"><a href="one-parameter.html#cb807-1"></a>shovels &lt;-<span class="st"> </span>shovels <span class="op">%&gt;%</span></span>
<span id="cb807-2"><a href="one-parameter.html#cb807-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">use_shovel_results =</span> <span class="kw">map</span>(shovel_size,</span>
<span id="cb807-3"><a href="one-parameter.html#cb807-3"></a>                                  <span class="op">~</span><span class="st"> </span><span class="kw">use_shovel</span>(<span class="dt">x =</span> urn,</span>
<span id="cb807-4"><a href="one-parameter.html#cb807-4"></a>                                               <span class="dt">size =</span> .x,</span>
<span id="cb807-5"><a href="one-parameter.html#cb807-5"></a>                                               <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span></span>
<span id="cb807-6"><a href="one-parameter.html#cb807-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_results =</span> <span class="kw">map</span>(shovel_size,</span>
<span id="cb807-7"><a href="one-parameter.html#cb807-7"></a>                                <span class="op">~</span><span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, </span>
<span id="cb807-8"><a href="one-parameter.html#cb807-8"></a>                                           <span class="dt">size =</span> .x, </span>
<span id="cb807-9"><a href="one-parameter.html#cb807-9"></a>                                           <span class="dt">reps =</span> <span class="dv">1000</span>)))</span>
<span id="cb807-10"><a href="one-parameter.html#cb807-10"></a><span class="kw">glimpse</span>(shovels)</span></code></pre></div>
<pre><code>## Rows: 3
## Columns: 3
## $ shovel_size        &lt;dbl&gt; 25, 50, 100
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[25000 x 3]&gt;, &lt;grouped_df[50000 x 3]&gt;…
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…</code></pre>
<p>Adding another <code>map_*</code> function will let us get the standard deviations of our estimated proportions:</p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="one-parameter.html#cb809-1"></a>shovels &lt;-<span class="st"> </span>shovels <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb809-2"><a href="one-parameter.html#cb809-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_sd =</span> <span class="kw">map_dbl</span>(prop_red_results, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()))</span>
<span id="cb809-3"><a href="one-parameter.html#cb809-3"></a><span class="kw">glimpse</span>(shovels)</span></code></pre></div>
<pre><code>## Rows: 3
## Columns: 4
## $ shovel_size        &lt;dbl&gt; 25, 50, 100
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[25000 x 3]&gt;, &lt;grouped_df[50000 x 3]&gt;…
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…
## $ prop_red_sd        &lt;dbl&gt; 0.099, 0.066, 0.046</code></pre>
<p>But now that we have this framework, there’s no need to limit ourselves to the sizes 25, 50, and 100. Why not try all integers from 1 to 100? We can use the same code, except we’ll now set <code>shovel_size = 1:100</code> when initializing the tibble.</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="one-parameter.html#cb811-1"></a>shovels_<span class="dv">100</span> &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">shovel_size =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb811-2"><a href="one-parameter.html#cb811-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">use_shovel_results =</span> <span class="kw">map</span>(shovel_size,</span>
<span id="cb811-3"><a href="one-parameter.html#cb811-3"></a>                                  <span class="op">~</span><span class="st"> </span><span class="kw">use_shovel</span>(<span class="dt">x =</span> urn,</span>
<span id="cb811-4"><a href="one-parameter.html#cb811-4"></a>                                               <span class="dt">size =</span> .x,</span>
<span id="cb811-5"><a href="one-parameter.html#cb811-5"></a>                                               <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span></span>
<span id="cb811-6"><a href="one-parameter.html#cb811-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_results =</span> <span class="kw">map</span>(shovel_size,</span>
<span id="cb811-7"><a href="one-parameter.html#cb811-7"></a>                                <span class="op">~</span><span class="st"> </span><span class="kw">prop_red</span>(<span class="dt">x =</span> urn, </span>
<span id="cb811-8"><a href="one-parameter.html#cb811-8"></a>                                           <span class="dt">size =</span> .x, </span>
<span id="cb811-9"><a href="one-parameter.html#cb811-9"></a>                                           <span class="dt">reps =</span> <span class="dv">1000</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb811-10"><a href="one-parameter.html#cb811-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prop_red_sd =</span> <span class="kw">map_dbl</span>(prop_red_results, </span>
<span id="cb811-11"><a href="one-parameter.html#cb811-11"></a>                               <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., prop_red) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sd</span>()))</span>
<span id="cb811-12"><a href="one-parameter.html#cb811-12"></a><span class="kw">glimpse</span>(shovels_<span class="dv">100</span>)</span></code></pre></div>
<pre><code>## Rows: 100
## Columns: 4
## $ shovel_size        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…
## $ use_shovel_results &lt;list&gt; [&lt;grouped_df[1000 x 3]&gt;, &lt;grouped_df[2000 x 3]&gt;, …
## $ prop_red_results   &lt;list&gt; [&lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[1000 x 3]&gt;, &lt;tbl_df[…
## $ prop_red_sd        &lt;dbl&gt; 0.485, 0.344, 0.290, 0.238, 0.218, 0.197, 0.184, 0…</code></pre>
<p>Now, we have the standard deviation of <code>prop_red</code> for all shovel sizes from 1 to 100. Let’s plot that value to see how it changes as the shovel gets larger:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="one-parameter.html#cb813-1"></a>shovels_<span class="dv">100</span> <span class="op">%&gt;%</span></span>
<span id="cb813-2"><a href="one-parameter.html#cb813-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> shovel_size, <span class="dt">y =</span> prop_red_sd)) <span class="op">+</span></span>
<span id="cb813-3"><a href="one-parameter.html#cb813-3"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb813-4"><a href="one-parameter.html#cb813-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Shovel size"</span>,</span>
<span id="cb813-5"><a href="one-parameter.html#cb813-5"></a>       <span class="dt">y =</span> <span class="st">"Standard deviation of the proportion red"</span>)</span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-563"></span>
<p class="caption marginnote shownote">
FIGURE 6.16: Comparing standard deviations of proportions red for 100 different shovels
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-563-1.png" alt="Comparing standard deviations of proportions red for 100 different shovels" width="672">
</div>
<p><label for="tufte-mn-55" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-55" class="margin-toggle"><span class="marginnote">The formula for standard error is the sample standard deviation (s) divided by the square root of the number of samples (n). This may be written as: SE = s/(√n).</span></p>
<p>This is interesting! You may recognize that the standard deviation of the proportion red is declining at a rate proportional to the square root of the shovel size. This is something you could have discovered by finding a formula in a statistics textbook, but it’s easier to understand if you see it for yourself.</p>
<p>This is the power of running many analyses at once using <code>map_*</code> functions and list columns: before, we could tell that the standard deviation was decreasing as the shovel size increased, but when only looking at shovel sizes of 25, 50, and 100, it wasn’t clear <em>how quickly</em> it was decreasing.</p>
</div>
</div>
<div id="returning-to-our-question" class="section level2">
<h2>
<span class="header-section-number">6.3</span> Returning to our question</h2>
<p>Recall the question we asked at the beginning of our chapter: how many beads must we sample to have a 90% chance of being within 5% of the true proportion of red beads in the entire urn?</p>
<p>We have looked at a number of different models and their accuracy and precision. To delve into our primary question, we must return to our discussion of distributions: posterior, joint, and marginal.</p>
<div id="joint-distribution" class="section level3">
<h3>
<span class="header-section-number">6.3.1</span> Joint distribution</h3>
<p>In Chapter <a href="probability.html#probability">5</a> we outlined the key intuition behind all inference: there is a joint distribution of data-which-we-might-see-from-our-experiment and models-which-we-are-considering. We take this joint distribution, combine it with the actual results of the experiment, and calculate a posterior distribution over the set of possible models. In other words, we start with</p>
<p><span class="math display">\[p(models, data)\]</span></p>
<p>We then add the specific results of the experiment, and calculate the conditional distribution of the models, given the data that we have seen:</p>
<p><span class="math display">\[p(models | data = results-of-experiment)\]</span>
The rest is just details.</p>
<p>We can do the same thing with our sampling problem. Assume that we know that there are 2,400 beads in the urn, and that all of them are either red or white. Our experiment involves the one time use of a paddle with 50 slots. We have 2,401 models under consideration. There might be zero red beads or one red bead or … 2,399 red beads or 2,400 red beads. There are 51 possible results from our experiment: zero red beads or one red bead or . . . or 49 red beads or 50 red beads. With this information we can calculate the joint distribution of models which we are considering and experiment results we might observe.</p>
<!-- DK: I am somewhat concerned that this is not exactly correct since we really ought to sample what happens when you pick 50 beads out of an urn. This can be approximated with the binomial, which is what we have done here. And, with such big numbers, it is a good approximation. But it is not exactly correct. -->
<p><img src="book_temp_files/figure-html/unnamed-chunk-565-1.png" width="672"></p>
<p>We follow the same steps now as we did in Chapter <a href="probability.html#probability">5</a>. We run the experiment. Assume that 16 of the 50 beads drawn in the paddle were red. What does that make our posterior probability? We want:</p>
<p><span class="math display">\[p(models | data = 16)\]</span></p>
<p>The same approach works again. We take a “slice” of the joint distribution where the number of red beads in the paddle is equal to 16. After normalization, that gives us this posterior probability for the number of red beads in the urn:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-566-1.png" width="672"></p>
</div>
<div id="data-generating-mechanism" class="section level3">
<h3>
<span class="header-section-number">6.3.2</span> Data Generating Mechanism</h3>
</div>
<div id="the-leap-to-continuous" class="section level3">
<h3>
<span class="header-section-number">6.3.3</span> The Leap to Continuous</h3>
<!-- DK: I will take a shot at this. -->
</div>
</div>
<div id="sampling-framework" class="section level2">
<h2>
<span class="header-section-number">6.4</span> Sampling framework</h2>
<p>In both our tactile and our virtual sampling activities, we used sampling for the purpose of estimation. We extracted samples in order to <em>estimate</em> the proportion of the urn’s beads that are red. We used sampling as a less time-consuming approach than performing an exhaustive count of all the beads. Our virtual sampling activity built up to the results comparing 1,000 proportions red based on samples of size 25, 50, and 100, and finally expanding that to all the sizes between 1 and 100. This was our first attempt at understanding two key concepts relating to sampling for estimation:</p>
<ol style="list-style-type: decimal">
<li>The effect of <em>sampling variation</em> on our estimates.</li>
<li>The effect of sample size on <em>sampling variation</em>.</li>
</ol>
<p>Let’s now introduce some terminology and notation as well as statistical definitions related to sampling. You will likely want to read this section a few times. Keep in mind, however, that all of the concepts underlying these terminology, notation, and definitions tie directly to the concepts underlying our tactile and virtual sampling activities. It will simply take time and practice to master them.</p>
<div id="terminology-and-notation" class="section level3">
<h3>
<span class="header-section-number">6.4.1</span> Terminology and notation</h3>
<p>Here is a list of terminology and mathematical notation relating to sampling.</p>
<p>First, a <strong>population</strong> is a collection of individuals or observations we are interested in. This is also commonly denoted as a <strong>study population</strong>. We mathematically denote the population’s size using upper-case <span class="math inline">\(N\)</span>. In our sampling activities, the (study) population is the collection of <span class="math inline">\(N\)</span> = 2400 identically sized red and white beads contained in the urn.</p>
<p>Second, a <strong>population parameter</strong> is a numerical summary quantity about the population that is unknown, but you wish you knew. For example, when this quantity is a mean, the population parameter of interest is the <em>population mean</em>. This is mathematically denoted with the Greek letter <span class="math inline">\(\mu\)</span> pronounced “mu” (we’ll see a sampling activity involving means in the upcoming Section <a href="two-parameters.html#resampling-tactile">7.1</a>). In our earlier sampling from the urn activity, however, since we were interested in the proportion of the urn’s beads that were red, the population parameter is the <em>population proportion</em>. This is mathematically denoted with the letter <span class="math inline">\(p\)</span>.</p>
<p>Third, a <strong>census</strong> is an exhaustive enumeration or counting of all <span class="math inline">\(N\)</span> individuals or observations in the population in order to compute the population parameter’s value <em>exactly</em>. In our sampling activity, this would correspond to counting the number of beads out of <span class="math inline">\(N\)</span> = 2400 that are red and computing the <em>population proportion</em> <span class="math inline">\(p\)</span> that are red <em>exactly</em>. When the number <span class="math inline">\(N\)</span> of individuals or observations in our population is large as was the case with our urn, a census can be quite expensive in terms of time, energy, and money.</p>
<p>Fourth, <strong>sampling</strong> is the act of collecting a sample from the population when we don’t have the means to perform a census. We mathematically denote the sample’s size using lower case <span class="math inline">\(n\)</span>, as opposed to upper case <span class="math inline">\(N\)</span> which denotes the population’s size. Typically the sample size <span class="math inline">\(n\)</span> is much smaller than the population size <span class="math inline">\(N\)</span>. Thus sampling is a cheaper alternative to performing a census. In our sampling activities, we used shovels with varying slots to extract samples of size <span class="math inline">\(n\)</span> = 1 through <span class="math inline">\(n\)</span> = 100.</p>
<p>Fifth, a <strong>point estimate (AKA sample statistic)</strong> is a summary statistic computed from a sample that <em>estimates</em> an unknown population parameter. In our sampling activities, recall that the unknown population parameter was the population proportion and that this is mathematically denoted with <span class="math inline">\(p\)</span>. Our point estimate is the <em>sample proportion</em>: the proportion of the shovel’s beads that are red. In other words, it is our guess of the proportion of the urn’s beads that are red. We mathematically denote the sample proportion using <span class="math inline">\(\hat{p}\)</span>. The “hat” on top of the <span class="math inline">\(p\)</span> indicates that it is an estimate of the unknown population proportion <span class="math inline">\(p\)</span>.</p>
<p>Sixth is the idea of <strong>representative sampling</strong>. A sample is said to be a <em>representative sample</em> if it roughly <em>looks like</em> the population. In other words, are the sample’s characteristics a good representation of the population’s characteristics? In our sampling activity, are the samples of <span class="math inline">\(n\)</span> beads extracted using our shovels representative of the urn’s <span class="math inline">\(N\)</span> = 2400 beads?</p>
<p>Seventh is the idea of <strong>generalizability</strong>. We say a sample is generalizable if any results based on the sample can generalize to the population. In our sampling activity, can we generalize the sample proportion from our shovels to the entire urn? Using our mathematical notation, this is akin to asking if <span class="math inline">\(\hat{p}\)</span> is a “good guess” of <span class="math inline">\(p\)</span>?</p>
<p>Eighth, we say <strong>biased sampling</strong> occurs if certain individuals or observations in a population have a higher chance of being included in a sample than others. We say a sampling procedure is <em>unbiased</em> if every observation in a population had an equal chance of being sampled. Had the red beads been much smaller than the white beads, and therefore more prone to falling through the shovel, our sample would have been <em>biased</em>. In our sampling activities, since we mixed all <span class="math inline">\(N = 2400\)</span> beads prior to each group’s sampling and since each of the equally sized beads had an equal chance of being sampled, our samples were <em>unbiased</em>.</p>
<p>Ninth and lastly, the idea of <strong>random sampling</strong>. We say a sampling procedure is <em>random</em> if we sample randomly from the population in an unbiased fashion. In our sampling activities, this would correspond to sufficiently mixing the urn before each use of the shovel.</p>
<p>Phew, that’s a lot of new terminology and notation to learn! Let’s put them all together to describe the paradigm of sampling.</p>
<p><strong>In general:</strong></p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>“good guess”</strong> of the unknown population parameter, thus</li>
<li>instead of performing a census, we can <strong>infer</strong> about the population using sampling.</li>
</ul>
<p><strong>Specific to our sampling activity:</strong></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n=50\)</span> beads at <strong>random</strong>, in other words, we mix all of the equally sized beads before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn’s 2400 beads, thus</li>
<li>any result based on the shovel’s beads can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\hat{p}\)</span> of the <span class="math inline">\(n=50\)</span> beads in the shovel that are red is a <strong>“good guess”</strong> of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N=2400\)</span> beads that are red, thus</li>
<li>instead of manually going over all 2400 beads in the urn, we can <strong>infer</strong> about the urn using the shovel.</li>
</ul>
<p>Note that last word we wrote in bold: <strong>infer</strong>. The act of “inferring” means to deduce or conclude information from evidence and reasoning. In our sampling activities, we wanted to infer about the proportion of the urn’s beads that are red. <a href="https://en.wikipedia.org/wiki/Statistical_inference"><em>Statistical inference</em></a> is the “theory, methods, and practice of forming judgments about the parameters of a population and the reliability of statistical relationships, typically on the basis of random sampling.” In other words, statistical inference is the act of inference via sampling.</p>
</div>
<div id="sampling-definitions" class="section level3">
<h3>
<span class="header-section-number">6.4.2</span> Statistical definitions</h3>
<p>Now, for some important statistical definitions related to sampling. As a refresher of our 1,000 repeated/replicated virtual samples of size <span class="math inline">\(n\)</span> = 25, <span class="math inline">\(n\)</span> = 50, and <span class="math inline">\(n\)</span> = 100 in Section <a href="one-parameter.html#sampling-simulation">6.2</a>, let’s display our figure showing the difference in proportions red according to different shovel sizes.</p>
<div class="figure">
<span id="fig:unnamed-chunk-568"></span>
<p class="caption marginnote shownote">
FIGURE 6.17: Previously seen three distributions of the sample proportion <span class="math inline">\(\hat{p}\)</span>.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-568-1.png" alt="Previously seen three distributions of the sample proportion $\hat{p}$." width="672">
</div>
<p>These types of distributions have a special name: <strong>sampling distributions</strong>; their visualization displays the effect of sampling variation on the distribution of a point estimate; in this case, the sample proportion <span class="math inline">\(\hat{p}\)</span>. Using these sampling distributions, for a given sample size <span class="math inline">\(n\)</span>, we can make statements about what values we typically expect.</p>
<p>For example, observe the centers of all three sampling distributions: they are all roughly centered around <span class="math inline">\(0.4 = 40\%\)</span>. Furthermore, observe that while we are somewhat likely to observe sample proportions of red beads of <span class="math inline">\(0.2 = 20\%\)</span> when using the shovel with 25 slots, we will almost never observe a proportion of 20% when using the shovel with 100 slots. Observe also the effect of sample size on the sampling variation. As the sample size <span class="math inline">\(n\)</span> increases from 25 to 50 to 100, the variation of the sampling distribution decreases and thus the values cluster more and more tightly around the same center of around 40%. We quantified this variation using the standard deviation of our sample proportions, seeing that the standard deviation decreases with the square root of the sample size:</p>
<div class="figure">
<span id="fig:unnamed-chunk-569"></span>
<p class="caption marginnote shownote">
FIGURE 6.18: Previously seen comparing standard deviations of proportions red for 100 different shovels
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-569-1.png" alt="Previously seen comparing standard deviations of proportions red for 100 different shovels" width="672">
</div>
<p>So as the sample size increases, the standard deviation of the proportion of red beads decreases. This type of standard deviation has another special name: <strong>standard error</strong>. Standard errors quantify the effect of sampling variation induced on our estimates. In other words, they quantify how much we can expect different proportions of a shovel’s beads that are red <em>to vary</em> from one sample to another sample to another sample, and so on. As a general rule, as sample size increases, the standard error decreases.</p>
<p>Unfortunately, these names confuse many people who are new to statistical inference. For example, it’s common for people who are new to statistical inference to call the “sampling distribution” the “sample distribution.” Another additional source of confusion is the name “standard deviation” and “standard error.” Remember that a standard error is merely a <em>kind</em> of standard deviation: the standard deviation of any point estimate from sampling. In other words, all standard errors are standard deviations, but not every standard deviation is necessarily a standard error.</p>
<p>To help reinforce these concepts, let’s re-display Figure 6.14 but using our new terminology, notation, and definitions relating to sampling in the figure below.</p>
<div class="figure">
<span id="fig:unnamed-chunk-570"></span>
<p class="caption marginnote shownote">
FIGURE 6.19: Three sampling distributions of the sample proportion <span class="math inline">\(\hat{p}\)</span>.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-570-1.png" alt="Three sampling distributions of the sample proportion $\hat{p}$." width="672">
</div>
<p>Furthermore, let’s display the graph of standard errors for <span class="math inline">\(n = 1\)</span> to <span class="math inline">\(n = 100\)</span> using our new terminology, notation, and definitions relating to sampling.</p>
<div class="figure">
<span id="fig:unnamed-chunk-571"></span>
<p class="caption marginnote shownote">
FIGURE 6.20: Standard errors of the sample proportion based on sample sizes of 1 to 100
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-571-1.png" alt="Standard errors of the sample proportion based on sample sizes of 1 to 100" width="672">
</div>
<p>Remember the key message of this last table: that as the sample size <span class="math inline">\(n\)</span> goes up, the “typical” error of your point estimate will go down, as quantified by the <em>standard error</em>.</p>
</div>
<div id="moral-of-the-story" class="section level3">
<h3>
<span class="header-section-number">6.4.3</span> The moral of the story</h3>
<p>Let’s recap this section so far. We’ve seen that if a sample is generated at random, then the resulting point estimate is a “good guess” of the true unknown population parameter. In our sampling activities, since we made sure to mix the beads first before extracting a sample with the shovel, the resulting sample proportion <span class="math inline">\(\hat{p}\)</span> of the shovel’s beads that were red was a “good guess” of the population proportion <span class="math inline">\(p\)</span> of the urn’s beads that were red.</p>
<p>However, what do we mean by our point estimate being a “good guess”? Sometimes, we’ll get an estimate that is less than the true value of the population parameter, while at other times we’ll get an estimate that is greater. This is due to sampling variation. Despite this sampling variation, our estimates will “on average” be correct and thus will be centered at the true value. This is because our sampling was done at random and thus in an unbiased fashion.</p>
<p>In our sampling activities, sometimes our sample proportion <span class="math inline">\(\hat{p}\)</span> was less than the true population proportion <span class="math inline">\(p\)</span>, while at other times it was greater. This was due to the sampling variability. However, despite this sampling variation, our sample proportions <span class="math inline">\(\hat{p}\)</span> were “on average” correct and thus were centered at the true value of the population proportion <span class="math inline">\(p\)</span>. This is because we mixed our urn before taking samples and thus the sampling was done at random and thus in an unbiased fashion. This is also known as having an <em>accurate</em> estimate.</p>
<p>What was the value of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N\)</span> = 2400 beads in the actual urn that were red? There were 900 red beads, for a proportion red of 900/2400 = 0.375 = 37.5%! How do we know this? Did the authors do an exhaustive count of all the beads? No! They were listed in the contents of the box that the urn came in! Hence we were able to make the contents of the virtual <code>urn</code> match the tactile urn:</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="one-parameter.html#cb814-1"></a>urn <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb814-2"><a href="one-parameter.html#cb814-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">sum_red =</span> <span class="kw">sum</span>(color <span class="op">==</span><span class="st"> "red"</span>), </span>
<span id="cb814-3"><a href="one-parameter.html#cb814-3"></a>            <span class="dt">sum_not_red =</span> <span class="kw">sum</span>(color <span class="op">!=</span><span class="st"> "red"</span>), <span class="dt">.groups =</span> <span class="st">'drop_last'</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 2
##   sum_red sum_not_red
##     &lt;int&gt;       &lt;int&gt;
## 1     900        1500</code></pre>
<p>Let’s re-display our sampling distributions from earlier, but now with a vertical red line marking the true population proportion <span class="math inline">\(p\)</span> of beads that are red = 37.5% in Figure 6.19 below. We see that while there is a certain amount of error in the sample proportions <span class="math inline">\(\hat{p}\)</span> for all three sampling distributions, on average the <span class="math inline">\(\hat{p}\)</span> are centered at the true population proportion red <span class="math inline">\(p\)</span>.</p>
<div class="figure">
<span id="fig:unnamed-chunk-573"></span>
<p class="caption marginnote shownote">
FIGURE 6.21: Three sampling distributions with population proportion <span class="math inline">\(p\)</span> marked by vertical line.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-573-1.png" alt="Three sampling distributions with population proportion $p$ marked by vertical line." width="672">
</div>
<p>At this point, you might be asking yourself: “If we already knew the true proportion of the urn’s beads that are red was 37.5%, then why did we do any sampling?” You might also be asking: “Why did we take 1,000 repeated samples of various sizes (n = 1 to n = 100)? Shouldn’t we be taking only <em>one</em> sample that’s as large as possible?”. If you did ask yourself these questions, your suspicion is merited!</p>
<p>The sampling activity involving the urn is merely an <em>idealized version</em> of how sampling is done in real life. We performed this exercise only to study and understand:</p>
<ol style="list-style-type: decimal">
<li>The effect of sampling variation.</li>
<li>The effect of sample size on sampling variation.</li>
</ol>
<p>This is not how sampling is done in real life. In a real-life scenario, we won’t know what the true value of the population parameter is. Furthermore, we wouldn’t be able to take 1,000 replicated samples. Rather, we take a single sample that’s as large as we can afford. In the next section, we’ll study a real-life example of sampling: polls.</p>
</div>
</div>
<div id="sampling-case-study" class="section level2">
<h2>
<span class="header-section-number">6.5</span> Case study: Polls</h2>
<p>Let’s now switch gears to a more realistic sampling scenario than our urn activity: a poll. In practice, pollsters do not take 1,000 repeated samples as we did in our previous sampling activities, but rather take only a <em>single sample</em> that’s as large as possible.</p>
<p>On December 4, 2013, National Public Radio in the US reported on a poll of President Obama’s approval rating among young Americans aged 18-29 in an article, <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">“Poll: Support For Obama Among Young Americans Eroding.”</a> The poll was conducted by the Kennedy School’s Institute of Politics at Harvard University. A quote from the article:</p>
<blockquote>
<p>After voting for him in large numbers in 2008 and 2012, young Americans are souring on President Obama.</p>
<p>According to a new Harvard University Institute of Politics poll, just 41 percent of millennials — adults ages 18-29 — approve of Obama’s job performance, his lowest-ever standing among the group and an 11-point drop from April.
Let’s tie elements of the real-life poll in this new article with our “tactile” and “virtual” urn activity from Sections <a href="one-parameter.html#sampling-activity">6.1</a> and <a href="one-parameter.html#sampling-simulation">6.2</a> using the terminology, notations, and definitions we learned in Section <a href="one-parameter.html#sampling-framework">6.4</a>. You’ll see that our sampling activity with the urn is an idealized version of what pollsters are trying to do in real life.</p>
</blockquote>
<p>First, who is the <strong>(Study) Population</strong> of <span class="math inline">\(N\)</span> individuals or observations of interest?</p>
<ul>
<li>Urn: <span class="math inline">\(N\)</span> = 2400 identically sized red and white beads</li>
<li>Obama poll: <span class="math inline">\(N\)</span> = ? young Americans aged 18-29</li>
</ul>
<p>Second, what is the <strong>population parameter</strong>?</p>
<ul>
<li>Urn: The population proportion <span class="math inline">\(p\)</span> of <em>all</em> the beads in the urn that are red.</li>
<li>Obama poll: The population proportion <span class="math inline">\(p\)</span> of <em>all</em> young Americans who approve of Obama’s job performance.</li>
</ul>
<p>Third, what would a <strong>census</strong> look like?</p>
<ul>
<li>Urn: Manually going over all <span class="math inline">\(N\)</span> = 2400 beads and exactly computing the population proportion <span class="math inline">\(p\)</span> of the beads that are red.</li>
<li>Obama poll: Locating all <span class="math inline">\(N\)</span> young Americans and asking them all if they approve of Obama’s job performance. In this case, we don’t even know what the population size <span class="math inline">\(N\)</span> is!</li>
</ul>
<p>Fourth, how do you perform <strong>sampling</strong> to obtain a sample of size <span class="math inline">\(n\)</span>?</p>
<ul>
<li>Urn: Using a shovel with <span class="math inline">\(n\)</span> slots.</li>
<li>Obama poll: One method is to get a list of phone numbers of all young Americans and pick out <span class="math inline">\(n\)</span> phone numbers. In this poll’s case, the sample size of this poll was <span class="math inline">\(n = 2089\)</span> young Americans.</li>
</ul>
<p>Fifth, what is your <strong>point estimate (AKA sample statistic)</strong> of the unknown population parameter?</p>
<ul>
<li>Urn: The sample proportion <span class="math inline">\(\hat{p}\)</span> of the beads in the shovel that were red.</li>
<li>Obama poll: The sample proportion <span class="math inline">\(\hat{p}\)</span> of young Americans in the sample that approve of Obama’s job performance. In this poll’s case, <span class="math inline">\(\hat{p} = 0.41 = 41\%\)</span>, the quoted percentage in the second paragraph of the article.</li>
</ul>
<p>Sixth, is the sampling procedure <strong>representative</strong>?</p>
<ul>
<li>Urn: Are the contents of the shovel representative of the contents of the urn? Because we mixed the urn before sampling, we can feel confident that they are.</li>
<li>Obama poll: Is the sample of <span class="math inline">\(n = 2089\)</span> young Americans representative of <em>all</em> young Americans aged 18-29? This depends on whether the sampling was random.</li>
</ul>
<p>Seventh, are the samples <strong>generalizable</strong> to the greater population?</p>
<ul>
<li>Urn: Is the sample proportion <span class="math inline">\(\hat{p}\)</span> of the shovel’s beads that are red a “good guess” of the population proportion <span class="math inline">\(p\)</span> of the urn’s beads that are red? Given that the sample was representative, the answer is yes.</li>
<li>Obama poll: Is the sample proportion <span class="math inline">\(\hat{p} = 0.41\)</span> of the sample of young Americans who supported Obama a “good guess” of the population proportion <span class="math inline">\(p\)</span> of all young Americans who supported Obama at this time in 2013? In other words, can we confidently say that roughly 41% of <em>all</em> young Americans approved of Obama at the time of the poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Eighth, is the sampling procedure <strong>unbiased</strong>? In other words, do all observations have an equal chance of being included in the sample?</p>
<ul>
<li>Urn: Since each bead was equally sized and we mixed the urn before using the shovel, each bead had an equal chance of being included in a sample and hence the sampling was unbiased.</li>
<li>Obama poll: Did all young Americans have an equal chance at being represented in this poll? Again, this depends on whether the sampling was random.</li>
</ul>
<p>Ninth and lastly, was the sampling done at <strong>random</strong>?</p>
<ul>
<li>Urn: As long as you mixed the urn sufficiently before sampling, your samples would be random.</li>
<li>Obama poll: Was the sample conducted at random? We can’t answer this question without knowing about the <em>sampling methodology</em> used by Kennedy School’s Institute of Politics at Harvard University. We’ll discuss this more at the end of this section.</li>
</ul>
<p>In other words, the poll by Kennedy School’s Institute of Politics at Harvard University can be thought of as <em>an instance</em> of using the shovel to sample beads from the urn. Furthermore, if another polling company conducted a similar poll of young Americans at roughly the same time, they would likely get a different estimate than 41%. This is due to <em>sampling variation</em>.</p>
<p>Let’s now revisit the sampling paradigm from Subsection <a href="one-parameter.html#terminology-and-notation">6.4.1</a>:</p>
<p><strong>In general</strong>:</p>
<ul>
<li>If the sampling of a sample of size <span class="math inline">\(n\)</span> is done at <strong>random</strong>, then</li>
<li>the sample is <strong>unbiased</strong> and <strong>representative</strong> of the population of size <span class="math inline">\(N\)</span>, thus</li>
<li>any result based on the sample can <strong>generalize</strong> to the population, thus</li>
<li>the point estimate is a <strong>“good guess”</strong> of the unknown population parameter, thus</li>
<li>instead of performing a census, we can <strong>infer</strong> about the population using sampling.</li>
</ul>
<p><strong>Specific to the urn:</strong></p>
<ul>
<li>If we extract a sample of <span class="math inline">\(n = 50\)</span> beads at <strong>random</strong>, in other words, we mix all of the equally sized beads before using the shovel, then</li>
<li>the contents of the shovel are an <strong>unbiased representation</strong> of the contents of the urn’s 2400 beads, thus</li>
<li>any result based on the shovel’s beads can <strong>generalize</strong> to the urn, thus</li>
<li>the sample proportion <span class="math inline">\(\hat{p}\)</span> of the <span class="math inline">\(n = 50\)</span> beads in the shovel that are red is a <strong>“good guess”</strong> of the population proportion <span class="math inline">\(p\)</span> of the <span class="math inline">\(N = 2400\)</span> beads that are red, thus</li>
<li>instead of manually going over all 2400 beads in the urn, we can <strong>infer</strong> about the urn using the shovel.</li>
</ul>
<p><strong>Specific to the Obama poll:</strong></p>
<ul>
<li>If we had a way of contacting a <strong>randomly</strong> chosen sample of 2089 young Americans and polling their approval of President Obama in 2013, then</li>
<li>these 2089 young Americans would be an <strong>unbiased</strong> and <strong>representative</strong> sample of <em>all</em> young Americans in 2013, thus</li>
<li>any results based on this sample of 2089 young Americans can <strong>generalize</strong> to the entire population of <em>all</em> young Americans in 2013, thus</li>
<li>the reported sample approval rating of 41% of these 2089 young Americans is a <strong>good guess</strong> of the true approval rating among all young Americans in 2013, thus</li>
<li>instead of performing an expensive census of all young Americans in 2013, we can <strong>infer</strong> about all young Americans in 2013 using polling.</li>
</ul>
<p>So as you can see, it was critical for the sample obtained by Kennedy School’s Institute of Politics at Harvard University to be truly random in order to infer about <em>all</em> young Americans’ opinions about Obama. Was their sample truly random? It’s hard to answer such questions without knowing about the <em>sampling methodology</em> they used.</p>
<p>For example, what if Kennedy School’s Institute of Politics at Harvard University conducted this poll using only mobile phone numbers? People without mobile phones would be left out and therefore not represented in the sample. This flaw is an example of <strong>censoring</strong>, the exclusion of certain datapoints due to an issue with data collection. This results in an incomplete observation and increases the prediction uncertainty of the estimand, Obama’s approval rating amount young Americans. Ensuring that our samples were random was easy to do in our sampling urn exercises; however, in a real-life situation like the Obama poll, this is much harder to do.</p>
<p><label for="tufte-mn-56" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-56" class="margin-toggle"><span class="marginnote">What you have visualized in this chapter was a demonstration of a famous theorem, or mathematically proven truth, called the <em>Central Limit Theorem</em>. It loosely states that when sample means are based on larger and larger sample sizes, the sampling distribution of these sample means becomes both more and more normally shaped and more and more narrow. In other words, the sampling distribution increasingly follows a <em>normal distribution</em> and the variation of these sampling distributions gets smaller, as quantified by their standard errors.</span></p>
<div id="prudence-is-this-relevant" class="section level3">
<h3>
<span class="header-section-number">6.5.1</span> Prudence: Is this relevant?</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/prudence.jpg" alt=" " width="1280"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Recall that prudence, one of our key themes, encompasses two primary issues: the relevance of the estimand and the map from concept to data.</p>
<p>In our polling example, is the estimand, Obama’s approval rating, relevant to the research question we want to answer? If we wanted to know Obama’s approval rating (and nothing else), yes. But, that’s not the case here. The aim of this poll is to draw a conclusion about a voter’s likelihood of voting for Obama in the next election <em>using</em> the approval rating as a predictive measure for voting behavior.</p>
<p>Our problem, estimating Obama’s electability in young people, is not solved by this poll. If we wanted to know the answer to this problem, we would need to change a few key aspects of the sampling.</p>
<p>First, not all young Americans vote! In fact, many do not. Therefore, if we wanted to draw a conclusion about Obama’s favorability among young American <strong>voters</strong>, the sample population would need to be modified to only include registered voters with the intention of voting in the next election. A sample population of random young Americans, with no question on voting behavior, tells us almost nothing about our key problem.</p>
<p>Second, we need to change the question. The <em>true</em> question is not Obama’s favoribility among young Americans, but is actually: will you or will you not vote for Obama in the next election? To allow more flexibility in responses and get a range of responses that accurately refect uncertainty and likelihood, we might pose the following question: on a scale from one to ten, with one being “most definitely not” and ten being “most definitely”, how likely are you to vote for Obama in the next election?</p>
<p>It is extremely important, but often overlooked, that <strong>the data we are analyzing should map to the research question we are trying to answer</strong>. In our polling example, we’ve just discovered that the collected data tells us very little about what we really want to know. Both the sample population and the research question are flawed and therefore offer us very little information that is relevant to our key issue: the voting behavior of young Americans in the next election.</p>
</div>
<div id="justice-math-and-other-problems" class="section level3">
<h3>
<span class="header-section-number">6.5.2</span> Justice: Math and other problems</h3>
<p>First, we must determine if we are modeling (just) for prediction or if we are (also) modeling for causation. Another way of looking at this is are we using a model for prediction or a model for explanation.</p>
<p>When polling on the attitude of young Americans towards Obama, we are not measuring a causal effect. When models are causal, we change the value of one input and figure out what the new output would be, thus allowing us to calculate a causal effect for a specific individual. Here, we are using the attitude of young Americans towards Obama to <strong>predict</strong> the outcome of the next election.</p>
<p>Disregarding the fact that we now know our central question does not address our main goal, let’s consider what a predictive model means in terms of our Preceptor Tables. First, know that in our actual Preceptor Table for this poll, we have the results for 2089 young Americans from a total population of young Americans that exceeds 50 million units (people). That means that, in our actual Preceptor Table, we have more than 50 million rows, with a mere 2089 rows that include an approval rating.</p>
<!-- DK: Put in a Preceptor Table -->
<p>An ideal Preceptor Table for this case would report an approval rating for <em>every one of our 50 million rows</em>. It quickly becomes clear, with a popuation size this large, why sampling and generalizing are essential to practical inference.</p>
<p>Recall that an infinite Preceptor Table gives us any information we want to know about all one of our units. Though an infinite Preceptor Table is not practial or even possible in most contexts, it’s important to consider how we decrease the size of the infinite Preceptor Table, mostly by assuming that certain rows and columns are “exchangeable”. This is where we run into the issue of realism in our polling example. This poll assumes that the columns for “approval rating of Obama” and “who-are-you-planning-to-vote-for” are interchangable. As we’ve seen, these columns aren’t analogs!</p>
<!-- Maybe include some notion of the data generating mechanism, which is $y_i ~ binomial(p)$ 

fitted value, error. Check out themes.
-->
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/justice.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
</div>
<div id="fortitude-filling-in-the-blanks" class="section level3">
<h3>
<span class="header-section-number">6.5.3</span> Fortitude: Filling in the blanks</h3>
<p>Our actual Preceptor Table is riddled with question marks. How do we fill them in?</p>
<p>There are few more important concepts in statistics and data science than the <strong>Data Generating Mechanism</strong> (DGM). Our <em>data</em>, the data that we collect and see, has been <em>generated</em> by the complexity and confusion of the world. The universes’s own <em>mechanism</em> has brought this data to us. Our job is to build a model of that process, to create, on the computer, a mechanism which generates fake data consistent with the data which we see. With that DGM, we can answer any question which we might have. In particular, with the DGM, we provide predictions of data we have not seen and estimates of the uncertainty associated with those predictions.</p>
<p>We need a “machine” which generates these predictions, which is the same thing as a machine which fills in all the question marks in the actual Preceptor Table, which is the same thing as a machine which produces “fake data” which looks a lot like our actual data.</p>
<p>The theme of fortitude places an emphasis on two things: the code which brings the model to life and the uncertainty of real life which impacts the model’s place in the world.</p>
<!-- Bring in DGM for the polling by asking a question like: What are the odds, if a bring in 10 random Americans, that at least 2 of them support Obama? -->
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/fortitude.jpg" alt=" " width="1024"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
</div>
<div id="temperance-be-humble" class="section level3">
<h3>
<span class="header-section-number">6.5.4</span> Temperance: Be humble</h3>
<p>Temperance is perhaps the most important virtue in data science. Our models are never as good as they appear to be. The world is complex and, even worse, always changing. We must be aware of the <em>unknown unknowns</em>, concerned about how <em>representative</em> our data/model is to our problem, worried about the realism of our assumptions, and leery of the siren call of testing. In simpler terms, we must be humble.</p>
<iframe src="https://www.youtube.com/embed/tvTRZJ-4EyI?showcase=0" width="672" height="400px">
</iframe>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/temperance.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>What we really care about is data we haven’t seen yet, mostly data from tomorrow. But what if the world changes, as it always does? In general, the world changes some. That means that are forecasts are more uncertain that a naive use of our model might suggest.</p>
<p>To apply this to our poll, what would happen if, the week after the poll is conducted, America entered into war with another nation? What if there was an outbreak of a dangerous virus, spurring a global pandemic? Our poll cannot account for such events, known as <em>unknown unknowns</em>, as they have not happened at the time that we collected data. But our conclusions about the world a week later, after the announcement of war or the outbreak of a virus, are largely going to be wrong!</p>
<p>This brings us to yet another reason we must be humble with our conclusions: realism. Does the structure of the model match the world? If it does not (and it never does) then all the inferences we make will be wrong. We just hope that they won’t be too wrong.</p>
<p>Is asking a random sample of young Americans their approval rating of Obama going to give us enough information to predict the outcome of the next election? No! Does it give us enough information to predict the voting behavior of young Americans at that specific point in time? Sadly, also no.</p>
<p>The assumptions which allowed the poll to move from the infinite Preceptor Table to the ideal Preceptor Table are not plausible. Because the goal of the poll (to predict whether a young American will vote for Obama) does not match the question being asked (the approval rating of Obama among a random sample of young Americans), the model lacks the realism that allows our inferences to be applied to the real world.</p>
<p>That being said, even if the model had asked a better question (“How likely are you to vote for Obama in the next election?”) to a more appropriate sample (registered voters between the ages of 19 and 34), there is <em>still</em> too much uncertainty with the real world to assume our conclusions will be relevant the next day, the next week, or the next month.</p>
</div>
<div id="rubin-causal-model" class="section level3">
<h3>
<span class="header-section-number">6.5.5</span> Rubin Causal Model</h3>
<p>Now that we have mastered sampling, let’s consider how these scenarios connect to the Rubin Causal Model (RCM).</p>
<p>For the most part, they don’t!</p>
<p>Remember the RCM’s slogan: <em>No causation without manipulation</em>. In both the urn example and our Obama poll, we are not manipulating our units (the beads and the opinions of the pollees, respectively). There are not a control and treatment condition to compare; there is no causal effect to measure. Therefore, the RCM cannot be directly applied to these scenarios.</p>
</div>
</div>
<div id="sampling-mechanism" class="section level2">
<h2>
<span class="header-section-number">6.6</span> Sampling Mechanism</h2>
<p>One of the most important aspects of sampling is the <strong>sampling mechanism</strong>: the mechanism through which we sample our population. This concept is related, but distinctly different, from the <strong>assignment mechanism</strong> that we learned about in Chapter 3.</p>
<p>The assignment mechanism sorts units into control and experiment groups, while the sampling mechanism is the means through which we aquire our sample. Assignment mechanisms do not have a place in our urn paradigm since we are not measuring any causal relationship or assigning beads to specific groups.</p>
<p>To think about the sampling mechanism further: why are certain beads sampled, while others are not? Is this completely random?</p>
<p>In order to investigate this concept, let’s revisit our Preceptor Tables.</p>
<div id="preceptor-tables" class="section level3">
<h3>
<span class="header-section-number">6.6.1</span> Preceptor Tables</h3>
<p>Recall that a Preceptor Table is a table with rows and columns for all the data we would (reasonably) like to have. There are two different types of Preceptor Tables that are applicable to our urn example: actual and ideal.</p>
<p>An actual Preceptor Table shows what we <em>actually</em> know. Accordingly, the table is riddled with question marks that the real world saddles us with. The ideal Preceptor Table is the Preceptor Table with no question marks, and a reasonable number of rows and columns. With an ideal Preceptor Table, there is need for inference; the estimand is a simple matter of arithmetic.</p>
<p>To visualize the different Preceptor Tables and their usefulness to us data scientists, let’s revisit our urn.</p>
</div>
<div id="ideal-preceptor-table-what-we-wish-we-knew" class="section level3">
<h3>
<span class="header-section-number">6.6.2</span> Ideal Preceptor Table: What we wish we knew</h3>
<p>As is the case in the Rubin Causal Model, we <em>wish</em> we knew the values for every single unit in every possible scenario. The analogous ideal here would be a table where we know the color identity of every single bead. To compare to our previous Preceptor Table, this is what our ideal Preceptor Table would look like:</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#vngjguzslq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vngjguzslq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vngjguzslq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vngjguzslq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vngjguzslq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vngjguzslq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vngjguzslq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vngjguzslq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vngjguzslq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vngjguzslq .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vngjguzslq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vngjguzslq .gt_from_md > :first-child {
  margin-top: 0;
}

#vngjguzslq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#vngjguzslq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vngjguzslq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vngjguzslq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vngjguzslq .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vngjguzslq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vngjguzslq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vngjguzslq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vngjguzslq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vngjguzslq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vngjguzslq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vngjguzslq .gt_left {
  text-align: left;
}

#vngjguzslq .gt_center {
  text-align: center;
}

#vngjguzslq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vngjguzslq .gt_font_normal {
  font-weight: normal;
}

#vngjguzslq .gt_font_bold {
  font-weight: bold;
}

#vngjguzslq .gt_font_italic {
  font-style: italic;
}

#vngjguzslq .gt_super {
  font-size: 65%;
}

#vngjguzslq .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="vngjguzslq" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>ID</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Year</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">1</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">200</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">201</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2399</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2400</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
</tbody>
</table></div>
<p>This Preceptor Table is possible by performing the exhaustive hand count of the entire urn. Let’s say that, after this tedious process, we find that the <strong>true</strong> and <strong>real</strong> proportion of red beads is exactly 37.5%. We know each bead’s color identity in the entire urn. To revisit the terminology of Chapter 5, we would be dealing with P(A|B), the probability of bead 1 being red given that we know the color_ID of every single bead in the urn. If the proportion of red beads is <strong>exactly</strong> 37.5%, we can say whether bead 1 is red or not with 100% certainty, since we know the exact number of red and white beads in the urn.</p>
<p>In this world, the estimand, the proportion of red beads in the urn, is a simple matter of arithmetic. However, as has been emphasized before, performing an exhaustive count is not the easiest way to estimate the proportion of red beads. Real-life sampling is far more complex. The process is <strong>extremely</strong> prone to error. Despite that, most people overestimate the validity of conclusions drawn from sampling. To stress the unknowns in sampling, let’s look at our actual Preceptor Table.</p>
</div>
<div id="actual-preceptor-table-what-we-know" class="section level3">
<h3>
<span class="header-section-number">6.6.3</span> Actual Preceptor Table: What we know</h3>
<p>Let’s imagine we use our shovel and sample 100 beads from the urn. After taking our sample, we find that 40% of the <em>sampled</em> beads are red. Let’s visualize this by looking at the entire urn after our sample in an actual Preceptor Table. We only know the colors of our randomly sampled 100 beads, the rest of the bead colors is our missing data!</p>
<p><label for="tufte-mn-57" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-57" class="margin-toggle"><span class="marginnote">Not all the rows in our actual Preceptor Table are shown, but you can imagine we have a lot of missing data with only some values filled in for the colors.</span></p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#nuwhogovgo .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#nuwhogovgo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#nuwhogovgo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#nuwhogovgo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nuwhogovgo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#nuwhogovgo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#nuwhogovgo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#nuwhogovgo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#nuwhogovgo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#nuwhogovgo .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#nuwhogovgo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#nuwhogovgo .gt_from_md > :first-child {
  margin-top: 0;
}

#nuwhogovgo .gt_from_md > :last-child {
  margin-bottom: 0;
}

#nuwhogovgo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#nuwhogovgo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#nuwhogovgo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nuwhogovgo .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#nuwhogovgo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nuwhogovgo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#nuwhogovgo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#nuwhogovgo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nuwhogovgo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#nuwhogovgo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#nuwhogovgo .gt_left {
  text-align: left;
}

#nuwhogovgo .gt_center {
  text-align: center;
}

#nuwhogovgo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#nuwhogovgo .gt_font_normal {
  font-weight: normal;
}

#nuwhogovgo .gt_font_bold {
  font-weight: bold;
}

#nuwhogovgo .gt_font_italic {
  font-style: italic;
}

#nuwhogovgo .gt_super {
  font-size: 65%;
}

#nuwhogovgo .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="nuwhogovgo" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>ID</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Color</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">1</td>
      <td class="gt_row gt_center">?</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2</td>
      <td class="gt_row gt_center">?</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">200</td>
      <td class="gt_row gt_center">white</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">201</td>
      <td class="gt_row gt_center">?</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2399</td>
      <td class="gt_row gt_center">red</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2400</td>
      <td class="gt_row gt_center">?</td>
    </tr>
</tbody>
</table></div>
<p>Where is all of our data? Well, when we took a sample of 100 beads from the total urn, we only have color identifications for 100 of the total 2400 beads in the urn. The rest of the beads were not sampled and we cannot say for certain whether they are white or red.</p>
<p>Something else we must consider is why some beads <strong>do</strong> get sampled, while others do not. This is a consequence of the sampling mechanism. Because we are drawing the sample using a shovel with 100 slots, we only have 100 known values. Therefore, our shovel (in addition to mixing the urn beforehand) is our sampling mechanism!</p>
<p>Consider this: what does this information tell us, specifically, about Bead 1? Bead 2? We know the proportion of red beads in our sample is 40%. Does this mean that bead 1 has a 40% chance of being red? As we learned in Chapter 5, this is not true! Let’s delve into why this assumption is wrong.</p>
<p>We can only claim <em>for certain</em> that, of the 100 beads that we sampled (of the total 2400 beads in the urn), 40% were red. If we were making a prediction of the probability of one of our <strong>sampled</strong> beads being red, 40% would be the correct guess! If we were making a prediction of the probability that an <strong>unsampled</strong> bead was red, the answer of 40% would be incorrect. Let’s revisit the histogram of our 1000 virtually sampled proportions using a virtual shovel.</p>
<div class="figure">
<span id="fig:unnamed-chunk-581"></span>
<p class="caption marginnote shownote">
FIGURE 6.22: Histogram showing the proportions of 50 beads that were red in 1000 replications.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-581-1.png" alt="Histogram showing the proportions of 50 beads that were red in 1000 replications." width="672">
</div>
<p>Here, we see a decent amount of variation in the proportion of red beads. In some extreme cases, our proportion was as low as 20% and as high as 60%! If we took either one of these extremes and tried to make an assumption of bead 1, we would most certainly be incorrect. This is why we run many simulations to make the <em>best possible prediction</em>. To make the best possible predicition, our point estimates must be <strong>accurate</strong> and <strong>precise</strong>. What do those two words mean in terms of sampling? Let’s find out!</p>
</div>
<div id="precision-versus-accuracy" class="section level3">
<h3>
<span class="header-section-number">6.6.4</span> Precision versus accuracy</h3>
<p>We saw in the previous section that as your sample size <span class="math inline">\(n\)</span> increases, your point estimates will vary less and less and be more and more concentrated around the true population parameter. This variation is quantified by the decreasing <em>standard error</em>. In other words, the typical error of your point estimates will decrease. In our sampling exercise, as the sample size increased, the variation of our sample proportions <span class="math inline">\(\hat{p}\)</span> decreased. This is also known as having a <em>precise</em> estimate.</p>
<p>So random sampling ensures our point estimates are <em>accurate</em>, while on the other hand having a large sample size ensures our point estimates are <em>precise</em>. While the terms “accuracy” and “precision” may sound like they mean the same thing, there is a subtle difference. Accuracy describes how “on target” our estimates are, whereas precision describes how “consistent” our estimates are. The figure below illustrates the difference.</p>
<div class="figure">
<span id="fig:unnamed-chunk-582"></span>
<p class="caption marginnote shownote">
FIGURE 6.23: Comparing accuracy and precision.
</p>
<img src="06-one-parameter/images/accuracy_vs_precision.jpg" alt="Comparing accuracy and precision." width="567">
</div>
<p>Now, it’s obvious that the best case scenario is the most precise and the most accurate option. However, real-life sampling isn’t so easy!</p>
<p>What if we had the option to use a shovel with <strong>200</strong> slots, but it had a minor magnetic property that caused it to pick up slightly more red beads than the 100 slotted shovel? On one hand, the larger shovel gives us increased precision due to a larger sample size. On the other, its magnetic property gives us decreased accuracy due to a sampling bias. Here, as is often the case in the real-world, there is a tradeoff!</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-583"></span>
<img src="06-one-parameter/images/accurate_precise_meme.png" alt="Which one? Hard choice!" width="369"><!--
<p class="caption marginnote">-->FIGURE 6.24: Which one? Hard choice!<!--</p>-->
<!--</div>--></span>
</p>
</div>
<div id="sampling-is-hard" class="section level3">
<h3>
<span class="header-section-number">6.6.5</span> Sampling is hard!</h3>
<p>As we just learned, there are often decisions that we, as data scientists, must make when sampling. We might have an option with increased precision but decreased accuracy, or vice versa. Those troubles aren’t the only ones that we must consider in sampling. There are two other major sources of sampling error: <strong>bias</strong> and <strong>censoring</strong>.</p>
<p><strong>Bias</strong> in the sampling mechanism can adversely impact the validity of our results. In our urn example, bias could be that the shovel’s magnetism causes it to pix up a higher proportion of red beads than a non-magnetized shovel. We might see bias if the red beads were heavier than the white beads and therefore lie at the bottom of the urn, decreasing their chance of being sampled in a shovel. It could be something as simple as the urn not being mixed after each shovel draw!</p>
<p><strong>Censoring</strong> is a different error in the sampling mechanism. To explain censoring, imagine we are measuring people’s heights with a tape measure. However, our tape measure only goes up to 6 foot 5 inches. What happens if we must measure someone above that height? Unfortunately, their actual measurement will be excluded from our data. The sampling mechanism is flawed and, consequently, our estimand will be off.</p>
<p>Here’s a harder question: given the ease of errors in sampling, how can we say whether our estimates are valid?</p>
<p>The easiest way to do this would be to re-run the experiment and compare the new results to our predictions. The validity of our predications, derived from the predictive Preceptor Table, is how we confirm that our conclusions are correct. This brings us to our final Preceptor Table.</p>
</div>
<div id="predictive-preceptor-table" class="section level3">
<h3>
<span class="header-section-number">6.6.6</span> Predictive Preceptor Table</h3>
<!-- MF: Do I create a predictive Preceptor Table here? Or just discuss it? -->
<!-- CB: Something like this might be helpful for predictive? Very similar to Tahmid's chapter.

urn %>%
  slice(1:8, 2399, 2400) %>%
  mutate(ID = as.character(ID),
         color = as.character(color)) %>%
  add_row(ID = "...", color = "...", .after  = 8) %>%
  add_row(ID = "Random bead color?", color = "?") %>%
  gt() %>%
  cols_label(ID = md("**bead ID**"),
             color = "Year") %>%
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = vars(ID))) %>%
  tab_style(cell_text(weight = "bold"),
            location = cells_body(columns = vars(ID))) %>%
  cols_align(align = "center", columns = TRUE)  -->
</div>
</div>
<div id="key-themes" class="section level2">
<h2>
<span class="header-section-number">6.7</span> Key Themes</h2>
<p>Throughout this book, we will return to a few central themes and apply them to each chapter. These concepts are important for both your overall statistical knowledge and your specific understanding of sampling.</p>
<p>To understand these concepts as they apply to sampling, let’s imagine that we are betting our roommate on the <em>proportion of red beads in the next shovel (with a shovel size of 100) taken from the urn</em>. Our roommate proposes that, if the proportion falls between 35 and 40%, we win! If we win, our roommate gives us 100 dollars; if we guess lose, we give our roommate 100 dollars. How would we go about this using what we have learned from this sampling chapter? Let’s revisit our key concepts first.</p>
<div id="validity" class="section level3">
<h3>
<span class="header-section-number">6.7.1</span> Validity</h3>
<p>Validity encompasses two issues: the map from concept to data and the relevance of the estimand. In other words, our conceptual sampling exercises must help to answer our central question: what is our best guess as to the next proportion of red beads drawn from the urn?</p>
<p>The data we are analyzing <em>must</em> map to the central question we are trying to answer. Though you might think this is obvious, it’s often overlooked! The outcome measure should accurately reflect our phenomeon of interest, our <strong>estimand</strong>. Here, the <strong>estimand</strong> is the proportion of red beads in the next shovel taken from the urn. As we have learned, the most <strong>precise</strong> and <strong>accurate</strong> estimate occurs when our sampling is <em>random</em> and our sample size is <em>large</em>.</p>
<p>We are taking a bet on the proportion of red beads in the next shovel (with a shovel size of 100) taken from the urn. To ensure a precise and accurate estimate, we must have a large and random sample. Of the tests we have conducted, the option with the least amount of standard deviation is the virtual sampling result from the 100 slot shovel, conducted 1000 times.</p>
<p>However, to sample properly, we must perfect our <strong>model structure</strong>, our next central theme.</p>
</div>
<div id="model-structure" class="section level3">
<h3>
<span class="header-section-number">6.7.2</span> Model Structure</h3>
<p>Model structure is the concept that our model must closely match the analogous real-life circumstance if our results are to be valid. The two most important aspects of model structure include the predictive/causal model difference and realism.</p>
<p>First, is our model <strong>predictive</strong> or <strong>causal</strong>? Because there is no causation in our sampling scenario (we are not measuring a causal effect), and because we are <strong>predicting</strong> the next proportion of red beads, we are using a predictive model.</p>
<p>Now that we know our model type, we must focus on another aspect of model structure: <strong>realism</strong>. Realism accounts for whether the model matches the world. Does our model, using virtual sampling to calculate the proportion of red beads using a large shovel 1000 times, match the given scenario? Yes! Our model is nearly identical to the proposed question: the proportion of red beads in the next shovel.</p>
<p>However, we must also consider <strong>prediction uncertainty</strong>: our ability, or lack thereof, to predict the future. Prediction uncertainty is rooted in two primary sources: <strong>parameter uncertainty</strong> and <strong>unmodeled variation</strong>.</p>
</div>
<div id="parameter-uncertainty" class="section level3">
<h3>
<span class="header-section-number">6.7.3</span> Parameter uncertainty</h3>
<p>We must also consider <strong>parameter uncertainty</strong> when making our prediction. Parameter uncertainty is the idea that, even if our model has correct form, we must estimate our parameters. We will never know our parameters perfectly. If we assume that we can estimate the parameters perfectly, we will be over-confident. To understand parameter uncertainty better, let’s look at the histogram for the shovel with 100 slots with 1000 repetitions.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-584-1.png" width="672"></p>
<p>The most frequent proportion of red beads falls between 35 and 40%. Is this the best parameter for our guess, then?</p>
<p>Though our intuition might say “yes!”, that is actually not a safe bet (unless you want to lose your money, of course). Recall the discussion of posterior predictions from Chapter 5. The best possible forecast is not just the most likely model, even with confidence in our model’s validity. In the real world, the best possible forecast will incorporate that uncertainty. We will not pretend that we know, for certain, that <span class="math inline">\(p = 35-40%\)</span>. Forecasts which incorporate our uncertainty about parameter values are called <strong>posterior predictions</strong>.</p>
<p>Though our model is valid and we see that the most common proportion does exist in the parameter between .35 and .40, the proportion of red beads falls in between these margins about 40% of the time. That’s great! But if we think about this a bit more, this means that, in about 60% of the simulations, the proportion of red beads <em>does not</em> fall in the proposed margins. In other words, though the most likely value of the estimand is between 35% and 40%, it is <em>more</em> likely that the estimand falls above or below these margins. The odds are not in our favor.</p>
<p>To optimize our chances, we want to be as confident as possible in our parameters, while still making a fair bet.</p>
</div>
<div id="unmodeled-variation" class="section level3">
<h3>
<span class="header-section-number">6.7.4</span> Unmodeled Variation</h3>
<p>To further complicate things, we must account for <strong>unmodeled variation</strong>. This idea essentially states that some randomness is intrinsic. In other words, though the proportion of red beads never falls below 10% or above 70% in any of our simulations (see below), it is still technically possible that we get one of those extreme parameters when we draw the next shovel.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-585-1.png" width="672"></p>
</div>
<div id="putting-it-all-together" class="section level3">
<h3>
<span class="header-section-number">6.7.5</span> Putting It All Together</h3>
<p>Let’s put all of these topics together in terms of our bet.</p>
<ul>
<li>Our <strong>estimand</strong>, the thing we want to know, is the proportion of red beads in the next shovel draw.</li>
<li>Our <strong>model structure</strong>, using the large shovel and performing the sample 1000 times, ensures an accurate and precise model on which we may make our prediction. It closely resembles the real-life situation, estimating the proportion of red beads in an urn, and we may therefore assume the model is valid.</li>
<li>
<strong>Prediction uncertainty</strong> highlights our inability to forecast the future. <strong>Parameter uncertainty</strong> states that, even when our model structure is valid, we must estimate the parameters. We can never perfectly estimate the proportion of red beads. In this situation, we must decide which parameters are generous enough to risk our money. <strong>Unmodeled variation</strong>, the idea that, no matter how accurate our model is, some randomness is intrinsic. It is possible, though unlikely, that the next shovel would have a proportion below 20%, despite the fact that our model does not show this possibility!</li>
</ul>
<p>With everything we know now, is this a good bet? No!</p>
<p>Like the smart data scientists we are, we know that the parameters are too narrow.</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2>
<span class="header-section-number">6.8</span> Conclusion</h2>
<p>In this chapter, we performed both tactile and virtual sampling exercises to infer about an unknown proportion. We also presented a case study of sampling in real life with polls. In each case, we used the sample proportion <span class="math inline">\(\hat{p}\)</span> to estimate the population proportion <span class="math inline">\(p\)</span>. However, we are not just limited to scenarios related to proportions. In other words, we can use sampling to estimate other population parameters using other point estimates as well.</p>
<p>Recall in our Obama poll case study in Section <a href="one-parameter.html#sampling-case-study">6.5</a> that based on this particular sample, the best guess by Kennedy School’s Institute of Politics at Harvard University of the U.S. President Obama’s approval rating among all young Americans was 41%. However, this isn’t the end of the story. If you read the article further, it states:</p>
<blockquote>
<p>The online survey of 2,089 adults was conducted from Oct. 30 to Nov. 11, just weeks after the federal government shutdown ended and the problems surrounding the implementation of the Affordable Care Act began to take center stage. The poll’s margin of error was plus or minus 2.1 percentage points.</p>
</blockquote>
<p>Note the term <em>margin of error</em>, which here is “plus or minus 2.1 percentage points.” Most polls won’t produce an estimate that’s perfectly right; there will always be a certain amount of error caused by <em>sampling variation</em>. The margin of error of plus or minus 2.1 percentage points is saying that a typical range of errors for polls of this type is about <span class="math inline">\(\pm\)</span> 2.1%, in words from about 2.1% too small to about 2.1% too big. We can restate this as the interval of <span class="math inline">\([41\% - 2.1\%, 41\% + 2.1\%] = [37.9\%, 43.1\%]\)</span> (this notation indicates the interval contains all values between 37.9% and 43.1%, including the end points of 37.9% and 43.1%). We’ll see in the next chapter that such intervals are known as <em>confidence intervals</em>.</p>

<!-- TO-DO: -->
<!-- 1. Talk with Vivian! -->
<!-- Remaining Outline of the Chapter -->
<!-- Prove that the bootstrap works, that our 95% confidence intervals provide correct coverage. We make a game and I give you a sample of like 40. Here's the 40, and you give me a 95% CI using the bootstrap tools we learned. Then I give you another 40. And another. If we do this 1,00 times, and we use the same procedure for calculating a confidence interval each time, then 950 should include the truth. That's how we know bootstraps is correct and I could only demonstrate this to you if we know what the truth is.  

Plan: create function called create_ci(), which takes a tibble with a single variable called height and returns the 95% confidence interval --- i.e., a numeric vector of length 2 --- for the 75th percentile.  Note that you get to hard code everything.

Then, create a tibble, first column is ID. Second column is height_sample, which is created by running sample(ch7$height, size = 40, replace = FALSE). Third column is ci, which is result mutate(ci = map(height_sample, ~ create_ci(.)). Fourth column is within_ci, which is TRUE if ci includes the TRUE value and FALSE otherwise. (If you want to have two columns, one for each limit, that is fine.)
-->
<!-- 5. height in the US, using all 2,475 men for 2009. Let's skip the bootstrap here. (We have seen it twice already.) Instead, we just go straight to lm(), tidy() to calculate the mean and its confidence interval. Note that, unlike with 2, we can never know the truth. Then, use this as an example to discuss parameter uncertainty. Incorporate discussion of all four virtues throughout.  -->
<!-- 6. Prediction. What can we use this model for? We think we know p(mean height for 2009), call it p(height). So what? What can we do with this and what do we need to be careful about? This is where we can discuss all our other topics from themes.Rmd. Build a data generating mechanism. With it, we can answer any question we like!  -->
<!-- Turn Standard error method section of coin bootstrap into a four sentence margin note. Show formula. Note that the 95% confidence interval from the bootstrap will generally be the same thing as +/- two times the standard error. But not always! -->
<!-- c) Discuss how this exercise is still useful even if we begin with all our data. That is, don't sample. Just use all 5,000 people. Then, do the bootstrap to get a confidence interval. Note that the interval will be --- how much? --- smaller than the ones we got above, because we are using 116 times as much data. But it is also weird. I know exactly what the mean is! I have the entire Rubin Table! I don't need a confidence interval for the mean.  -->
<!-- d) That is both true, and false. If all you truly care about is the mean these 5,000 people then, it is true, you are done. But that is generally not the case! The true Rubin Table is often bigger than you might initially think. You might also be interested in data from another time period (which has occurred but which may not be available to you) or from 2021, which has not even happened yet. Your Rubin Table includes rows for all those people. They are just missing. You also care about the millions of people who are not in the 5,000. You really want the mean for the country. (Or the world?) So, you use the model that you have to estimate stuff for the data that you don't. What is your best guess for the mean in 2011 (which you can check) or in 2021 (which you can't)? How confident are you are that estimate? What is your 50/50 prediction interval? -->
<!-- e) Relatedly, what if I told you that your 2009 data I gave you did not include one person (or ten people or 100), which was (were) dropped at random from the data by mistake. What is your guess as to the height of that single person, or the height of the average of the 10 people or the tallest of the 10 classes? What is your confidence interval for that? Want to bet? These are all different estimands. -->
<!-- 4) Recall how the probability chapter goes farther than this. It gets all the way to posterior predictions. What will be the mint year of the next penny we get from the bank? What will be the average of the next five pennies we pull? What is a reasonable uncertainty for these forecasts?  Do a posterior predictive checks. Note that we should use all the same "tools" as in that probability chapter. That is, our bootstraps has built a posterior distribution, just like the posterior distribution we built with the coin tosses. Do we then sample from this posterior to answer other questions? Or is that too hard. -->
<!-- 4a) Key issue: How to we transition from this crazy bootstrap approach to using R functions to make the same calculations. Bootstraps take too long, and they are a bother. We need to show how they give the same answer as the built in R functions and then transition away from the bootstrap. Indeed, there is an argument that this chapter (or last chapter?) is the last Bayes Scatterplot we show. That was all about intuition. Once we have that, we can just go to doing things the right way. -->
<!-- 4b) Key issue two: Do we go straight from the bootstrap to rstanarm functions? That would be pretty aggressive. But also pretty cool! Or maybe this chapter we show the bootstrap, the base R (t.test()? lm()?) and rstanarm together. Indeed, the goal for this chapter is to connect them all. Then, next chapter (two parameters) leaves out the bootstrap. And then N parameters drop base functions. But does that really work? Maybe we use base and rstanarm for the rest of the book? Maybe rstanarm only appears in advanced sections. We never use them in this class. Save them for Gov 52? I don't know! -->
<!-- 5) Need to build a Rubin Table. (Read chapter 3 for background and discussion.) We want to have the year for every penny in the world. Sadly, we don't have that! But we do have 50 pennies. Show an RT, which shows both pennies we know the year of and pennies we don't know the year of. If we knew all the pennies, we could just caculate our estimand directly. We would know exactly the mean, the median, the 3rd oldest and so on. No uncertainty. But, we don't have all the years. The question marks mock us! So, we need to infer what is in the missing rows. (And then we . . . not sure I have thought this through.) Also, we can discuss lots of possible biases in the sampling mechanism. Indeed, the sampling mechanism is the key thing to discuss in this section. -->
<!-- 6) We should start the chapter with a decision we face, even a toy one which is not much more than the prediction game. Maybe our friend Joe bets us that a random penny that we get in change from Starbuck's will be older than 1990. Should we take the bet? At what odds? Then, we come back to this at the end and, with the information we have learned, take the bet or not. -->
<!-- 7) Always nice to highlight how flexible the simulation approach is. You might be able to solve the basic problem analytically. But, as soon as some complexity comes in, simulation is your only hope. For example, Joe bets that the second oldest of the four pennies he got in change is older than 1990. Take that bet? Only (?) approach is simulation. Or maybe we should start with a bet which we know can only be solved with simulation. -->
<!-- 2) Get rid of ## Warning: Removed 2 rows containing missing values (geom_bar). Just use drop_na() and explain what you are doing. -->
<!-- 3) Make our own speadsheet data? Use names from contributors to the book. -->
<!-- Other Notes -->
<!-- This is probably too hard for the chapter itself but might make for a good problem set: Estimating who is going to win an election as the votes come in. After one vote, don't know anything. After 5 votes, maybe a little. After 10 votes, more. And so on. Show how the best estimate evolves over time, as information comes in. Do this as a contest. What procedure is best? Show that some shrinkage is a very good idea. Each stage is, potentially, a new contest. See which approach wins the most contests. In the end, of course, they converge. Can't just be "Repub ahead" as H_1. Need to be "Repub = 0.6" Without this hack, can't calculate the likelihood easily. Right? See Rossman approach for tennis matches.  -->
<!-- Show updating as each vote comes in. Then show that you get the same answer if you just include all the votes at once. -->
<!-- First, look at competing models. Who is ahead, D or R? -->
<!-- Second, add another model. D or R or tied? -->
<!-- Third, what is D percentage of support? -->
<!-- Assuming this is correct, we get to bring in prediction and betting. Then, we have the motivating question: What is a good estimate for the percentage of Democrats in this bucket? How do we combine information from the overall population and from our sample to come up with a good estimate, and confidence interval, for the percentage Democratic in that bucket? Perhaps this multi-level model is one of the last things we do. Even Mr P??  -->
<!-- Workshop Statistics:  Discovery with Data, A Bayesian Approach by James H. Albert and Allan J. Rossman --- Topic 16 has some interesting stuff about how we learn a proportion.  -->
</div>
</div></body></html>

<p style="text-align: center;">
<a href="probability.html"><button class="btn btn-default">Previous</button></a>
<a href="two-parameters.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-12
</p>
</div>
</div>



</body>
</html>
