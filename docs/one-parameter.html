<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 7 One Parameter | Preceptor’s Primer for Bayesian Data Science" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />

<meta name="author" content="David Kane" />

<meta name="date" content="2020-07-16" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 7 One Parameter | Preceptor’s Primer for Bayesian Data Science">

<title>Chapter 7 One Parameter | Preceptor’s Primer for Bayesian Data Science</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Preceptor's Primer for Bayesian Data Science<p><p class="author">David Kane</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Cover</a>
<a href="preamble.html">Preamble</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="tidyverse.html"><span class="toc-section-number">2</span> Tidyverse</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="sampling.html"><span class="toc-section-number">6</span> Sampling</a>
<a id="active-page" href="one-parameter.html"><span class="toc-section-number">7</span> One Parameter</a><ul class="toc-sections">
<li class="toc"><a href="#resampling-tactile"> Pennies activity</a></li>
<li class="toc"><a href="#confidence-intervals-using-lm"> Confidence Intervals using lm</a></li>
<li class="toc"><a href="#ci-build-up"> Measuring uncertainty with confidence intervals</a></li>
<li class="toc"><a href="#income-from-trains-using-bootstrap"> Income from trains using Bootstrap</a></li>
<li class="toc"><a href="#parameter-uncertainty-and-unmodeled-variation"> Parameter Uncertainty and Unmodeled Variation</a></li>
<li class="toc"><a href="#case-study-looking-at-2018-qscore-data"> Case study: Looking at 2018 Qscore data</a></li>
<li class="toc"><a href="#ci-conclusion"> Conclusion</a></li>
</ul>
<a href="two-parameters.html"><span class="toc-section-number">8</span> Two Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="pitfalls.html"><span class="toc-section-number">10</span> Pitfalls</a>
<a href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="productivity.html">Productivity</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="references-1.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="one-parameter" class="section level1">
<h1>
<span class="header-section-number">Chapter 7</span> One Parameter</h1>
<!-- Explain PPBDS.data and how to install it at start of chapter. Just a sentence or two, with `remotes::install_github("davidkane9/PPBDS.data")` in the sentence, along with note that, obviously, one needs to `library(remotes)` first. This would make for a good margin note. -->
<!-- 

$$ y_i = \beta + \epsilon_i $$
$$ \hat{y_i} = \beta  $$



Read Chapter 5 and zoom with Vivian about the connection between the two chapters

Figure out the 5-8 subparts and the sub-subparts within each. This will evolve over time, of course.

0. Question about height in America in 2009. 

1. Pennies. Pretty much as it is now, with perhaps the addition of showing how lm(year ~ 1) gives the same answer.

2. Exploratory Data Analysis of nhanes

2. height from the 5,000 nhanes observations for 2009. This can go much faster. Two key differences from pennies. First, we know the truth, so we can examine whether or not the bootstrap works. (That is, we pull a sample of 40 and see if the bootstrap confidence interval from that 40 includes the true mean of the 5,000.) Second, we simultaneously calculate two things: mean height and 75th percentile height. The first can also be done with lm(). But the second can not! Which is why we sometimes need the bootstrap.

Possibly focus on just 2500 men and their average height. their mean height is this, but we make a game and I give you a sample of like 40. Her's the 40, and give me a 95% CI using the bootstrap tools we learned. If we do the same procedure, then 950 should include the truth. That's how we know bootstraps is correct and I could only demonstrate this to you if we know what the truth is. 

Cut this from chapter 8. Something like it belongs here

=======
Consider a bootstrap sample of the trains dataset with 1,000 replicates, and the data contained in the first of these 1000 replicates: 



```r
# boots <- bootstraps(trains, 1000)
```

Because bootstrapping can take a lot of time, we often create the bootstrap sample as a new object, and then use this new object as the starting point for later analysis. You would not want to redo the bootstrap every time you made a minor change in a plot later on. The result of running `bootstraps()` is usually a tibble of class "bootstraps," with two colums: `splits`  (a list) and `id` (a character).  


```r
# boots
```


Using the `analysis()` function from the **rsample** package is useful in working with the data stored within each replicate in the `splits` column. Let's look at the 9th replicate.


```r
# x$boots[[9]] %>% analysis()
```

Now, let's say we're interested in calculating a single parameter across each of these bootstrapped samples: the mean income for each of these replicates. We use `mutate()` to add a new column to the tibble. We use a map function to accomplish this, as explained in Chapter \@ref(functions).


```r
# x <- boots %>% 
#  mutate(mean_income = map_dbl(splits, ~ analysis(.) %>% 
#                              pull(income) %>% 
#                              mean()))

#x
```



Now we have 1000 replicates and 1000 values of mean_income to work with. If we want to construct a distribution for the bootstrapped values of `mean_income` with a 95 percent confidence interval, we can calculate the bounds of this interval.
=======
End of cut section.

3. height in the US, using all 5,000 for 2009. Let's skip the bootstrap here. (We have seen it twice already.) Instead, we just go straight to lm(), tidy() to calculate the mean and its confidence interval. Note that, unlike with 2, we can never know the truth. Then, use this as an example to discuss parameter uncertainty. 

want to estimate the height for the all US women. and i give you 2500. We don't need to do bootstraps, we could just run lm and tidy for the CI. We don't really have the true value in this case, but we can talk about the parameter uncertainty in this case. Want a plot that shows the thousand diff runs in the y axis and x axis is the different cI. check chapter 8 for the plot. 

4. Prediction. What can we use this model for? We think we know p(mean height for 2009), call it p(height). So what? What can we do with this and what do we need to be careful about? This is where we can discuss all our other topics from themes.Rmd. Some key topics:

possibly make them sub sub section based on themes

-->
<!-- Turn Standard error method section of coin bootstrap into a four sentence margin note. -->
<!-- Fix summarize warnings. I think you just need to provide a value for the `.groups` argument, perhaps just `.groups = "drop_last"`, which is the default. Of course, you also need to explain what this does. But why do we need to specify the default? -->
<!-- Switch from qscores to nhanes as the main data example. Why? The demonstration works much better with a big dataset than it does with a small one, for reasons that we ought to discuss in the chapter. Which variable should we use? Let's go with height? Use just the data from 2009, which is 5,000 observations.  -->
<!-- a) We can see how good that confidence interval is because we have all the data. We know the height for all 5,000 people in the sample, so we can see what the true mean is. Did our 95% confidence interval include the mean? It should! -->
<!-- b) We can replicate this experiment 1,000 times. Sample, without replacement, 43 people from nhanes. (Point out that, although we used 50 with the penny example, bootstrapping works whatever the size of our sample. So, we use 43 here.) Use the bootstrap to calculate a confidence interval for the mean. This should include the mean about 950 of the 1,000. But it will fail about 500 times! And that is cool to show. -->
<!-- c) Discuss how this exercise is still useful even if we begin with all our data. That is, don't sample. Just use all 5,000 people. Then, do the bootstrap to get a confidence interval. Note that the interval will be --- how much? --- smaller than the ones we got above, because we are using 116 times as much data. But it is also weird. I know exactly what the mean is! I have the entire Rubin Table! I don't need a confidence interval for the mean.  -->
<!-- d) That is both true, and false. If all you truly care about is the mean these 5,000 people then, it is true, you are done. But that is generally not the case! The true Rubin Table is often bigger than you might initially think. You might also be interested in data from another time period (which has occurred but which may not be available to you) or from 2021, which has not even happened yet. Your Rubin Table includes rows for all those people. They are just missing. You also care about the millions of people who are not in the 5,000. You really want the mean for the country. (Or the world?) So, you use the model that you have to estimate stuff for the data that you don't. What is your best guess for the mean in 2011 (which you can check) or in 2021 (which you can't)? How confident are you are that estimate? What is your 50/50 prediction interval? -->
<!-- e) Relatedly, what if I told you that your 2009 data I gave you did not include one person (or ten people or 100), which was (were) dropped at random from the data by mistake. What is your guess as to the height of that single person, or the height of the average of the 10 people or the tallest of the 10 classes? What is your confidence interval for that? Want to bet? These are all different estimands. -->
<!-- All of this allows us to hit all the themes from style.Rmd even though we are only estimating one parameter. I think that this is enough for one chapter, especially if we keep the pennies around. No need to get into other data sets. -->
<!-- 2) Need to get rid of `rep_sample_n()` and replace with `rsample:boostraps()`. Example usage [here](https://juliasilge.com/blog/beer-production/). Do this first, just to get warmed up. Make sure everything still works! Consult this [useful tutorial](https://www.danielphadley.com/bootstrap_tutto/) for the bootstraps function. We can keep everything else with the penny example the same, for now. -->
<!-- 4) After completing the current penny example, show how we can estimate other estimands --- the median, 3rd biggest, et cetera --- in exactly the same way. All the same procedures apply in these cases. Obviously, we can go much faster and don't have to do them all. Key is to see that there are many things (and their uncertainty) which we can estimate. The mean is just one of them. We can still just use our standard Bayesian interpretation for all these estimands and uncertainty intervals. -->
<!-- 3) Refer back to the probability chapter. Note that it ends with the estimating of a single parameter, the p associated with a coin. You want to remind readers of what they have already learned and also move a little bit further. Read the set of notes at the start of chapter 6.  -->
<!-- 4) Recall how the probability chapter goes farther than this. It gets all the way to posterior predictions. What will be the mint year of the next penny we get from the bank? What will be the average of the next five pennies we pull? What is a reasonable uncertainty for these forecasts?  Do a posterior predictive checks. Note that we should use all the same "tools" as in that probability chapter. That is, our bootstraps has built a posterior distribution, just like the posterior distribution we built with the coin tosses. We then sample from this posterior to answer other questions. -->
<!-- 4a) Key issue: How to we transition from this crazy bootstrap approach to using R functions to make the same calculations. Bootstraps take too long, and they are a bother. We need to show how they give the same answer as the built in R functions and then transition away from the bootstrap. Indeed, there is an argument that this chapter (or last chapter?) is the last Bayes Scatterplot we show. That was all about intuition. Once we have that, we can just go to doing things the right way. -->
<!-- 4b) Key issue two: Do we go straight from the bootstrap to rstanarm functions? That would be pretty aggressive. But also pretty cool! Or maybe this chapter we show the bootstrap, the base R (t.test()? lm()?) and rstanarm together. Indeed, the goal for this chapter is to connect them all. Then, next chapter (two parameters) leaves out the bootstrap. And then N parameters drop base functions. But does that really work? Maybe we use base and rstanarm for the rest of the book? Maybe rstanarm only appears in advanced sections. We never use them in this class. Save them for Gov 52? I don't know! -->
<!-- 5) Need to build a Rubin Table. (Read chapter 3 for background and discussion.) We want to have the year for every penny in the world. Sadly, we don't have that! But we do have 50 pennies. Show an RT, which shows both pennies we know the year of and pennies we don't know the year of. If we knew all the pennies, we could just caculate our estimand directly. We would know exactly the mean, the median, the 3rd oldest and so on. No uncertainty. But, we don't have all the years. The question marks mock us! So, we need to infer what is in the missing rows. (And then we . . . not sure I have thought this through.) Also, we can discuss lots of possible biases in the sampling mechanism. Indeed, the sampling mechanism is the key thing to discuss in this section. -->
<!-- 6) We should start the chapter with a decision we face, even a toy one which is not much more than the prediction game. Maybe our friend Joe bets us that a random penny that we get in change from Starbuck's will be older than 1990. Should we take the bet? At what odds? Then, we come back to this at the end and, with the information we have learned, take the bet or not. -->
<!-- 7) Always nice to highlight how flexible the simulation approach is. You might be able to solve the basic problem analytically. But, as soon as some complexity comes in, simulation is your only hope. For example, Joe bets that the second oldest of the four pennies he got in change is older than 1990. Take that bet? Only (?) approach is simulation. Or maybe we should start with a bet which we know can only be solved with simulation. -->
<!-- 1) Get rid of ## Warning: `...` is not empty by using the `.group` argument correctly. -->
<!-- 2) Get rid of ## Warning: Removed 2 rows containing missing values (geom_bar). Just use drop_na() and explain what you are doing. -->
<!-- 3) Make our own speadsheet data? Use names from contributors to the book. -->
<!-- Other Notes -->
<!-- This is probably too hard for the chapter itself but might make for a good problem set: Estimating who is going to win an election as the votes come in. After one vote, don't know anything. After 5 votes, maybe a little. After 10 votes, more. And so on. Show how the best estimate evolves over time, as information comes in. Do this as a contest. What procedure is best? Show that some shrinkage is a very good idea. Each stage is, potentially, a new contest. See which approach wins the most contests. In the end, of course, they converge. Can't just be "Repub ahead" as H_1. Need to be "Repub = 0.6" Without this hack, can't calculate the likelihood easily. Right? See Rossman approach for tennis matches.  -->
<!-- TA: Yea, I like this!

<!-- Show updating as each vote comes in. Then show that you get the same answer if you just include all the votes at once. -->
<!-- First, look at competing models. Who is ahead, D or R? -->
<!-- Second, add another model. D or R or tied? -->
<!-- Third, what is D percentage of support? -->
<!-- Assuming this is correct, we get to bring in prediction and betting. Then, we have the motivating question: What is a good estimate for the percentage of Democrats in this bucket? How do we combine information from the overall population and from our sample to come up with a good estimate, and confidence interval, for the percentage Democratic in that bucket? Perhaps this multi-level model is one of the last things we do. Even Mr P??  -->
<!-- Find a place for this quote somewhere. -->
<!-- > In this sense, the bootstrap distribution represents an (approximate) -->
<!-- nonparametric, noninformative posterior distribution for our parameter. -->
<!-- But this bootstrap distribution is obtained painlessly --- without having to -->
<!-- formally specify a prior and without having to sample from the posterior -->
<!-- distribution. Hence we might think of the bootstrap distribution as a “poor -->
<!-- man’s” Bayes posterior. By perturbing the data, the bootstrap approximates -->
<!-- the Bayesian effect of perturbing the parameters, and is typically -->
<!-- much simpler to carry out. --- Elements of Statistical Learning, 2nd edition, by Hastie et al, page 271. -->
<!-- Workshop Statistics:  Discovery with Data, A Bayesian Approach by James H. Albert and Allan J. Rossman --- Topic 16 has some interesting stuff about how we learn a proportion.  -->
<p>Before digging into this chapter, please download PPBDS data, which we will be using for this chapter. To get the PPBDS data, please run <code>library(remotes)</code> and then <code>remotes::install_github("davidkane9/PPBDS.data")</code>. In Chapter <a href="sampling.html#sampling">6</a>, we studied sampling. We started with a “tactile” exercise where we wanted to know the proportion of balls in the urn in Figure <a href="#fig:sampling-exercise-1"><strong>??</strong></a> that are red. While we could have performed an exhaustive count, this would have been a tedious process. So instead, we used a shovel to extract a sample of 50 balls and used the resulting proportion that were red as an <em>estimate</em>. Furthermore, we made sure to mix the urn’s contents before every use of the shovel. Because of the randomness created by the mixing, different uses of the shovel yielded different proportions red and hence different estimates of the proportion of the urn’s balls that are red.</p>
<p>Remember: There is a <em>truth</em> here. There is an urn. It has red and white balls in it. An exact, but unknown, number of the balls are red. An exact, but unknown, number of the balls are white. An exact, but unknown, percentage of the balls are red – defined as the number red divided by the sum of the number red and the number white. Our goal was to estimate that unknown percentage. We wanted to make statements about the world, even if we can never be certain that those statements are <em>true</em>. We will never have the time or inclination to actually count all the balls. We use the term <em>parameter</em> for things that exist but which are unknown. We use statistics to estimate the true values of parameters.</p>
<!-- TA: This might just be me, but I think it would be helpful to reinforce the last two sentences as the topic sentences for the Remember paragraph. -->
<p>We then mimicked this <em>physical</em> sampling exercise with an equivalent <em>virtual</em> sampling exercise using the computer. In Subsection <a href="sampling.html#different-shovels">6.2.4</a>, we repeated this sampling procedure 1,000 times, using three different virtual shovels with 25, 50, and 100 slots. We visualized these three sets of 1,000 estimates in Figure <a href="#fig:comparing-sampling-distributions-3"><strong>??</strong></a> and saw that as the sample size increased, the variation in the estimates decreased. We then expanded this for all sample sizes from 1 to 100.</p>
<p>In doing so, we constructed <em>sampling distributions</em>. The motivation for taking a 1,000 repeated samples and visualizing the resulting estimates was to study how these estimates varied from one sample to another; in other words, we wanted to study the effect of <em>sampling variation</em>. We quantified the variation of these estimates using their standard deviation, which has a special name: the <em>standard error</em>. In particular, we saw that as the sample size increased from 1 to 100, the standard error decreased and thus the sampling distributions narrowed. Larger sample sizes led to more <em>precise</em> estimates that varied less around the center.</p>
<!-- TA: I think we can distinguish further the difference between standard deviation and standard error in the above paragraph. Readers can confuse the two. -->
<p>We then tied these sampling exercises to terminology and mathematical notation related to sampling in Subsection <a href="sampling.html#terminology-and-notation">6.3.1</a>. Our <em>study population</em> was the large urn with <span class="math inline">\(N\)</span> = 2,400 balls, while the <em>population parameter</em>, the unknown quantity of interest, was the population proportion <span class="math inline">\(p\)</span> of the urn’s balls that were red. Since performing a <em>census</em> would be expensive in terms of time and energy, we instead extracted a <em>sample</em> of size <span class="math inline">\(n\)</span> = 50. The <em>point estimate</em>, also known as a <em>sample statistic</em>, used to estimate <span class="math inline">\(p\)</span> was the sample proportion <span class="math inline">\(\widehat{p}\)</span> of these 50 sampled balls that were red. Furthermore, since the sample was obtained at <em>random</em>, it can be considered as <em>unbiased</em> and as <em>representative</em> of the population. Thus any results based on the sample could be <em>generalized</em> to the population. Therefore, the proportion of the shovel’s balls that were red was a “good guess” of the proportion of the urn’s balls that are red. In other words, we used the sample to draw <em>inferences</em> about the population.</p>
<p>However, as described in Section <a href="sampling.html#sampling-simulation">6.2</a>, both the physical and virtual sampling exercises are not what one would do in real life. This was merely an activity used to study the effects of sampling variation. In a real life situation, we would not take 1,000 samples of size <span class="math inline">\(n\)</span>, but rather take a <em>single</em> representative sample that’s as large as possible. Additionally, we knew that the true proportion of the urn’s balls that were red was 37.5%. In a real-life situation, we will not know what this value is. Because if we did, then why would we take a sample to estimate it?</p>
<p>An example of a realistic sampling situation would be a poll, like the <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Obama poll</a> you saw in Section <a href="sampling.html#sampling-case-study">6.4</a>. Pollsters did not know the true proportion of <em>all</em> young Americans who supported President Obama in 2013, and thus they took a single sample of size <span class="math inline">\(n\)</span> = 2,089 young Americans to estimate this value.</p>
<p>So how does one quantify the effects of sampling variation when you only have a <em>single sample</em> to work with? You cannot directly study the effects of sampling variation when you only have one sample. One common method to study this is <em>bootstrapping resampling</em>.</p>
<p>What if we would like, not only a single estimate of the unknown population parameter, but also a <em>range of highly plausible</em> values? Going back to the Obama poll article, it stated that the pollsters’ estimate of the proportion of all young Americans who supported President Obama was 41%. But in addition it stated that the poll’s “margin of error was plus or minus 2.1 percentage points.” This “plausible range” was [41% - 2.1%, 41% + 2.1%] = [38.9%, 43.1%]. This range of plausible values is what’s known as a <em>confidence interval</em>, which will be the focus of the later sections of this chapter.</p>
<p>For concreteness, let’s consider two simple tasks. First, predict the height of a random person you have not met. Second, predict the height of the second tallest person in a group of ten random people. What are you predictions and how certain are you of them?</p>
<!-- Problem of predicting someone's height or of predicting the tallest person in a group of 10. And how uncertain are you about those predictions? -->
<!--
Create graphic illustrating two-step process of 1) construct bootstrap distribution
and then 2) based on bootstrap dist'n create CI?
-->
<!-- TA: For the comment above, are you referring to Obama's polling data?-->
<div id="resampling-tactile" class="section level2">
<h2>
<span class="header-section-number">7.1</span> Pennies activity</h2>
<p>As we did in Chapter <a href="sampling.html#sampling">6</a>, we’ll begin with a hands-on tactile activity. We almost always need the <strong>tidyverse</strong> package.</p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="one-parameter.html#cb706-1"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb706-2"><a href="one-parameter.html#cb706-2"></a><span class="kw">library</span>(rsample)</span>
<span id="cb706-3"><a href="one-parameter.html#cb706-3"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<p><strong>PPBDS.data</strong> includes the data sets for this book. <strong>rsample</strong> includes functions for bootstraping, the main statistical tool which will we use here.</p>
<div id="what-is-the-average-year-on-us-pennies-in-2019" class="section level3">
<h3>
<span class="header-section-number">7.1.1</span> What is the average year on US pennies in 2019?</h3>
<p>Try to imagine all the pennies being used in the United States in 2019. That’s a lot of pennies! Now say we’re interested in the average year of minting of <em>all</em> these pennies. One way to compute this value would be to gather up all pennies being used in the US, record the year, and compute the average. However, this would be near impossible! So instead, let’s collect a <em>sample</em> of 50 pennies from a local bank in downtown Northampton, Massachusetts, USA as seen in Figure <a href="#fig:resampling-exercise-a"><strong>??</strong></a>.</p>
<div class="figure">
<span id="fig:unnamed-chunk-417-1"></span>
<p class="caption marginnote shownote">
FIGURE 7.1: Collecting a sample of 50 US pennies from a local bank.
</p>
<img src="07-one-parameter/images/bank.jpg" alt="Collecting a sample of 50 US pennies from a local bank.">
</div>
<div class="figure">
<span id="fig:unnamed-chunk-417-2"></span>
<p class="caption marginnote shownote">
FIGURE 7.2: Collecting a sample of 50 US pennies from a local bank.
</p>
<img src="07-one-parameter/images/roll.jpg" alt="Collecting a sample of 50 US pennies from a local bank.">
</div>
<p>An image of these 50 pennies can be seen in Figure <a href="#fig:resampling-exercise-c"><strong>??</strong></a>. For each of the 50 pennies starting in the top left, progressing row-by-row, and ending in the bottom right, note there is an “ID” identification variable printed in black and the year of minting printed in white.</p>
<div class="figure">
<span id="fig:unnamed-chunk-418"></span>
<p class="caption marginnote shownote">
FIGURE 7.3: 50 US pennies labelled.
</p>
<img src="07-one-parameter/images/3.jpg" alt="50 US pennies labelled.">
</div>
<p>The <strong>moderndive</strong>  package contains this data on our 50 sampled pennies in the <code>pennies_sample</code> data frame:</p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="one-parameter.html#cb707-1"></a><span class="kw">library</span>(moderndive)</span>
<span id="cb707-2"><a href="one-parameter.html#cb707-2"></a></span>
<span id="cb707-3"><a href="one-parameter.html#cb707-3"></a>pennies_sample</span></code></pre></div>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 50 x 2
##       ID  year
##    &lt;int&gt; &lt;dbl&gt;
##  1     1  2002
##  2     2  1986
##  3     3  2017
##  4     4  1988
##  5     5  2008
##  6     6  1983
##  7     7  2008
##  8     8  1996
##  9     9  2004
## 10    10  2000
## # … with 40 more rows</code></pre>
<p>The <code>pennies_sample</code> data frame has 50 rows corresponding to each penny with two variables. The first variable <code>ID</code> corresponds to the ID labels in Figure <a href="#fig:resampling-exercise-c"><strong>??</strong></a>, whereas the second variable <code>year</code> corresponds to the year of minting saved as a numeric variable, also known as a double (<code>dbl</code>).</p>
<p>Based on these 50 sampled pennies, what can we say about <em>all</em> US pennies in 2019? Let’s study some properties of our sample by performing an exploratory data analysis. Let’s first visualize the distribution of the year of these 50 pennies using our data visualization tools from Chapter <a href="#viz"><strong>??</strong></a>. Since <code>year</code> is a numerical variable, we use a histogram in Figure <a href="#fig:pennies-sample-histogram"><strong>??</strong></a> to visualize its distribution.</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="one-parameter.html#cb710-1"></a>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb710-2"><a href="one-parameter.html#cb710-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb710-3"><a href="one-parameter.html#cb710-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">"white"</span>)</span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-420"></span>
<p class="caption marginnote shownote">
FIGURE 7.4: Distribution of year on 50 US pennies.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-420-1.png" alt="Distribution of year on 50 US pennies." width="672">
</div>
<p>Observe a slightly left-skewed distribution, since most pennies fall between 1980 and 2010 with only a few pennies older than 1970. What is the average year for the 50 sampled pennies? Eyeballing the histogram it appears to be around 1990. Let’s now compute this value exactly using our data wrangling tools from Chapter <a href="tidyverse.html#tidyverse">2</a>.</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="one-parameter.html#cb711-1"></a>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb711-2"><a href="one-parameter.html#cb711-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_year
##       &lt;dbl&gt;
## 1     1995.</code></pre>
<p>Thus, if we’re willing to assume that <code>pennies_sample</code> is a representative sample from <em>all</em> US pennies, a “good guess” of the average year of minting of all US pennies would be 1995.44. In other words, around 1995. This should all start sounding similar to what we did previously in Chapter <a href="sampling.html#sampling">6</a>!</p>
<p>In Chapter <a href="sampling.html#sampling">6</a>, our <em>study population</em> was the urn of <span class="math inline">\(N\)</span> = 2400 balls. Our <em>population parameter</em> was the <em>population proportion</em> of these balls that were red, denoted by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel. We then computed the relevant <em>point estimate</em>: the <em>sample proportion</em> of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Here our population is <span class="math inline">\(N\)</span> = whatever the number of pennies are being used in the US, a value which we don’t know and probably never will. The population parameter of interest is now the <em>population mean</em> year of all these pennies, a value denoted mathematically by the Greek letter <span class="math inline">\(\mu\)</span> (pronounced “mu”). In order to estimate <span class="math inline">\(\mu\)</span>, we went to the bank and obtained a sample of 50 pennies and computed the relevant point estimate: the <em>sample mean</em> year of these 50 pennies, denoted mathematically by <span class="math inline">\(\overline{x}\)</span> (pronounced “x-bar”). An alternative and more intuitive notation for the sample mean is <span class="math inline">\(\widehat{\mu}\)</span>. However, this is unfortunately not as commonly used, so in this book we’ll stick with convention and always denote the sample mean as <span class="math inline">\(\overline{x}\)</span>.</p>
<p>We summarize the correspondence between the sampling urn exercise in Chapter <a href="sampling.html#sampling">6</a> and our pennies exercise in Table <a href="#tab:table-ch8-b"><strong>??</strong></a>.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#rgndohygub .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#rgndohygub .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rgndohygub .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#rgndohygub .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#rgndohygub .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rgndohygub .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#rgndohygub .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#rgndohygub .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#rgndohygub .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#rgndohygub .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#rgndohygub .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#rgndohygub .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#rgndohygub .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#rgndohygub .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#rgndohygub .gt_from_md > :first-child {
  margin-top: 0;
}

#rgndohygub .gt_from_md > :last-child {
  margin-bottom: 0;
}

#rgndohygub .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#rgndohygub .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#rgndohygub .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rgndohygub .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#rgndohygub .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#rgndohygub .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#rgndohygub .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#rgndohygub .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rgndohygub .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#rgndohygub .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#rgndohygub .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#rgndohygub .gt_left {
  text-align: left;
}

#rgndohygub .gt_center {
  text-align: center;
}

#rgndohygub .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#rgndohygub .gt_font_normal {
  font-weight: normal;
}

#rgndohygub .gt_font_bold {
  font-weight: bold;
}

#rgndohygub .gt_font_italic {
  font-style: italic;
}

#rgndohygub .gt_super {
  font-size: 65%;
}

#rgndohygub .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="rgndohygub" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Scenario</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Population_parameter</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Notation</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Point_Estimate</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Symbol</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>1</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population Proportion</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$p$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Sample Proportion</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\widehat{p}$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>2</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population mean</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\mu $$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Sample mean</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\overline{x}$$ or $$\widehat{\mu}$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>3</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in population proportions</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$p_1 - p_2$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in sample proportions</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\widehat{p}_1 - \widehat{p}_2$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>4</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in Pupulation means</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\mu_1 - \mu_2$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in sample means</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\overline{x}_1 - \overline{x}_2$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>5</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population regression slope</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\beta_1$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Fitted regression slope</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$b_1$$ or $$\widehat{\beta}_1$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>6</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population regression coefficient</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\beta_0$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Fitted regression intercept</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$b_0$$ or $$\widehat{\beta}_0$$</p>
</div></td>
    </tr>
</tbody>
</table></div>
<p>Going back to our 50 sampled pennies in Figure <a href="#fig:resampling-exercise-c"><strong>??</strong></a>, the point estimate of interest is the sample mean <span class="math inline">\(\overline{x}\)</span> of 1995.44. This quantity is an <em>estimate</em> of the population mean year of <em>all</em> US pennies <span class="math inline">\(\mu\)</span>.</p>
<p>Recall that we also saw in Chapter <a href="sampling.html#sampling">6</a> that such estimates are prone to <em>sampling variation</em>. For example, in this particular sample in Figure <a href="#fig:resampling-exercise-c"><strong>??</strong></a>, we observed three pennies with the year 1999. If we sampled another 50 pennies, would we observe exactly three pennies with the year 1999 again? More than likely not. We might observe none, one, two, or maybe even all 50! The same can be said for the other 26 unique years that are represented in our sample of 50 pennies.</p>
<p>Let’s now perform the virtual analog for 1000 resamples. Using these results, we’ll be able to study the variability in the sample means from 1000 resamples of size 50. Let’s first add a <code>times = 1000</code> argument to <code>bootstraps()</code>  to indicate we would like 1000 replicates. Remember that we must use the <code>rsample</code> library to use bootstraps. Thus, we want to repeat the resampling with the replacement of 50 pennies 1000 times. We will also select the variable we care concerned with, which is <code>year</code>.</p>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="one-parameter.html#cb714-1"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb714-2"><a href="one-parameter.html#cb714-2"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb714-3"><a href="one-parameter.html#cb714-3"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>)</span>
<span id="cb714-4"><a href="one-parameter.html#cb714-4"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling</code></pre>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1,000 x 2
##    splits          id           
##    &lt;list&gt;          &lt;chr&gt;        
##  1 &lt;split [50/17]&gt; Bootstrap0001
##  2 &lt;split [50/18]&gt; Bootstrap0002
##  3 &lt;split [50/19]&gt; Bootstrap0003
##  4 &lt;split [50/21]&gt; Bootstrap0004
##  5 &lt;split [50/20]&gt; Bootstrap0005
##  6 &lt;split [50/20]&gt; Bootstrap0006
##  7 &lt;split [50/19]&gt; Bootstrap0007
##  8 &lt;split [50/16]&gt; Bootstrap0008
##  9 &lt;split [50/13]&gt; Bootstrap0009
## 10 &lt;split [50/17]&gt; Bootstrap0010
## # … with 990 more rows</code></pre>
<p>So we have now created bootstrap samples, which are stored in a tibble-like object, and each bootstrap sample is nested in the splits column. If you are interested to view a specific bootstrap sample, you can use the <code>analysis()</code> function from the <code>rsample</code> package, which basically allows you to view a specific bootstrap sample as a data frame. To do so, type <code>analysis(virtual_resamples$splits[[n]]) %&gt;% as_tibble()</code> where n represents the nth bootstrap sample. We will be looking at the first bootstrap sample in this case.</p>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="one-parameter.html#cb718-1"></a><span class="kw">analysis</span>(virtual_resamples<span class="op">$</span>splits[[<span class="dv">1</span>]]) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>()</span></code></pre></div>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 50 x 1
##     year
##    &lt;dbl&gt;
##  1  2018
##  2  2013
##  3  1983
##  4  1978
##  5  1979
##  6  1997
##  7  2013
##  8  2015
##  9  2017
## 10  1997
## # … with 40 more rows</code></pre>
<p>Using <code>analysis</code> is a very significant function for bootstrapping, because it allows us to pull out necessary data.</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="one-parameter.html#cb721-1"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb721-2"><a href="one-parameter.html#cb721-2"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb721-3"><a href="one-parameter.html#cb721-3"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb721-4"><a href="one-parameter.html#cb721-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.)))</span>
<span id="cb721-5"><a href="one-parameter.html#cb721-5"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling</code></pre>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1,000 x 3
##    splits          id            boot             
##  * &lt;list&gt;          &lt;chr&gt;         &lt;list&gt;           
##  1 &lt;split [50/22]&gt; Bootstrap0001 &lt;tibble [50 × 1]&gt;
##  2 &lt;split [50/22]&gt; Bootstrap0002 &lt;tibble [50 × 1]&gt;
##  3 &lt;split [50/15]&gt; Bootstrap0003 &lt;tibble [50 × 1]&gt;
##  4 &lt;split [50/16]&gt; Bootstrap0004 &lt;tibble [50 × 1]&gt;
##  5 &lt;split [50/19]&gt; Bootstrap0005 &lt;tibble [50 × 1]&gt;
##  6 &lt;split [50/18]&gt; Bootstrap0006 &lt;tibble [50 × 1]&gt;
##  7 &lt;split [50/19]&gt; Bootstrap0007 &lt;tibble [50 × 1]&gt;
##  8 &lt;split [50/21]&gt; Bootstrap0008 &lt;tibble [50 × 1]&gt;
##  9 &lt;split [50/19]&gt; Bootstrap0009 &lt;tibble [50 × 1]&gt;
## 10 &lt;split [50/15]&gt; Bootstrap0010 &lt;tibble [50 × 1]&gt;
## # … with 990 more rows</code></pre>
<p><code>boot</code> is now a list-column in the tibble, which we can use if we want to find a specific characteristic of each sample like the average year or median year. Let’s add more columns for our tibble to find the average year of each bootstrap sample.</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="one-parameter.html#cb725-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb725-2"><a href="one-parameter.html#cb725-2"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb725-3"><a href="one-parameter.html#cb725-3"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb725-4"><a href="one-parameter.html#cb725-4"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb725-5"><a href="one-parameter.html#cb725-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb725-6"><a href="one-parameter.html#cb725-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">years =</span> <span class="kw">map</span>(boot, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., year))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb725-7"><a href="one-parameter.html#cb725-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year_mean =</span> <span class="kw">map_dbl</span>(years, <span class="op">~</span><span class="st"> </span><span class="kw">mean</span>(.))) </span>
<span id="cb725-8"><a href="one-parameter.html#cb725-8"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling</code></pre>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1,000 x 5
##    splits          id            boot              years      year_mean
##  * &lt;list&gt;          &lt;chr&gt;         &lt;list&gt;            &lt;list&gt;         &lt;dbl&gt;
##  1 &lt;split [50/19]&gt; Bootstrap0001 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1992.
##  2 &lt;split [50/20]&gt; Bootstrap0002 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1999.
##  3 &lt;split [50/16]&gt; Bootstrap0003 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1992.
##  4 &lt;split [50/18]&gt; Bootstrap0004 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
##  5 &lt;split [50/18]&gt; Bootstrap0005 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1995.
##  6 &lt;split [50/18]&gt; Bootstrap0006 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1998.
##  7 &lt;split [50/17]&gt; Bootstrap0007 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
##  8 &lt;split [50/14]&gt; Bootstrap0008 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1995.
##  9 &lt;split [50/19]&gt; Bootstrap0009 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
## 10 &lt;split [50/20]&gt; Bootstrap0010 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     2000.
## # … with 990 more rows</code></pre>
<p>Great! We were able to create a thousand bootstrap samples and calculate the mean year for each resample. Let’s now create a plot to visualize the distribution of the average year for each resample.</p>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="one-parameter.html#cb729-1"></a>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb729-2"><a href="one-parameter.html#cb729-2"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb729-3"><a href="one-parameter.html#cb729-3"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year_mean), <span class="dt">binwidth =</span> <span class="fl">.1</span>, <span class="dt">fill =</span> <span class="st">"red"</span>) <span class="op">+</span></span>
<span id="cb729-4"><a href="one-parameter.html#cb729-4"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Estimate in Year"</span>,</span>
<span id="cb729-5"><a href="one-parameter.html#cb729-5"></a>         <span class="dt">title =</span> <span class="st">"Posterior Distribution for the Mean Year of American Pennies in 2019"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-428-1.png" width="672">
Note here that the bell shape is starting to become much more apparent. We now have a general sense for the range of values that the sample mean may take on. But where is this histogram centered? Let’s compute the mean of the 1,000 resample means:</p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="one-parameter.html#cb730-1"></a>mean_of_means &lt;-<span class="st"> </span>virtual_resamples <span class="op">%&gt;%</span></span>
<span id="cb730-2"><a href="one-parameter.html#cb730-2"></a><span class="st">  </span><span class="kw">select</span>(year_mean) <span class="op">%&gt;%</span></span>
<span id="cb730-3"><a href="one-parameter.html#cb730-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_of_means =</span> <span class="kw">mean</span>(year_mean)) <span class="op">%&gt;%</span></span>
<span id="cb730-4"><a href="one-parameter.html#cb730-4"></a><span class="st">  </span><span class="kw">pull</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb730-5"><a href="one-parameter.html#cb730-5"></a><span class="st">  </span><span class="kw">round</span>(<span class="dv">2</span>)</span></code></pre></div>
<p>The mean of these 1,000 means is 1995.52, which is quite close to the mean of our original sample of 50 pennies of 1995.44. This is the case since each of the 1,000 resamples is based on the original sample of 50 pennies.</p>
<p>Recall that in the “resampling with replacement” scenario we are illustrating here, this histogram has a special name: the <em>bootstrap distribution of the sample mean</em>. Furthermore, recall it is an approximation to the <em>sampling distribution</em> of the sample mean, a concept you saw in Chapter <a href="sampling.html#sampling">6</a> on sampling. This distribution allows us to study the effect of sampling variation on our estimates of the true population mean, in this case the true mean year for <em>all</em> US pennies. However, unlike in Chapter <a href="sampling.html#sampling">6</a> where we took multiple samples (something one would never do in practice), bootstrap distributions are constructed by taking multiple resamples from a <em>single</em> sample: in this case, the 50 original pennies from the bank.</p>
<p>Congratulations! You’ve just constructed your first bootstrap distribution! In the next section, you’ll see how to use this bootstrap distribution to construct <em>confidence intervals</em>.</p>
</div>
</div>
<div id="confidence-intervals-using-lm" class="section level2">
<h2>
<span class="header-section-number">7.2</span> Confidence Intervals using lm</h2>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="one-parameter.html#cb731-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb731-2"><a href="one-parameter.html#cb731-2"></a>  <span class="kw">lm</span>(year_mean <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> virtual_resamples) <span class="op">%&gt;%</span></span>
<span id="cb731-3"><a href="one-parameter.html#cb731-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb731-4"><a href="one-parameter.html#cb731-4"></a><span class="st">  </span><span class="kw">select</span>(conf.low, estimate, conf.high)</span></code></pre></div>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1 x 3
##   conf.low estimate conf.high
##      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    1995.    1996.     1996.</code></pre>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="one-parameter.html#cb734-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb734-2"><a href="one-parameter.html#cb734-2"></a>  <span class="kw">lm</span>(year_mean <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> virtual_resamples) <span class="op">%&gt;%</span></span>
<span id="cb734-3"><a href="one-parameter.html#cb734-3"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb734-4"><a href="one-parameter.html#cb734-4"></a><span class="st">  </span><span class="kw">select</span>(conf.low, estimate, conf.high)</span></code></pre></div>
<pre><code>## Warning: `...` is not empty.
## 
## We detected these problematic arguments:
## * `needs_dots`
## 
## These dots only exist to allow future extensions and should be empty.
## Did you misspecify an argument?</code></pre>
<pre><code>## # A tibble: 1 x 3
##   conf.low estimate conf.high
##      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    1995.    1996.     1996.</code></pre>
</div>
<div id="ci-build-up" class="section level2">
<h2>
<span class="header-section-number">7.3</span> Measuring uncertainty with confidence intervals</h2>
<p>Let’s start this section with an analogy involving fishing. Say you are trying to catch a fish. On the one hand, you could use a spear, while on the other you could use a net. Using the net will probably allow you to catch more fish!</p>
<p>Now think back to our pennies exercise where you are trying to estimate the true population mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies.  Think of the value of <span class="math inline">\(\mu\)</span> as a fish.</p>
<p>On the one hand, we could use the appropriate <em>point estimate/sample statistic</em> to estimate <span class="math inline">\(\mu\)</span>, which we saw in Table <a href="#tab:table-ch8-b"><strong>??</strong></a> is the sample mean <span class="math inline">\(\overline{x}\)</span>. Based on our sample of 50 pennies from the bank, the sample mean was 1995.44. Think of using this value as “fishing with a spear.”</p>
<p>What would “fishing with a net” correspond to? Look at the bootstrap distribution in Figure <a href="#fig:one-thousand-sample-means"><strong>??</strong></a> once more. Between which two years would you say that “most” sample means lie? While this question is somewhat subjective, saying that most sample means lie between 1992 and 2000 would not be unreasonable. Think of this interval as the “net.”</p>
<p>What we’ve just illustrated is the concept of a <em>confidence interval</em>, which we’ll abbreviate with “CI” throughout this book. As opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a <em>confidence interval</em>  gives what can be interpreted as a range of plausible values. Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-432"></span>
<p class="caption marginnote shownote">
FIGURE 7.5: Analogy of difference between point estimates and confidence intervals.
</p>
<img src="07-one-parameter/images/point_estimate_vs_conf_int.png" alt="Analogy of difference between point estimates and confidence intervals.">
</div>
<p>Our proposed interval of 1992 to 2000 was constructed by eye and was thus somewhat subjective. We now introduce two methods for constructing such intervals in a more exact fashion: the <em>percentile method</em> and the <em>standard error method</em>.</p>
<p>Both methods for confidence interval construction share some commonalities. First, they are both constructed from a bootstrap distribution, as you constructed in Subsection <a href="#bootstrap-1000-replicates"><strong>??</strong></a> and visualized in Figure <a href="#fig:one-thousand-sample-means"><strong>??</strong></a>.</p>
<p>Second, they both require you to specify the  <em>confidence level</em>. Commonly used confidence levels include 90%, 95%, and 99%. All other things being equal, higher confidence levels correspond to wider confidence intervals, and lower confidence levels correspond to narrower confidence intervals. In this book, we’ll be mostly using 95% and hence constructing “95% confidence intervals for <span class="math inline">\(\mu\)</span>” for our pennies activity.</p>
</div>
<div id="income-from-trains-using-bootstrap" class="section level2">
<h2>
<span class="header-section-number">7.4</span> Income from trains using Bootstrap</h2>
<p>In addition to using <code>lm()</code>, we can also use bootsrapping to extract confidence intervals. Bootstrapping is a significant tool used in statistics. Bootstrapping repeatedly draws samples from a data set and derives standard errors and confidence intervals for any statistic. While using <code>lm()</code> can produce confidence intervals for the mean of a data set or the coefficient in a regression, bootstrapping can produce confidence intervals for any statistics, such as median, 3rd highest value, etc.</p>
<p>To use bootstrapping, we will need the <strong>tidyverse</strong> and <strong>rsample</strong> packages. The <strong>rsample</strong> package gives us commands to use for bootstrapping. For the purpose of this example, let’s try to find the confidence interval for the mean income in our trains dataset from Chapter 3.</p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="one-parameter.html#cb737-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb737-2"><a href="one-parameter.html#cb737-2"></a><span class="kw">library</span>(rsample)</span>
<span id="cb737-3"><a href="one-parameter.html#cb737-3"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb737-4"><a href="one-parameter.html#cb737-4"></a></span>
<span id="cb737-5"><a href="one-parameter.html#cb737-5"></a>train_samples &lt;-<span class="st"> </span><span class="kw">bootstraps</span>(trains, <span class="dt">times =</span> <span class="dv">1000</span>)</span>
<span id="cb737-6"><a href="one-parameter.html#cb737-6"></a></span>
<span id="cb737-7"><a href="one-parameter.html#cb737-7"></a>derive_mean_income &lt;-<span class="st"> </span><span class="cf">function</span>(splits) {</span>
<span id="cb737-8"><a href="one-parameter.html#cb737-8"></a> x &lt;-<span class="st"> </span><span class="kw">analysis</span>(splits)</span>
<span id="cb737-9"><a href="one-parameter.html#cb737-9"></a> <span class="kw">return</span>(<span class="kw">mean</span>(x<span class="op">$</span>income))</span>
<span id="cb737-10"><a href="one-parameter.html#cb737-10"></a>}</span>
<span id="cb737-11"><a href="one-parameter.html#cb737-11"></a></span>
<span id="cb737-12"><a href="one-parameter.html#cb737-12"></a>train_samples<span class="op">$</span>mean_income &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(train_samples<span class="op">$</span>splits, derive_mean_income)</span>
<span id="cb737-13"><a href="one-parameter.html#cb737-13"></a><span class="kw">quantile</span>(train_samples<span class="op">$</span>mean_income, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 128623.6 154507.4</code></pre>
<p>To find the confidence interval for the mean income in our train dataset, we first create our bootstrap samples using <code>bootstraps()</code>, where the times argument represents the number of bootstrap samples you want. Bootstrap samples are stored in a tibble and each bootstrap sample is nested in a split column. We then create a function for the statistic we are looking at; in this case, we want to focus on the mean income. Once we create our function, we can apply our statistic, the mean income, to each of our bootstrap samples by using map_dbl. Finally, we use quantile to extract our confidence intervals.</p>
<p>If we want to find a different statistic like the median income, we can essentially do the same thing but edit the function to derive the median income.</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="one-parameter.html#cb739-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb739-2"><a href="one-parameter.html#cb739-2"></a><span class="kw">library</span>(rsample)</span>
<span id="cb739-3"><a href="one-parameter.html#cb739-3"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb739-4"><a href="one-parameter.html#cb739-4"></a></span>
<span id="cb739-5"><a href="one-parameter.html#cb739-5"></a>train_samples &lt;-<span class="st"> </span><span class="kw">bootstraps</span>(trains, <span class="dt">times =</span> <span class="dv">1000</span>)</span>
<span id="cb739-6"><a href="one-parameter.html#cb739-6"></a></span>
<span id="cb739-7"><a href="one-parameter.html#cb739-7"></a>derive_median_income &lt;-<span class="st"> </span><span class="cf">function</span>(splits) {</span>
<span id="cb739-8"><a href="one-parameter.html#cb739-8"></a> x &lt;-<span class="st"> </span><span class="kw">analysis</span>(splits)</span>
<span id="cb739-9"><a href="one-parameter.html#cb739-9"></a> <span class="kw">return</span>(<span class="kw">median</span>(x<span class="op">$</span>income))</span>
<span id="cb739-10"><a href="one-parameter.html#cb739-10"></a>}</span>
<span id="cb739-11"><a href="one-parameter.html#cb739-11"></a></span>
<span id="cb739-12"><a href="one-parameter.html#cb739-12"></a>train_samples<span class="op">$</span>median_income &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(train_samples<span class="op">$</span>splits, derive_median_income)</span>
<span id="cb739-13"><a href="one-parameter.html#cb739-13"></a><span class="kw">quantile</span>(train_samples<span class="op">$</span>median_income, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))</span></code></pre></div>
<pre><code>##   2.5%  97.5% 
## 105000 135000</code></pre>
<p>Redo but more quickly, estimating mean income.</p>
<p>Estimate median income, or 3rd highest income.</p>
</div>
<div id="parameter-uncertainty-and-unmodeled-variation" class="section level2">
<h2>
<span class="header-section-number">7.5</span> Parameter Uncertainty and Unmodeled Variation</h2>
<p>Although, we have used bootstrap to predict what we think the mean or a parameter like the median will be, it is important to understand what parameter uncertainty is. Paraameter uncertainty refers to when exact values of parameters are unknown to experimenters and cannot be controlled for. These values usually cannot be inferred by statistical or computational methods. Let’s look at the confidence interval of the mean as an example. Based on our bootstrap method, the 95% CI for the mean income is [128999.8, 155201.6]. However, if we take into consideration parameter uncertainty here, we fall under the trap of overconfidence. This is because we do not know for sure the way our confidence interval is elicited is perfectly accurate. We are thus overconfident here when we use a confidence interval.</p>
<p>Furthermore, it is important that we understand what a residual is. The residual in data science is the error that results. In simple terms, it is the observed value minus the predicted value. So, for example, let’s say that the actual mean income is 140,000 but the predicted mean income we got was 130,000. That means the residual in our estimation is 10,000.</p>
<p>But the reason why residuals are so important is that they help explain why we can’t make perfect predictions, especially for an individual. In our experiments, there is a lot of unmodeled variation, or residual variation. Residual variance refers to the variance of residuals, and occurs because randomness in our data is inherently intrinsic. There will be randomness in our data even if we have full knowldge of our data. This thus implies that we cannot really make fully accurate predictions of the future; we can only make probabilistic predictions. It is essentially difficult to control for residual variation, and predictions we get from methods like bootstrapping should not be taken as the final concensus.</p>
<p>I might need to talk more about unmodeled variation here.</p>
</div>
<div id="case-study-looking-at-2018-qscore-data" class="section level2">
<h2>
<span class="header-section-number">7.6</span> Case study: Looking at 2018 Qscore data</h2>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="one-parameter.html#cb741-1"></a>qscoresdata &lt;-<span class="st"> </span>qscores <span class="op">%&gt;%</span></span>
<span id="cb741-2"><a href="one-parameter.html#cb741-2"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">==</span><span class="st"> "2018F"</span>) <span class="op">%&gt;%</span></span>
<span id="cb741-3"><a href="one-parameter.html#cb741-3"></a><span class="st">  </span><span class="kw">select</span>(course_name, department, rating)</span>
<span id="cb741-4"><a href="one-parameter.html#cb741-4"></a></span>
<span id="cb741-5"><a href="one-parameter.html#cb741-5"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb741-6"><a href="one-parameter.html#cb741-6"></a>sampleqscore &lt;-<span class="st"> </span><span class="kw">sample_n</span>(qscoresdata, <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</span>
<span id="cb741-7"><a href="one-parameter.html#cb741-7"></a></span>
<span id="cb741-8"><a href="one-parameter.html#cb741-8"></a>qscoreboot &lt;-<span class="st"> </span><span class="kw">bootstraps</span>(sampleqscore, <span class="dt">times =</span> <span class="dv">10</span>)</span>
<span id="cb741-9"><a href="one-parameter.html#cb741-9"></a></span>
<span id="cb741-10"><a href="one-parameter.html#cb741-10"></a>derive_mean_rating &lt;-<span class="st"> </span><span class="cf">function</span>(splits) {</span>
<span id="cb741-11"><a href="one-parameter.html#cb741-11"></a> x &lt;-<span class="st"> </span><span class="kw">analysis</span>(splits)</span>
<span id="cb741-12"><a href="one-parameter.html#cb741-12"></a> <span class="kw">return</span>(<span class="kw">mean</span>(x<span class="op">$</span>rating))</span>
<span id="cb741-13"><a href="one-parameter.html#cb741-13"></a>}</span>
<span id="cb741-14"><a href="one-parameter.html#cb741-14"></a></span>
<span id="cb741-15"><a href="one-parameter.html#cb741-15"></a>qscoreboot<span class="op">$</span>mean_rating &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(qscoreboot<span class="op">$</span>splits, derive_mean_rating)</span>
<span id="cb741-16"><a href="one-parameter.html#cb741-16"></a><span class="kw">quantile</span>(qscoreboot<span class="op">$</span>mean_rating, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))</span></code></pre></div>
<pre><code>##    2.5%   97.5% 
## 4.08435 4.34330</code></pre>
<!-- TA: Is this you want it done with bootstraps? Am a little confused how the directions ask to make bootstraps from one sample -->
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="one-parameter.html#cb743-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb743-2"><a href="one-parameter.html#cb743-2"></a></span>
<span id="cb743-3"><a href="one-parameter.html#cb743-3"></a>qscoresamples &lt;-<span class="st"> </span><span class="kw">rep_sample_n</span>(qscores, <span class="dv">50</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>, <span class="dt">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb743-4"><a href="one-parameter.html#cb743-4"></a>qscorebootstraps &lt;-<span class="st"> </span><span class="kw">bootstraps</span>(qscoresamples, <span class="dt">times =</span> <span class="dv">1000</span>)</span>
<span id="cb743-5"><a href="one-parameter.html#cb743-5"></a></span>
<span id="cb743-6"><a href="one-parameter.html#cb743-6"></a>derive_mean_rating &lt;-<span class="st"> </span><span class="cf">function</span>(splits) {</span>
<span id="cb743-7"><a href="one-parameter.html#cb743-7"></a> x &lt;-<span class="st"> </span><span class="kw">analysis</span>(splits)</span>
<span id="cb743-8"><a href="one-parameter.html#cb743-8"></a> <span class="kw">return</span>(<span class="kw">mean</span>(x<span class="op">$</span>rating))</span>
<span id="cb743-9"><a href="one-parameter.html#cb743-9"></a>}</span>
<span id="cb743-10"><a href="one-parameter.html#cb743-10"></a></span>
<span id="cb743-11"><a href="one-parameter.html#cb743-11"></a>qscorebootstraps<span class="op">$</span>mean_rating &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(qscorebootstraps<span class="op">$</span>splits, derive_mean_rating)</span>
<span id="cb743-12"><a href="one-parameter.html#cb743-12"></a><span class="kw">quantile</span>(qscorebootstraps<span class="op">$</span>mean_rating, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">025</span>, <span class="fl">.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 4.169260 4.178436</code></pre>
<!-- TA: Based on the directions, it seems that i need to use rep_sample_n but Im confused how we are then going to apply bootstraps function to those samples.  -->
</div>
<div id="ci-conclusion" class="section level2">
<h2>
<span class="header-section-number">7.7</span> Conclusion</h2>
<!-- DK: This section --- and, indeed, the conclusion to each chapter --- are very important. This is a real chance to hit all the highlights. Everything here should be considered fair game for the exam. Indeed, everything here should be covered in the exam. This one is not bad. But it could be cleaned up a bit, with much nicer plots. Maybe a table which directly compares bootstrap and sampling distributions. Need to remind people about why we bootstrap. (We do it because it proves that the lm() simple approaches make sense. It is the justification for our shortcuts. And, indeed, whenever those shortcuts don't work --- which is often! --- a bootstrap still will work.) -->
<div id="bootstrap-vs-sampling" class="section level3">
<h3>
<span class="header-section-number">7.7.1</span> Comparing bootstrap and sampling distributions</h3>
<p>Let’s talk more about the relationship between <em>sampling distributions</em> and <em>bootstrap distributions</em>.</p>
<p>Recall back in Subsection <a href="sampling.html#shovel-1000-times">6.2.3</a>, we took 1,000 virtual samples from the <code>urn</code> using a virtual shovel, computed 1,000 values of the sample proportion red <span class="math inline">\(\widehat{p}\)</span>, then visualized their distribution in a histogram. Recall that this distribution is called the <em>sampling distribution of</em> <span class="math inline">\(\widehat{p}\)</span> . Furthermore, the standard deviation of the sampling distribution has a special name: the <em>standard error</em>.</p>
<p>We also mentioned that this sampling activity does not reflect how sampling is done in real life. Rather, it was an <em>idealized version</em> of sampling so that we could study the effects of sampling variation on estimates, like the proportion of the shovel’s balls that are red. In real life, however, one would take a single sample that’s as large as possible, much like in the Obama poll we saw in Section <a href="sampling.html#sampling-case-study">6.4</a>. But how can we get a sense of the effect of sampling variation on estimates if we only have one sample and thus only one estimate? Don’t we need many samples and hence many estimates?</p>
<!-- DK: There is nothing wrong with this text, but I don't like it. We need a more coherent story connecting sampling to the bootstrap. Randomization is magic and these are two forms of randomization. Maybe each chapter after this should mention three types of randomization. These two and then assignment to treatment. Indeed, all of statistics is dealing with situations in which we could not use all three randomization techniques, or approximations thereto. -->
<p>The workaround to having a <em>single</em> sample was to perform <em>bootstrap resampling with replacement</em> from the single sample. We did this in the resampling activity in Section <a href="one-parameter.html#resampling-tactile">7.1</a> where we focused on the mean year of minting of pennies. We used pieces of paper representing the original sample of 50 pennies from the bank and resampled them with replacement from a hat. We had 35 of our friends perform this activity and visualized the resulting 35 sample means <span class="math inline">\(\overline{x}\)</span> in a histogram in Figure <a href="#fig:tactile-resampling-6"><strong>??</strong></a>.</p>
<p>This distribution was called the <em>bootstrap distribution</em> of <span class="math inline">\(\overline{x}\)</span>. We stated at the time that the bootstrap distribution is an <em>approximation</em> to the sampling distribution of <span class="math inline">\(\overline{x}\)</span> in the sense that both distributions will have a similar shape and similar spread.  Thus the <em>standard error</em> of the bootstrap distribution can be used as an approximation to the <em>standard error</em> of the sampling distribution.
<!-- DK: The below seems useful, but does it belong in a Conclusion? Probably not. Perhaps each chapter ends with some stats nonsense (like CLT in sampling chapter) before we get to the real conclusion. --></p>
<p>Let’s show you that this is the case by now comparing these two types of distributions. Specifically, we’ll compare</p>
<ol style="list-style-type: decimal">
<li>the sampling distribution of <span class="math inline">\(\widehat{p}\)</span> based on 1,000 virtual samples from the <code>urn</code> from Subsection <a href="sampling.html#shovel-1000-times">6.2.3</a> to</li>
<li>the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> based on 1,000 virtual resamples with replacement from Ilyas and Yohan’s single sample <code>urn_sample_1</code>.</li>
</ol>
<div id="bootstrap-distribution" class="section level4 unnumbered">
<h4>Bootstrap distribution</h4>
<p>Here is the code to construct the bootstrap distribution of <span class="math inline">\(\widehat{p}\)</span> based on Ilyas and Yohan’s original sample of 50 balls saved in <code>urn_sample_1</code>.</p>
<!-- DK: This is still ugly. Might also be nice to show this exercise with sampling of 100, 1000, 10000 and then 100000, in order to show how things smooth out and look more normal as n increases. -->
</div>
<div id="comparison" class="section level4 unnumbered">
<h4>Comparison</h4>
<ol style="list-style-type: decimal">
<li>To the bootstrap distribution on the bottom: a dashed line at the sample proportion <span class="math inline">\(\widehat{p}\)</span> = 21/50 = 0.42 = 42% that Ilyas and Yohan observed.</li>
</ol>
<p>Notice that the bootstrap distribution’s standard error is a rather good <em>approximation</em> to the sampling distribution’s standard error. This leads us to our second lesson about bootstrapping:</p>
<blockquote>
<p>Even if the bootstrap distribution might not have the same center as the sampling distribution, it will likely have very similar shape and spread. In other words, bootstrapping will give you a good estimate of the <em>standard error</em>.</p>
</blockquote>
<p>Thus, using the fact that the bootstrap distribution and sampling distributions have similar spreads, we can build confidence intervals using bootstrapping as we’ve done all throughout this chapter!</p>
<!-- ## Rubin Causal Model -->
<!-- At least then we could have an average blood pressure for the respondents in our sample, right? -->
<!-- Not so fast! It is probably not reasonable to assume that every blood pressure measurement is perfectly accurate.  Some survey respondents may misremember or round the values, or use measurements from a doctor's visit long ago.  (How many American adults own blood pressure monitors?)  Furthermore, blood pressure monitors aren't 100% accurate. -->
<!-- One's blood pressure reading also isn't a single, constant number, even if it could be perfectly measured: it depends on the time of day, whether one exercised or ate before taking the measurement, and so on. -->
<!-- So what we really should do is think of each measurement as being drawn from a distribution of potential values for each person; we could construct a *confidence interval* around each of the values to try to reflect these sources of error.  Let's say that a fair CI is 15 points in either direction.  (It may actually be higher; this is just for illustration.)  Then our table really looks something like this: -->
<!-- ```{r, echo = FALSE} -->
<!-- # First, we create a tibble with the values we want for the table -->
<!-- tibble(subject = c("Respondent 1", "Respondent 2", "Respondent 3", "...", "Respondent 1,000"), -->
<!--        `Blood Pressure` = c("130 (115, 145)", "110 (95, 125)", "115 (100, 130)", "...", "140 (125, 155)")) %>% -->
<!--   # Then, we use the gt function to make it pretty -->
<!--   gt() %>% -->
<!--   cols_label(subject = md("**Respondent**")) %>% -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = vars(subject))) %>% -->
<!--   tab_style(cell_text(weight = "bold"), -->
<!--             location = cells_body(columns = vars(subject))) -->
<!-- ``` -->
<!-- 1. **Uncertainty in estimating the ATE**.  Even if treatment is randomly assigned, and thus $\widehat{ATE}$ is an unbiased estimate of the true ATE, we still may not have a very *precise* estimate if our sample is small.  With this miniscule sample (five sujects!), the uncertainty might be gigantic, perhaps someting like ($-25$, $13$), which would lead to a prediction for Joe of ($117, 155$).  As we get a larger sample size, this uncertainty decreases.   -->
<!-- 1. **Individual variation**.  Even if we have a perfect estimate of the *average* treatment effect, it still may be the case that the effect *for Joe* is higher or lower than average.  We can assume this away if we say that the treatment effect is a constant $\tau$ for everyone, but that is not likely to be true in the real world --- and this source of uncertainty does not go away simply by collecting more observations.  So with a large sample, let's say that we calculated a confidence interval around $\widehat{ATE}$ of ($-6, -5.67$), leading to an interval for Joe's outcome under control of ($135.67, 136$).  The uncertainty due to individual variation may still be a great deal higher---say ($120, 152$).  These numbers are simply illustrative, but they highlight an important point: even if you have a good estimate of the ATE, you should still be much more uncertain about the causal effect for any *particular individual*. -->
<!-- The main takeaway is that we can get rid of #1 by collecting more data, but the only way to get rid of #2 is through making assumptions, potentially very strong ones. -->
<!-- ## Conclusion -->
<!--
Other stuff which might be added

The kind of computer-based statistical inference we've seen so far has a particular name in the field of statistics: *simulation-based inference*. This is because we are performing statistical inference using computer simulations.\index{simulation-based inference} In our opinion, two large benefits of simulation-based methods over theory-based methods are that (1) they are easier for people new to statistical inference to understand and (2) they also work in situations where theory-based methods and mathematical formulas don't exist.


#### Confidence intervals based on 100 virtual samples {-}

Let's say, however, we repeated this 100 times, not tactilely, but virtually. Let's do this only 100 times instead of 1000 like we did before so that the results can fit on the screen. Again, the steps for compute a 95% confidence interval for $p$ are:

1. Collect a sample of size $n = 50$ as we did in Chapter \@ref(sampling)
1. Compute $\widehat{p}$: the sample proportion red of these $n$ = 50 balls
1. Compute the standard error $\text{SE} = \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute the margin of error $\text{MoE} = 1.96 \cdot \text{SE} =  1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
1. Compute both end points of the confidence interval:
    + `lower_ci`: $\widehat{p} - \text{MoE} = \widehat{p} - 1.96 \cdot \text{SE} = \widehat{p} - 1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$
    + `upper_ci`: $\widehat{p} + \text{MoE} = \widehat{p} + 1.96 \cdot \text{SE} = \widehat{p} +1.96 \cdot \sqrt{\frac{\widehat{p}(1-\widehat{p})}{n}}$

Run the following three steps, being sure to `View()` the resulting data frame after each step so you can convince yourself of what's going on:



We see that of our 100 confidence intervals based on samples of size $n$ = 50, `sum(virtual_prop_red[["captured"]])` of them captured the true $p = 900/2400$, whereas `100 - sum(virtual_prop_red[["captured"]])` of them missed. As we create more and more confidence intervals based on more and more samples, about 95% of these intervals will capture. In other words, our procedure is "95% reliable." 
-->

</div>
</div>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="sampling.html"><button class="btn btn-default">Previous</button></a>
<a href="two-parameters.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-07-16
</p>
</div>
</div>



</body>
</html>
